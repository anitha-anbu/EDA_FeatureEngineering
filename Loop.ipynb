{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.894557823129\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86139178539\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.105442176871\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.155563791346\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   4]\n",
      " [ 27  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       251\n",
      "          1       0.80      0.37      0.51        43\n",
      "\n",
      "avg / total       0.89      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 10,  19,  26,  67,  74,  86,  95, 127, 159, 172, 178, 188, 207,\n",
      "       213, 214, 229, 244, 265, 273, 289], dtype=int64),)]]\n",
      "[0.86139178538989436]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846079105389\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0466042805522\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   2]\n",
      " [ 33  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       251\n",
      "          1       0.83      0.23      0.36        43\n",
      "\n",
      "avg / total       0.88      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 10,  19,  26,  67,  74,  86,  95, 127, 159, 172, 178, 188, 207,\n",
      "       213, 214, 229, 244, 265, 273, 289], dtype=int64),)], [0.88095238095238093, 'SelectKBest+LR', (array([ 19,  26,  42,  74,  95, 127, 168, 172, 214, 229, 244, 265], dtype=int64),)]]\n",
      "[0.86139178538989436, 0.84607910538925157]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 10,  19,  26,  67,  74,  86,  95, 127, 159, 172, 178, 188, 207,\n",
      "       213, 214, 229, 244, 265, 273, 289], dtype=int64),)], [0.88095238095238093, 'SelectKBest+LR', (array([ 19,  26,  42,  74,  95, 127, 168, 172, 214, 229, 244, 265], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86139178538989436, 0.84607910538925157, 0.83503546899454539]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 10,  19,  26,  67,  74,  86,  95, 127, 159, 172, 178, 188, 207,\n",
      "       213, 214, 229, 244, 265, 273, 289], dtype=int64),)], [0.88095238095238093, 'SelectKBest+LR', (array([ 19,  26,  42,  74,  95, 127, 168, 172, 214, 229, 244, 265], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86139178538989436, 0.84607910538925157, 0.83503546899454539, 0.83503546899454539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 10,  19,  26,  67,  74,  86,  95, 127, 159, 172, 178, 188, 207,\n",
      "       213, 214, 229, 244, 265, 273, 289], dtype=int64),)], [0.88095238095238093, 'SelectKBest+LR', (array([ 19,  26,  42,  74,  95, 127, 168, 172, 214, 229, 244, 265], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86139178538989436, 0.84607910538925157, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835890169764\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.198554618734\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   7]\n",
      " [ 37   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       251\n",
      "          1       0.46      0.14      0.21        43\n",
      "\n",
      "avg / total       0.81      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 10,  19,  26,  67,  74,  86,  95, 127, 159, 172, 178, 188, 207,\n",
      "       213, 214, 229, 244, 265, 273, 289], dtype=int64),)], [0.88095238095238093, 'SelectKBest+LR', (array([ 19,  26,  42,  74,  95, 127, 168, 172, 214, 229, 244, 265], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 22,  45,  59,  81, 121, 137, 143, 194, 207, 208, 229, 236, 265], dtype=int64),)]]\n",
      "[0.86139178538989436, 0.84607910538925157, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.8358901697641109]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.894557823129\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856276718011\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.105442176871\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.155563791346\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   2]\n",
      " [ 29  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94       251\n",
      "          1       0.88      0.33      0.47        43\n",
      "\n",
      "avg / total       0.89      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 10,  19,  26,  67,  74,  86,  95, 127, 159, 172, 178, 188, 207,\n",
      "       213, 214, 229, 244, 265, 273, 289], dtype=int64),)], [0.88095238095238093, 'SelectKBest+LR', (array([ 19,  26,  42,  74,  95, 127, 168, 172, 214, 229, 244, 265], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 22,  45,  59,  81, 121, 137, 143, 194, 207, 208, 229, 236, 265], dtype=int64),)], [0.89455782312925169, 'XGBoost', (array([ 10,  22,  26,  42,  43,  74,  86, 126, 127, 178, 207, 213, 229,\n",
      "       249, 265, 289], dtype=int64),)]]\n",
      "[0.86139178538989436, 0.84607910538925157, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.8358901697641109, 0.85627671801102334]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.89455782312925169, 'XGBoost', (array([ 10,  22,  26,  42,  43,  74,  86, 126, 127, 178, 207, 213, 229,\n",
      "       249, 265, 289], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.897959183673\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860545772685\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.102040816327\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00226244343891\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   7]\n",
      " [ 23  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       260\n",
      "          1       0.61      0.32      0.42        34\n",
      "\n",
      "avg / total       0.88      0.90      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([ 44,  78,  92, 103, 111, 134, 138, 174, 177, 185, 195, 197, 198,\n",
      "       226, 234, 254, 268, 271], dtype=int64),)]]\n",
      "[0.86054577268455779]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85031995429\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0975113122172\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   9]\n",
      " [ 24  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       260\n",
      "          1       0.53      0.29      0.38        34\n",
      "\n",
      "avg / total       0.87      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([ 44,  78,  92, 103, 111, 134, 138, 174, 177, 185, 195, 197, 198,\n",
      "       226, 234, 254, 268, 271], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 25,  26,  44,  50,  78, 103, 111, 122, 134, 138, 159, 185, 195,\n",
      "       197, 198, 219, 254, 268, 271], dtype=int64),)]]\n",
      "[0.86054577268455779, 0.8503199542899359]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([ 44,  78,  92, 103, 111, 134, 138, 174, 177, 185, 195, 197, 198,\n",
      "       226, 234, 254, 268, 271], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 25,  26,  44,  50,  78, 103, 111, 122, 134, 138, 159, 185, 195,\n",
      "       197, 198, 219, 254, 268, 271], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86054577268455779, 0.8503199542899359, 0.82738237456726249]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([ 44,  78,  92, 103, 111, 134, 138, 174, 177, 185, 195, 197, 198,\n",
      "       226, 234, 254, 268, 271], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 25,  26,  44,  50,  78, 103, 111, 122, 134, 138, 159, 185, 195,\n",
      "       197, 198, 219, 254, 268, 271], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88435374149659862, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86054577268455779, 0.8503199542899359, 0.82738237456726249, 0.82738237456726249]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([ 44,  78,  92, 103, 111, 134, 138, 174, 177, 185, 195, 197, 198,\n",
      "       226, 234, 254, 268, 271], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 25,  26,  44,  50,  78, 103, 111, 122, 134, 138, 159, 185, 195,\n",
      "       197, 198, 219, 254, 268, 271], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88435374149659862, 'KNN', (array([], dtype=int64),)], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86054577268455779, 0.8503199542899359, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.8299269481\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230542986425\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   9]\n",
      " [ 28   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       260\n",
      "          1       0.40      0.18      0.24        34\n",
      "\n",
      "avg / total       0.84      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([ 44,  78,  92, 103, 111, 134, 138, 174, 177, 185, 195, 197, 198,\n",
      "       226, 234, 254, 268, 271], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 25,  26,  44,  50,  78, 103, 111, 122, 134, 138, 159, 185, 195,\n",
      "       197, 198, 219, 254, 268, 271], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88435374149659862, 'KNN', (array([], dtype=int64),)], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([ 19,  27,  33,  46,  78,  96, 142, 166, 185, 197, 219, 268, 271,\n",
      "       276, 290], dtype=int64),)]]\n",
      "[0.86054577268455779, 0.8503199542899359, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249, 0.82992694809973988]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.901360544218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.850332980852\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0986394557823\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.035520361991\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   6]\n",
      " [ 23  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       260\n",
      "          1       0.65      0.32      0.43        34\n",
      "\n",
      "avg / total       0.89      0.90      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([ 44,  78,  92, 103, 111, 134, 138, 174, 177, 185, 195, 197, 198,\n",
      "       226, 234, 254, 268, 271], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 25,  26,  44,  50,  78, 103, 111, 122, 134, 138, 159, 185, 195,\n",
      "       197, 198, 219, 254, 268, 271], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88435374149659862, 'KNN', (array([], dtype=int64),)], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([ 19,  27,  33,  46,  78,  96, 142, 166, 185, 197, 219, 268, 271,\n",
      "       276, 290], dtype=int64),)], [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]]\n",
      "[0.86054577268455779, 0.8503199542899359, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249, 0.82992694809973988, 0.85033298085248044]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.874992955474\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.127847803961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   9]\n",
      " [ 40  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       241\n",
      "          1       0.59      0.25      0.35        53\n",
      "\n",
      "avg / total       0.81      0.83      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83333333333333337, 'LogisticRegression', (array([  0,   8,  17,  21,  55,  66,  76,  90, 101, 105, 111, 119, 133,\n",
      "       136, 138, 152, 165, 174, 207, 281, 286, 289], dtype=int64),)]]\n",
      "[0.87499295547403599]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846946755248\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.173882408205\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   9]\n",
      " [ 42  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       241\n",
      "          1       0.55      0.21      0.30        53\n",
      "\n",
      "avg / total       0.79      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83333333333333337, 'LogisticRegression', (array([  0,   8,  17,  21,  55,  66,  76,  90, 101, 105, 111, 119, 133,\n",
      "       136, 138, 152, 165, 174, 207, 281, 286, 289], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,   8,  21,  42,  55,  76,  90, 101, 102, 105, 111, 119, 122,\n",
      "       152, 165, 172, 207, 243, 281, 286], dtype=int64),)]]\n",
      "[0.87499295547403599, 0.84694675524817742]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83333333333333337, 'LogisticRegression', (array([  0,   8,  17,  21,  55,  66,  76,  90, 101, 105, 111, 119, 133,\n",
      "       136, 138, 152, 165, 174, 207, 281, 286, 289], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,   8,  21,  42,  55,  76,  90, 101, 102, 105, 111, 119, 122,\n",
      "       152, 165, 172, 207, 243, 281, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87499295547403599, 0.84694675524817742, 0.84353890355788297]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83333333333333337, 'LogisticRegression', (array([  0,   8,  17,  21,  55,  66,  76,  90, 101, 105, 111, 119, 133,\n",
      "       136, 138, 152, 165, 174, 207, 281, 286, 289], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,   8,  21,  42,  55,  76,  90, 101, 102, 105, 111, 119, 122,\n",
      "       152, 165, 172, 207, 243, 281, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87499295547403599, 0.84694675524817742, 0.84353890355788297, 0.84353890355788297]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83333333333333337, 'LogisticRegression', (array([  0,   8,  17,  21,  55,  66,  76,  90, 101, 105, 111, 119, 133,\n",
      "       136, 138, 152, 165, 174, 207, 281, 286, 289], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,   8,  21,  42,  55,  76,  90, 101, 102, 105, 111, 119, 122,\n",
      "       152, 165, 172, 207, 243, 281, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87499295547403599, 0.84694675524817742, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843508511934\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.24293431457\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[231  10]\n",
      " [ 44   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.90       241\n",
      "          1       0.47      0.17      0.25        53\n",
      "\n",
      "avg / total       0.77      0.82      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83333333333333337, 'LogisticRegression', (array([  0,   8,  17,  21,  55,  66,  76,  90, 101, 105, 111, 119, 133,\n",
      "       136, 138, 152, 165, 174, 207, 281, 286, 289], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,   8,  21,  42,  55,  76,  90, 101, 102, 105, 111, 119, 122,\n",
      "       152, 165, 172, 207, 243, 281, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81632653061224492, 'RandomForest', (array([ 13,  16,  55,  66,  90,  98, 101, 105, 116, 119, 120, 124, 172,\n",
      "       189, 207, 213, 232, 242, 282], dtype=int64),)]]\n",
      "[0.87499295547403599, 0.84694675524817742, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297, 0.8435085119344784]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86817717462\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.150865106083\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   5]\n",
      " [ 45   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       241\n",
      "          1       0.62      0.15      0.24        53\n",
      "\n",
      "avg / total       0.80      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83333333333333337, 'LogisticRegression', (array([  0,   8,  17,  21,  55,  66,  76,  90, 101, 105, 111, 119, 133,\n",
      "       136, 138, 152, 165, 174, 207, 281, 286, 289], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,   8,  21,  42,  55,  76,  90, 101, 102, 105, 111, 119, 122,\n",
      "       152, 165, 172, 207, 243, 281, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81632653061224492, 'RandomForest', (array([ 13,  16,  55,  66,  90,  98, 101, 105, 116, 119, 120, 124, 172,\n",
      "       189, 207, 213, 232, 242, 282], dtype=int64),)], [0.82993197278911568, 'XGBoost', (array([ 55,  66,  90,  92, 101, 116, 119, 124, 133, 136, 168, 207, 286], dtype=int64),)]]\n",
      "[0.87499295547403599, 0.84694675524817742, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297, 0.8435085119344784, 0.868177174620263]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862235601177\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0351153525433\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   6]\n",
      " [ 32  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       251\n",
      "          1       0.65      0.26      0.37        43\n",
      "\n",
      "avg / total       0.85      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  2,  35,  51,  54,  58,  77,  97, 101, 116, 127, 147, 165, 173,\n",
      "       185, 247, 259, 272], dtype=int64),)]]\n",
      "[0.86223560117707887]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862246452957\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.116834985639\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   7]\n",
      " [ 34   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       251\n",
      "          1       0.56      0.21      0.31        43\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  2,  35,  51,  54,  58,  77,  97, 101, 116, 127, 147, 165, 173,\n",
      "       185, 247, 259, 272], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 35,  36,  58,  68,  73,  97, 101, 127, 130, 131, 158, 165, 194,\n",
      "       198, 235, 259], dtype=int64),)]]\n",
      "[0.86223560117707887, 0.86224645295666669]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225794496433\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   2]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       251\n",
      "          1       0.00      0.00      0.00        43\n",
      "\n",
      "avg / total       0.73      0.85      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  2,  35,  51,  54,  58,  77,  97, 101, 116, 127, 147, 165, 173,\n",
      "       185, 247, 259, 272], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 35,  36,  58,  68,  73,  97, 101, 127, 130, 131, 158, 165, 194,\n",
      "       198, 235, 259], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([ 95, 244], dtype=int64),)]]\n",
      "[0.86223560117707887, 0.86224645295666669, 0.83503546899454539]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  2,  35,  51,  54,  58,  77,  97, 101, 116, 127, 147, 165, 173,\n",
      "       185, 247, 259, 272], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 35,  36,  58,  68,  73,  97, 101, 127, 130, 131, 158, 165, 194,\n",
      "       198, 235, 259], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([ 95, 244], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86223560117707887, 0.86224645295666669, 0.83503546899454539, 0.83503546899454539]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  2,  35,  51,  54,  58,  77,  97, 101, 116, 127, 147, 165, 173,\n",
      "       185, 247, 259, 272], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 35,  36,  58,  68,  73,  97, 101, 127, 130, 131, 158, 165, 194,\n",
      "       198, 235, 259], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([ 95, 244], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86223560117707887, 0.86224645295666669, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842660346581\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.28027425183\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241  10]\n",
      " [ 37   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       251\n",
      "          1       0.38      0.14      0.20        43\n",
      "\n",
      "avg / total       0.79      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  2,  35,  51,  54,  58,  77,  97, 101, 116, 127, 147, 165, 173,\n",
      "       185, 247, 259, 272], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 35,  36,  58,  68,  73,  97, 101, 127, 130, 131, 158, 165, 194,\n",
      "       198, 235, 259], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([ 95, 244], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84013605442176875, 'RandomForest', (array([ 32,  35,  36,  54,  73,  77,  94,  95,  98, 100, 130, 158, 191,\n",
      "       258, 259, 260], dtype=int64),)]]\n",
      "[0.86223560117707887, 0.86224645295666669, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.84266034658138056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.876693602543\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225794496433\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   9]\n",
      " [ 36   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       251\n",
      "          1       0.44      0.16      0.24        43\n",
      "\n",
      "avg / total       0.81      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  2,  35,  51,  54,  58,  77,  97, 101, 116, 127, 147, 165, 173,\n",
      "       185, 247, 259, 272], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 35,  36,  58,  68,  73,  97, 101, 127, 130, 131, 158, 165, 194,\n",
      "       198, 235, 259], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([ 95, 244], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84013605442176875, 'RandomForest', (array([ 32,  35,  36,  54,  73,  77,  94,  95,  98, 100, 130, 158, 191,\n",
      "       258, 259, 260], dtype=int64),)], [0.84693877551020413, 'XGBoost', (array([ 35,  36,  50,  54,  58,  73,  77,  87,  94, 100, 101, 123, 127,\n",
      "       158, 165, 194], dtype=int64),)]]\n",
      "[0.86223560117707887, 0.86224645295666669, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.84266034658138056, 0.8766936025433516]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862244897959\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0291834002677\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   8]\n",
      " [ 29  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       249\n",
      "          1       0.67      0.36      0.46        45\n",
      "\n",
      "avg / total       0.86      0.87      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 10,  11,  17,  21,  53,  54,  59,  61,  83,  98, 133, 141, 156,\n",
      "       161, 165, 188, 191, 202, 210, 220, 223, 226, 259, 276], dtype=int64),)]]\n",
      "[0.86224489795918358]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.04953145917\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   2]\n",
      " [ 38   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       249\n",
      "          1       0.78      0.16      0.26        45\n",
      "\n",
      "avg / total       0.85      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 10,  11,  17,  21,  53,  54,  59,  61,  83,  98, 133, 141, 156,\n",
      "       161, 165, 188, 191, 202, 210, 220, 223, 226, 259, 276], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  53,  83, 141, 161, 191, 202, 259, 276], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.85034013605442171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 10,  11,  17,  21,  53,  54,  59,  61,  83,  98, 133, 141, 156,\n",
      "       161, 165, 188, 191, 202, 210, 220, 223, 226, 259, 276], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  53,  83, 141, 161, 191, 202, 259, 276], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.85034013605442171, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 10,  11,  17,  21,  53,  54,  59,  61,  83,  98, 133, 141, 156,\n",
      "       161, 165, 188, 191, 202, 210, 220, 223, 226, 259, 276], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  53,  83, 141, 161, 191, 202, 259, 276], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.85034013605442171, 0.83673469387755117, 0.83673469387755117]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 10,  11,  17,  21,  53,  54,  59,  61,  83,  98, 133, 141, 156,\n",
      "       161, 165, 188, 191, 202, 210, 220, 223, 226, 259, 276], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  53,  83, 141, 161, 191, 202, 259, 276], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.85034013605442171, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0232931726908\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   2]\n",
      " [ 37   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       249\n",
      "          1       0.80      0.18      0.29        45\n",
      "\n",
      "avg / total       0.86      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 10,  11,  17,  21,  53,  54,  59,  61,  83,  98, 133, 141, 156,\n",
      "       161, 165, 188, 191, 202, 210, 220, 223, 226, 259, 276], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  53,  83, 141, 161, 191, 202, 259, 276], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86734693877551017, 'RandomForest', (array([ 11,  21,  59,  61,  83,  98, 161, 223, 259, 276], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.85034013605442171, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83418367346938771]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.102008032129\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   6]\n",
      " [ 36   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       249\n",
      "          1       0.60      0.20      0.30        45\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 10,  11,  17,  21,  53,  54,  59,  61,  83,  98, 133, 141, 156,\n",
      "       161, 165, 188, 191, 202, 210, 220, 223, 226, 259, 276], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  53,  83, 141, 161, 191, 202, 259, 276], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86734693877551017, 'RandomForest', (array([ 11,  21,  59,  61,  83,  98, 161, 223, 259, 276], dtype=int64),)], [0.8571428571428571, 'XGBoost', (array([ 10,  21,  33,  61,  69,  83,  98, 133, 141, 161, 188, 202, 223,\n",
      "       259, 276], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.85034013605442171, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83418367346938771, 0.8571428571428571]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.864795918367\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.228840125392\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247  14]\n",
      " [ 22  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.93       261\n",
      "          1       0.44      0.33      0.38        33\n",
      "\n",
      "avg / total       0.86      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 13,  15,  59,  67,  71,  75,  82,  90, 108, 116, 129, 131, 136,\n",
      "       147, 155, 165, 170, 183, 185, 224, 232, 242, 258, 274, 283], dtype=int64),)]]\n",
      "[0.86479591836734693]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   8]\n",
      " [ 25   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       261\n",
      "          1       0.50      0.24      0.33        33\n",
      "\n",
      "avg / total       0.86      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 13,  15,  59,  67,  71,  75,  82,  90, 108, 116, 129, 131, 136,\n",
      "       147, 155, 165, 170, 183, 185, 224, 232, 242, 258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([  4,  13,  59,  67,  71,  75, 108, 116, 155, 165, 183, 185, 224,\n",
      "       258, 274, 283], dtype=int64),)]]\n",
      "[0.86479591836734693, 0.84353741496598644]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 13,  15,  59,  67,  71,  75,  82,  90, 108, 116, 129, 131, 136,\n",
      "       147, 155, 165, 170, 183, 185, 224, 232, 242, 258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([  4,  13,  59,  67,  71,  75, 108, 116, 155, 165, 183, 185, 224,\n",
      "       258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86479591836734693, 0.84353741496598644, 0.82653061224489799]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 13,  15,  59,  67,  71,  75,  82,  90, 108, 116, 129, 131, 136,\n",
      "       147, 155, 165, 170, 183, 185, 224, 232, 242, 258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([  4,  13,  59,  67,  71,  75, 108, 116, 155, 165, 183, 185, 224,\n",
      "       258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88775510204081631, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86479591836734693, 0.84353741496598644, 0.82653061224489799, 0.82653061224489799]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 13,  15,  59,  67,  71,  75,  82,  90, 108, 116, 129, 131, 136,\n",
      "       147, 155, 165, 170, 183, 185, 224, 232, 242, 258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([  4,  13,  59,  67,  71,  75, 108, 116, 155, 165, 183, 185, 224,\n",
      "       258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88775510204081631, 'KNN', (array([], dtype=int64),)], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86479591836734693, 0.84353741496598644, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.160571229537\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[255   6]\n",
      " [ 28   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       261\n",
      "          1       0.45      0.15      0.23        33\n",
      "\n",
      "avg / total       0.85      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 13,  15,  59,  67,  71,  75,  82,  90, 108, 116, 129, 131, 136,\n",
      "       147, 155, 165, 170, 183, 185, 224, 232, 242, 258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([  4,  13,  59,  67,  71,  75, 108, 116, 155, 165, 183, 185, 224,\n",
      "       258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88775510204081631, 'KNN', (array([], dtype=int64),)], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.88435374149659862, 'RandomForest', (array([ 34,  56,  57,  59,  67,  75,  90,  97, 134, 183, 241], dtype=int64),)]]\n",
      "[0.86479591836734693, 0.84353741496598644, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799, 0.82993197278911568]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.160571229537\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   9]\n",
      " [ 25   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       261\n",
      "          1       0.47      0.24      0.32        33\n",
      "\n",
      "avg / total       0.86      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 13,  15,  59,  67,  71,  75,  82,  90, 108, 116, 129, 131, 136,\n",
      "       147, 155, 165, 170, 183, 185, 224, 232, 242, 258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([  4,  13,  59,  67,  71,  75, 108, 116, 155, 165, 183, 185, 224,\n",
      "       258, 274, 283], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88775510204081631, 'KNN', (array([], dtype=int64),)], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.88435374149659862, 'RandomForest', (array([ 34,  56,  57,  59,  67,  75,  90,  97, 134, 183, 241], dtype=int64),)], [0.88435374149659862, 'XGBoost', (array([ 13,  15,  27,  34,  57,  59,  67,  75,  82, 136, 143, 155, 183,\n",
      "       185, 210, 224, 268], dtype=int64),)]]\n",
      "[0.86479591836734693, 0.84353741496598644, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799, 0.82993197278911568, 0.85714285714285721]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863077286452\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0955882352941\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   0]\n",
      " [ 41  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       238\n",
      "          1       1.00      0.27      0.42        56\n",
      "\n",
      "avg / total       0.88      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 12,  22,  25,  42,  51,  68,  78,  79,  90,  94, 105, 140, 171,\n",
      "       242, 254], dtype=int64),)]]\n",
      "[0.86307728645169757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851181146206\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.169117647059\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   0]\n",
      " [ 53   3]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       238\n",
      "          1       1.00      0.05      0.10        56\n",
      "\n",
      "avg / total       0.85      0.82      0.75       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 12,  22,  25,  42,  51,  68,  78,  79,  90,  94, 105, 140, 171,\n",
      "       242, 254], dtype=int64),)], [0.81972789115646261, 'SelectKBest+LR', (array([ 25,  68, 140], dtype=int64),)]]\n",
      "[0.86307728645169757, 0.85118114620557817]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846089935034\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.235294117647\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   0]\n",
      " [ 56   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89       238\n",
      "\n",
      "avg / total       0.81      1.00      0.89       238\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 12,  22,  25,  42,  51,  68,  78,  79,  90,  94, 105, 140, 171,\n",
      "       242, 254], dtype=int64),)], [0.81972789115646261, 'SelectKBest+LR', (array([ 25,  68, 140], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86307728645169757, 0.85118114620557817, 0.84608993503364394]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846089935034\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.235294117647\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   0]\n",
      " [ 56   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89       238\n",
      "\n",
      "avg / total       0.81      1.00      0.89       238\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 12,  22,  25,  42,  51,  68,  78,  79,  90,  94, 105, 140, 171,\n",
      "       242, 254], dtype=int64),)], [0.81972789115646261, 'SelectKBest+LR', (array([ 25,  68, 140], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80952380952380953, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86307728645169757, 0.85118114620557817, 0.84608993503364394, 0.84608993503364394]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846089935034\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.235294117647\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   0]\n",
      " [ 56   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89       238\n",
      "\n",
      "avg / total       0.81      1.00      0.89       238\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 12,  22,  25,  42,  51,  68,  78,  79,  90,  94, 105, 140, 171,\n",
      "       242, 254], dtype=int64),)], [0.81972789115646261, 'SelectKBest+LR', (array([ 25,  68, 140], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80952380952380953, 'KNN', (array([], dtype=int64),)], [0.80952380952380953, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86307728645169757, 0.85118114620557817, 0.84608993503364394, 0.84608993503364394, 0.84608993503364394]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833306594017\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0588235294118\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[231   7]\n",
      " [ 41  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91       238\n",
      "          1       0.68      0.27      0.38        56\n",
      "\n",
      "avg / total       0.82      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 12,  22,  25,  42,  51,  68,  78,  79,  90,  94, 105, 140, 171,\n",
      "       242, 254], dtype=int64),)], [0.81972789115646261, 'SelectKBest+LR', (array([ 25,  68, 140], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80952380952380953, 'KNN', (array([], dtype=int64),)], [0.80952380952380953, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 45,  51,  52,  68,  78, 100, 105, 135, 140, 169, 170, 182, 210,\n",
      "       220, 229, 231, 235, 242, 247, 259, 282, 285], dtype=int64),)]]\n",
      "[0.86307728645169757, 0.85118114620557817, 0.84608993503364394, 0.84608993503364394, 0.84608993503364394, 0.83330659401718421]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861393938038\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.25\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   3]\n",
      " [ 31  25]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       238\n",
      "          1       0.89      0.45      0.60        56\n",
      "\n",
      "avg / total       0.89      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 12,  22,  25,  42,  51,  68,  78,  79,  90,  94, 105, 140, 171,\n",
      "       242, 254], dtype=int64),)], [0.81972789115646261, 'SelectKBest+LR', (array([ 25,  68, 140], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80952380952380953, 'KNN', (array([], dtype=int64),)], [0.80952380952380953, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 45,  51,  52,  68,  78, 100, 105, 135, 140, 169, 170, 182, 210,\n",
      "       220, 229, 231, 235, 242, 247, 259, 282, 285], dtype=int64),)], [0.88435374149659862, 'XGBoost', (array([  6,  12,  25,  42,  45,  51,  52,  59,  68,  78,  81,  90, 105,\n",
      "       111, 140, 142, 157, 169, 170, 182, 210, 231, 235, 242, 255, 259,\n",
      "       282, 285], dtype=int64),)]]\n",
      "[0.86307728645169757, 0.85118114620557817, 0.84608993503364394, 0.84608993503364394, 0.84608993503364394, 0.83330659401718421, 0.86139393803765552]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858853802612\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0690909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   8]\n",
      " [ 32  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       250\n",
      "          1       0.60      0.27      0.37        44\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 27,  34,  42,  66,  75,  83,  95,  97, 112, 125, 142, 144, 153,\n",
      "       154, 182, 207, 228, 236, 243, 258], dtype=int64),)]]\n",
      "[0.85885380261187338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862237809163\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0958181818182\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   6]\n",
      " [ 35   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       250\n",
      "          1       0.60      0.20      0.31        44\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 27,  34,  42,  66,  75,  83,  95,  97, 112, 125, 142, 144, 153,\n",
      "       154, 182, 207, 228, 236, 243, 258], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 10,  34,  66,  75,  83,  95, 112, 144, 152, 153, 182, 207, 224,\n",
      "       236, 243], dtype=int64),)]]\n",
      "[0.85885380261187338, 0.86223780916282877]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 27,  34,  42,  66,  75,  83,  95,  97, 112, 125, 142, 144, 153,\n",
      "       154, 182, 207, 228, 236, 243, 258], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 10,  34,  66,  75,  83,  95, 112, 144, 152, 153, 182, 207, 224,\n",
      "       236, 243], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85885380261187338, 0.86223780916282877, 0.83588580913059995]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 27,  34,  42,  66,  75,  83,  95,  97, 112, 125, 142, 144, 153,\n",
      "       154, 182, 207, 228, 236, 243, 258], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 10,  34,  66,  75,  83,  95, 112, 144, 152, 153, 182, 207, 224,\n",
      "       236, 243], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85885380261187338, 0.86223780916282877, 0.83588580913059995, 0.83588580913059995]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 27,  34,  42,  66,  75,  83,  95,  97, 112, 125, 142, 144, 153,\n",
      "       154, 182, 207, 228, 236, 243, 258], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 10,  34,  66,  75,  83,  95, 112, 144, 152, 153, 182, 207, 224,\n",
      "       236, 243], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85885380261187338, 0.86223780916282877, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835070143778\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   7]\n",
      " [ 37   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       250\n",
      "          1       0.50      0.16      0.24        44\n",
      "\n",
      "avg / total       0.81      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 27,  34,  42,  66,  75,  83,  95,  97, 112, 125, 142, 144, 153,\n",
      "       154, 182, 207, 228, 236, 243, 258], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 10,  34,  66,  75,  83,  95, 112, 144, 152, 153, 182, 207, 224,\n",
      "       236, 243], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 10,  14,  30,  47,  50,  83,  95, 126, 145, 153, 154, 175, 182, 224], dtype=int64),)]]\n",
      "[0.85885380261187338, 0.86223780916282877, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.83507014377827693]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867355062392\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0958181818182\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   6]\n",
      " [ 35   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       250\n",
      "          1       0.60      0.20      0.31        44\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 27,  34,  42,  66,  75,  83,  95,  97, 112, 125, 142, 144, 153,\n",
      "       154, 182, 207, 228, 236, 243, 258], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 10,  34,  66,  75,  83,  95, 112, 144, 152, 153, 182, 207, 224,\n",
      "       236, 243], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 10,  14,  30,  47,  50,  83,  95, 126, 145, 153, 154, 175, 182, 224], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([ 10,  14,  30,  66,  69,  95, 112, 125, 142, 153, 159, 175, 224,\n",
      "       226, 243], dtype=int64),)]]\n",
      "[0.85885380261187338, 0.86223780916282877, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.83507014377827693, 0.86735506239225424]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853743040529\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0654799745709\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   4]\n",
      " [ 36  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       242\n",
      "          1       0.80      0.31      0.44        52\n",
      "\n",
      "avg / total       0.86      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 16,  21,  23,  93, 120, 127, 165, 175, 192, 194, 204, 222, 226,\n",
      "       232, 234, 245, 253, 261, 273, 280], dtype=int64),)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85374304052852479]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85118983427\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0046090273363\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   3]\n",
      " [ 40  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       242\n",
      "          1       0.80      0.23      0.36        52\n",
      "\n",
      "avg / total       0.85      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 16,  21,  23,  93, 120, 127, 165, 175, 192, 194, 204, 222, 226,\n",
      "       232, 234, 245, 253, 261, 273, 280], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 16,  23,  38,  93, 120, 127, 165, 175, 192, 204, 230, 232, 245,\n",
      "       253, 261], dtype=int64),)]]\n",
      "[0.85374304052852479, 0.8511898342698071]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 16,  21,  23,  93, 120, 127, 165, 175, 192, 194, 204, 222, 226,\n",
      "       232, 234, 245, 253, 261, 273, 280], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 16,  23,  38,  93, 120, 127, 165, 175, 192, 204, 230, 232, 245,\n",
      "       253, 261], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85374304052852479, 0.8511898342698071, 0.84268856342182852]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 16,  21,  23,  93, 120, 127, 165, 175, 192, 194, 204, 222, 226,\n",
      "       232, 234, 245, 253, 261, 273, 280], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 16,  23,  38,  93, 120, 127, 165, 175, 192, 204, 230, 232, 245,\n",
      "       253, 261], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85374304052852479, 0.8511898342698071, 0.84268856342182852, 0.84268856342182852]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 16,  21,  23,  93, 120, 127, 165, 175, 192, 194, 204, 222, 226,\n",
      "       232, 234, 245, 253, 261, 273, 280], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 16,  23,  38,  93, 120, 127, 165, 175, 192, 204, 230, 232, 245,\n",
      "       253, 261], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85374304052852479, 0.8511898342698071, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.837593002684\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.144787031151\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   6]\n",
      " [ 43   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       242\n",
      "          1       0.60      0.17      0.27        52\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 16,  21,  23,  93, 120, 127, 165, 175, 192, 194, 204, 222, 226,\n",
      "       232, 234, 245, 253, 261, 273, 280], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 16,  23,  38,  93, 120, 127, 165, 175, 192, 204, 230, 232, 245,\n",
      "       253, 261], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83333333333333337, 'RandomForest', (array([  2,   7,  33,  38,  93, 127, 165, 192, 216, 230, 234, 257, 258,\n",
      "       261, 289], dtype=int64),)]]\n",
      "[0.85374304052852479, 0.8511898342698071, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.83759300268398107]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862257315804\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.135568976478\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   2]\n",
      " [ 35  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       242\n",
      "          1       0.89      0.33      0.48        52\n",
      "\n",
      "avg / total       0.88      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 16,  21,  23,  93, 120, 127, 165, 175, 192, 194, 204, 222, 226,\n",
      "       232, 234, 245, 253, 261, 273, 280], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 16,  23,  38,  93, 120, 127, 165, 175, 192, 204, 230, 232, 245,\n",
      "       253, 261], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83333333333333337, 'RandomForest', (array([  2,   7,  33,  38,  93, 127, 165, 192, 216, 230, 234, 257, 258,\n",
      "       261, 289], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([  7,  23,  38,  75,  93, 120, 127, 146, 165, 175, 213, 222, 226,\n",
      "       232, 234, 245, 261, 280, 292], dtype=int64),)]]\n",
      "[0.85374304052852479, 0.8511898342698071, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.83759300268398107, 0.86225731580385212]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869023154123\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0457987738911\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230   5]\n",
      " [ 40  19]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       235\n",
      "          1       0.79      0.32      0.46        59\n",
      "\n",
      "avg / total       0.84      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84693877551020413, 'LogisticRegression', (array([  1,   5,   8,  14,  32,  59,  63, 110, 148, 149, 161, 162, 172,\n",
      "       180, 187, 211, 229, 231, 238, 253, 264, 272, 290, 292], dtype=int64),)]]\n",
      "[0.8690231541228064]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.80612244898\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857975201365\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.19387755102\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.208654886405\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   0]\n",
      " [ 57   2]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       235\n",
      "          1       1.00      0.03      0.07        59\n",
      "\n",
      "avg / total       0.84      0.81      0.73       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  1,   5,   8,  14,  32,  59,  63, 110, 148, 149, 161, 162, 172,\n",
      "       180, 187, 211, 229, 231, 238, 253, 264, 272, 290, 292], dtype=int64),)], [0.80612244897959184, 'SelectKBest+LR', (array([148, 180], dtype=int64),)]]\n",
      "[0.8690231541228064, 0.85797520136498007]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.799319727891\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848640966509\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.200680272109\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.251063829787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   0]\n",
      " [ 59   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       235\n",
      "\n",
      "avg / total       0.80      1.00      0.89       235\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  1,   5,   8,  14,  32,  59,  63, 110, 148, 149, 161, 162, 172,\n",
      "       180, 187, 211, 229, 231, 238, 253, 264, 272, 290, 292], dtype=int64),)], [0.80612244897959184, 'SelectKBest+LR', (array([148, 180], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8690231541228064, 0.85797520136498007, 0.8486409665094049]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.799319727891\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848640966509\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.200680272109\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.251063829787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   0]\n",
      " [ 59   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       235\n",
      "\n",
      "avg / total       0.80      1.00      0.89       235\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  1,   5,   8,  14,  32,  59,  63, 110, 148, 149, 161, 162, 172,\n",
      "       180, 187, 211, 229, 231, 238, 253, 264, 272, 290, 292], dtype=int64),)], [0.80612244897959184, 'SelectKBest+LR', (array([148, 180], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79931972789115646, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8690231541228064, 0.85797520136498007, 0.8486409665094049, 0.8486409665094049]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.799319727891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848640966509\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.200680272109\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.251063829787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   0]\n",
      " [ 59   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       235\n",
      "\n",
      "avg / total       0.80      1.00      0.89       235\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  1,   5,   8,  14,  32,  59,  63, 110, 148, 149, 161, 162, 172,\n",
      "       180, 187, 211, 229, 231, 238, 253, 264, 272, 290, 292], dtype=int64),)], [0.80612244897959184, 'SelectKBest+LR', (array([148, 180], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79931972789115646, 'KNN', (array([], dtype=int64),)], [0.79931972789115646, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8690231541228064, 0.85797520136498007, 0.8486409665094049, 0.8486409665094049, 0.8486409665094049]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.855454550445\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.187450414713\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[226   9]\n",
      " [ 47  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.96      0.89       235\n",
      "          1       0.57      0.20      0.30        59\n",
      "\n",
      "avg / total       0.78      0.81      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  1,   5,   8,  14,  32,  59,  63, 110, 148, 149, 161, 162, 172,\n",
      "       180, 187, 211, 229, 231, 238, 253, 264, 272, 290, 292], dtype=int64),)], [0.80612244897959184, 'SelectKBest+LR', (array([148, 180], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79931972789115646, 'KNN', (array([], dtype=int64),)], [0.79931972789115646, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.80952380952380953, 'RandomForest', (array([  1,   5,  14,  28,  32,  63,  82, 107, 126, 148, 158, 170, 180,\n",
      "       239, 266, 269, 271, 272, 276, 282, 290], dtype=int64),)]]\n",
      "[0.8690231541228064, 0.85797520136498007, 0.8486409665094049, 0.8486409665094049, 0.8486409665094049, 0.85545455044502594]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867339827844\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0245943021998\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[231   4]\n",
      " [ 42  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       235\n",
      "          1       0.81      0.29      0.43        59\n",
      "\n",
      "avg / total       0.84      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  1,   5,   8,  14,  32,  59,  63, 110, 148, 149, 161, 162, 172,\n",
      "       180, 187, 211, 229, 231, 238, 253, 264, 272, 290, 292], dtype=int64),)], [0.80612244897959184, 'SelectKBest+LR', (array([148, 180], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79931972789115646, 'KNN', (array([], dtype=int64),)], [0.79931972789115646, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.80952380952380953, 'RandomForest', (array([  1,   5,  14,  28,  32,  63,  82, 107, 126, 148, 158, 170, 180,\n",
      "       239, 266, 269, 271, 272, 276, 282, 290], dtype=int64),)], [0.84353741496598644, 'XGBoost', (array([  5,   8,  28,  59,  63,  66, 110, 123, 126, 139, 148, 158, 161,\n",
      "       180, 187, 211, 239, 253, 264, 290, 292], dtype=int64),)]]\n",
      "[0.8690231541228064, 0.85797520136498007, 0.8486409665094049, 0.8486409665094049, 0.8486409665094049, 0.85545455044502594, 0.8673398278439598]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858843537415\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0816599732262\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   6]\n",
      " [ 29  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       249\n",
      "          1       0.73      0.36      0.48        45\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 13,  35,  44,  57,  75,  78,  80,  85,  94, 102, 121, 126, 128,\n",
      "       134, 152, 169, 198, 213, 238, 240, 264, 291], dtype=int64),)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.858843537414966]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.847789115646\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00294511378849\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   6]\n",
      " [ 32  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       249\n",
      "          1       0.68      0.29      0.41        45\n",
      "\n",
      "avg / total       0.85      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 13,  35,  44,  57,  75,  78,  80,  85,  94, 102, 121, 126, 128,\n",
      "       134, 152, 169, 198, 213, 238, 240, 264, 291], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 13,  35,  44,  75,  80,  85,  94, 111, 126, 128, 134, 169, 213,\n",
      "       238, 240, 246, 264, 270, 291], dtype=int64),)]]\n",
      "[0.858843537414966, 0.84778911564625847]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 13,  35,  44,  57,  75,  78,  80,  85,  94, 102, 121, 126, 128,\n",
      "       134, 152, 169, 198, 213, 238, 240, 264, 291], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 13,  35,  44,  75,  80,  85,  94, 111, 126, 128, 134, 169, 213,\n",
      "       238, 240, 246, 264, 270, 291], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.858843537414966, 0.84778911564625847, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 13,  35,  44,  57,  75,  78,  80,  85,  94, 102, 121, 126, 128,\n",
      "       134, 152, 169, 198, 213, 238, 240, 264, 291], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 13,  35,  44,  75,  80,  85,  94, 111, 126, 128, 134, 169, 213,\n",
      "       238, 240, 246, 264, 270, 291], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.858843537414966, 0.84778911564625847, 0.83673469387755117, 0.83673469387755117]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 13,  35,  44,  57,  75,  78,  80,  85,  94, 102, 121, 126, 128,\n",
      "       134, 152, 169, 198, 213, 238, 240, 264, 291], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 13,  35,  44,  75,  80,  85,  94, 111, 126, 128, 134, 169, 213,\n",
      "       238, 240, 246, 264, 270, 291], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.858843537414966, 0.84778911564625847, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.831632653061\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.04953145917\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   5]\n",
      " [ 35  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       249\n",
      "          1       0.67      0.22      0.33        45\n",
      "\n",
      "avg / total       0.84      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 13,  35,  44,  57,  75,  78,  80,  85,  94, 102, 121, 126, 128,\n",
      "       134, 152, 169, 198, 213, 238, 240, 264, 291], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 13,  35,  44,  75,  80,  85,  94, 111, 126, 128, 134, 169, 213,\n",
      "       238, 240, 246, 264, 270, 291], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 75,  94,  95, 104, 111, 128, 134, 136, 148, 198, 199, 207, 238,\n",
      "       251, 281], dtype=int64),)]]\n",
      "[0.858843537414966, 0.84778911564625847, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83163265306122447]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854591836735\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.107898259705\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   4]\n",
      " [ 30  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.94       249\n",
      "          1       0.79      0.33      0.47        45\n",
      "\n",
      "avg / total       0.88      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 13,  35,  44,  57,  75,  78,  80,  85,  94, 102, 121, 126, 128,\n",
      "       134, 152, 169, 198, 213, 238, 240, 264, 291], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 13,  35,  44,  75,  80,  85,  94, 111, 126, 128, 134, 169, 213,\n",
      "       238, 240, 246, 264, 270, 291], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 75,  94,  95, 104, 111, 128, 134, 136, 148, 198, 199, 207, 238,\n",
      "       251, 281], dtype=int64),)], [0.88435374149659862, 'XGBoost', (array([ 11,  35,  72,  80,  85,  94,  95, 104, 111, 126, 127, 134, 136,\n",
      "       140, 169, 198, 213, 240, 264], dtype=int64),)]]\n",
      "[0.858843537414966, 0.84778911564625847, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83163265306122447, 0.85459183673469397]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859693877551\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0291834002677\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   9]\n",
      " [ 28  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       249\n",
      "          1       0.65      0.38      0.48        45\n",
      "\n",
      "avg / total       0.86      0.87      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 55,  59,  73,  86, 102, 103, 132, 133, 136, 137, 149, 164, 166,\n",
      "       167, 175, 176, 183, 192, 209, 229, 231, 246, 247, 266, 277, 289], dtype=int64),)]]\n",
      "[0.85969387755102034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852040816327\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.128246318608\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 40   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       249\n",
      "          1       0.62      0.11      0.19        45\n",
      "\n",
      "avg / total       0.82      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 55,  59,  73,  86, 102, 103, 132, 133, 136, 137, 149, 164, 166,\n",
      "       167, 175, 176, 183, 192, 209, 229, 231, 246, 247, 266, 277, 289], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([164, 166, 175, 176, 209, 246, 247, 280], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85204081632653061]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 55,  59,  73,  86, 102, 103, 132, 133, 136, 137, 149, 164, 166,\n",
      "       167, 175, 176, 183, 192, 209, 229, 231, 246, 247, 266, 277, 289], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([164, 166, 175, 176, 209, 246, 247, 280], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85204081632653061, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 55,  59,  73,  86, 102, 103, 132, 133, 136, 137, 149, 164, 166,\n",
      "       167, 175, 176, 183, 192, 209, 229, 231, 246, 247, 266, 277, 289], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([164, 166, 175, 176, 209, 246, 247, 280], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85204081632653061, 0.83673469387755117, 0.83673469387755117]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 55,  59,  73,  86, 102, 103, 132, 133, 136, 137, 149, 164, 166,\n",
      "       167, 175, 176, 183, 192, 209, 229, 231, 246, 247, 266, 277, 289], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([164, 166, 175, 176, 209, 246, 247, 280], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85204081632653061, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846088435374\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   8]\n",
      " [ 37   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.91       249\n",
      "          1       0.50      0.18      0.26        45\n",
      "\n",
      "avg / total       0.81      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 55,  59,  73,  86, 102, 103, 132, 133, 136, 137, 149, 164, 166,\n",
      "       167, 175, 176, 183, 192, 209, 229, 231, 246, 247, 266, 277, 289], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([164, 166, 175, 176, 209, 246, 247, 280], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  3,  17,  55,  93, 128, 154, 160, 172, 175, 190, 209, 231, 246,\n",
      "       266, 277, 279], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85204081632653061, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.84608843537414968]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0232931726908\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   7]\n",
      " [ 32  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.93       249\n",
      "          1       0.65      0.29      0.40        45\n",
      "\n",
      "avg / total       0.85      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 55,  59,  73,  86, 102, 103, 132, 133, 136, 137, 149, 164, 166,\n",
      "       167, 175, 176, 183, 192, 209, 229, 231, 246, 247, 266, 277, 289], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([164, 166, 175, 176, 209, 246, 247, 280], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  3,  17,  55,  93, 128, 154, 160, 172, 175, 190, 209, 231, 246,\n",
      "       266, 277, 279], dtype=int64),)], [0.86734693877551017, 'XGBoost', (array([ 17,  50,  55,  59,  68, 122, 136, 160, 161, 175, 183, 209, 229,\n",
      "       231, 239, 246, 247, 266, 277, 292], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85204081632653061, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.84608843537414968, 0.87074829931972797]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869899591654\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0219688542825\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230   2]\n",
      " [ 48  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       232\n",
      "          1       0.88      0.23      0.36        62\n",
      "\n",
      "avg / total       0.84      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  4,  40,  49,  62,  65,  89, 116, 127, 140, 154, 179, 183, 186,\n",
      "       194, 229, 293], dtype=int64),)]]\n",
      "[0.86989959165434072]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.802721088435\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863945002716\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.197278911565\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[229   3]\n",
      " [ 55   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.99      0.89       232\n",
      "          1       0.70      0.11      0.19        62\n",
      "\n",
      "avg / total       0.78      0.80      0.74       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  4,  40,  49,  62,  65,  89, 116, 127, 140, 154, 179, 183, 186,\n",
      "       194, 229, 293], dtype=int64),)], [0.80272108843537415, 'SelectKBest+LR', (array([ 40,  62,  65, 125, 154, 179, 235, 274, 285, 293], dtype=int64),)]]\n",
      "[0.86989959165434072, 0.86394500271620978]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.789115646259\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851191997985\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.210884353741\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.26724137931\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   0]\n",
      " [ 62   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       232\n",
      "\n",
      "avg / total       0.79      1.00      0.88       232\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  4,  40,  49,  62,  65,  89, 116, 127, 140, 154, 179, 183, 186,\n",
      "       194, 229, 293], dtype=int64),)], [0.80272108843537415, 'SelectKBest+LR', (array([ 40,  62,  65, 125, 154, 179, 235, 274, 285, 293], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86989959165434072, 0.86394500271620978, 0.85119199798516598]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.789115646259\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851191997985\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.210884353741\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.26724137931\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   0]\n",
      " [ 62   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       232\n",
      "\n",
      "avg / total       0.79      1.00      0.88       232\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  4,  40,  49,  62,  65,  89, 116, 127, 140, 154, 179, 183, 186,\n",
      "       194, 229, 293], dtype=int64),)], [0.80272108843537415, 'SelectKBest+LR', (array([ 40,  62,  65, 125, 154, 179, 235, 274, 285, 293], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78911564625850339, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86989959165434072, 0.86394500271620978, 0.85119199798516598, 0.85119199798516598]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.789115646259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851191997985\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.210884353741\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.26724137931\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   0]\n",
      " [ 62   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       232\n",
      "\n",
      "avg / total       0.79      1.00      0.88       232\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  4,  40,  49,  62,  65,  89, 116, 127, 140, 154, 179, 183, 186,\n",
      "       194, 229, 293], dtype=int64),)], [0.80272108843537415, 'SelectKBest+LR', (array([ 40,  62,  65, 125, 154, 179, 235, 274, 285, 293], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78911564625850339, 'KNN', (array([], dtype=int64),)], [0.78911564625850339, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86989959165434072, 0.86394500271620978, 0.85119199798516598, 0.85119199798516598, 0.85119199798516598]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.772108843537\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852040152271\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.227891156463\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.369438264739\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[222  10]\n",
      " [ 57   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.96      0.87       232\n",
      "          1       0.33      0.08      0.13        62\n",
      "\n",
      "avg / total       0.70      0.77      0.71       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  4,  40,  49,  62,  65,  89, 116, 127, 140, 154, 179, 183, 186,\n",
      "       194, 229, 293], dtype=int64),)], [0.80272108843537415, 'SelectKBest+LR', (array([ 40,  62,  65, 125, 154, 179, 235, 274, 285, 293], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78911564625850339, 'KNN', (array([], dtype=int64),)], [0.78911564625850339, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.77210884353741494, 'RandomForest', (array([ 22,  90,  93, 104, 133, 139, 140, 164, 178, 188, 192, 203, 210,\n",
      "       227, 271], dtype=int64),)]]\n",
      "[0.86989959165434072, 0.86394500271620978, 0.85119199798516598, 0.85119199798516598, 0.85119199798516598, 0.85204015227066598]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867337719467\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0628476084538\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[224   8]\n",
      " [ 44  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       232\n",
      "          1       0.69      0.29      0.41        62\n",
      "\n",
      "avg / total       0.81      0.82      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  4,  40,  49,  62,  65,  89, 116, 127, 140, 154, 179, 183, 186,\n",
      "       194, 229, 293], dtype=int64),)], [0.80272108843537415, 'SelectKBest+LR', (array([ 40,  62,  65, 125, 154, 179, 235, 274, 285, 293], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78911564625850339, 'KNN', (array([], dtype=int64),)], [0.78911564625850339, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.77210884353741494, 'RandomForest', (array([ 22,  90,  93, 104, 133, 139, 140, 164, 178, 188, 192, 203, 210,\n",
      "       227, 271], dtype=int64),)], [0.8231292517006803, 'XGBoost', (array([  0,   4,  22,  39,  40,  88,  89, 116, 125, 133, 140, 154, 164,\n",
      "       178, 183, 192, 194, 204, 210, 216, 229, 235, 237, 253, 271, 284], dtype=int64),)]]\n",
      "[0.86989959165434072, 0.86394500271620978, 0.85119199798516598, 0.85119199798516598, 0.85119199798516598, 0.85204015227066598, 0.86733771946658955]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857148750639\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.123772791024\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   6]\n",
      " [ 28  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.93       248\n",
      "          1       0.75      0.39      0.51        46\n",
      "\n",
      "avg / total       0.87      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  9,  21,  32,  39,  59,  66,  84,  87,  90,  97, 159, 165, 179,\n",
      "       192, 212, 214, 218, 230, 256, 273, 280, 281, 282, 287], dtype=int64),)]]\n",
      "[0.8571487506386557]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852901388457\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00508415147265\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   5]\n",
      " [ 34  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       248\n",
      "          1       0.71      0.26      0.38        46\n",
      "\n",
      "avg / total       0.85      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  9,  21,  32,  39,  59,  66,  84,  87,  90,  97, 159, 165, 179,\n",
      "       192, 212, 214, 218, 230, 256, 273, 280, 281, 282, 287], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 15,  20,  21,  33,  39,  84,  87,  90,  97, 159, 167, 192, 218,\n",
      "       280, 281, 282, 287], dtype=int64),)]]\n",
      "[0.8571487506386557, 0.85290138845669927]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  9,  21,  32,  39,  59,  66,  84,  87,  90,  97, 159, 165, 179,\n",
      "       192, 212, 214, 218, 230, 256, 273, 280, 281, 282, 287], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 15,  20,  21,  33,  39,  84,  87,  90,  97, 159, 167, 192, 218,\n",
      "       280, 281, 282, 287], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8571487506386557, 0.85290138845669927, 0.83758650047030658]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  9,  21,  32,  39,  59,  66,  84,  87,  90,  97, 159, 165, 179,\n",
      "       192, 212, 214, 218, 230, 256, 273, 280, 281, 282, 287], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 15,  20,  21,  33,  39,  84,  87,  90,  97, 159, 167, 192, 218,\n",
      "       280, 281, 282, 287], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8571487506386557, 0.85290138845669927, 0.83758650047030658, 0.83758650047030658]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  9,  21,  32,  39,  59,  66,  84,  87,  90,  97, 159, 165, 179,\n",
      "       192, 212, 214, 218, 230, 256, 273, 280, 281, 282, 287], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 15,  20,  21,  33,  39,  84,  87,  90,  97, 159, 167, 192, 218,\n",
      "       280, 281, 282, 287], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8571487506386557, 0.85290138845669927, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.8375995381\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   9]\n",
      " [ 37   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       248\n",
      "          1       0.50      0.20      0.28        46\n",
      "\n",
      "avg / total       0.81      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  9,  21,  32,  39,  59,  66,  84,  87,  90,  97, 159, 165, 179,\n",
      "       192, 212, 214, 218, 230, 256, 273, 280, 281, 282, 287], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 15,  20,  21,  33,  39,  84,  87,  90,  97, 159, 167, 192, 218,\n",
      "       280, 281, 282, 287], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84353741496598644, 'RandomForest', (array([ 20,  21,  22,  58,  64,  78,  87,  90,  96, 162, 227, 230, 231,\n",
      "       234, 248, 260, 263, 281], dtype=int64),)]]\n",
      "[0.8571487506386557, 0.85290138845669927, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.83759953810044874]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856317950346\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0722300140252\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   4]\n",
      " [ 32  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       248\n",
      "          1       0.78      0.30      0.44        46\n",
      "\n",
      "avg / total       0.87      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  9,  21,  32,  39,  59,  66,  84,  87,  90,  97, 159, 165, 179,\n",
      "       192, 212, 214, 218, 230, 256, 273, 280, 281, 282, 287], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 15,  20,  21,  33,  39,  84,  87,  90,  97, 159, 167, 192, 218,\n",
      "       280, 281, 282, 287], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84353741496598644, 'RandomForest', (array([ 20,  21,  22,  58,  64,  78,  87,  90,  96, 162, 227, 230, 231,\n",
      "       234, 248, 260, 263, 281], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([ 21,  33,  34,  84, 128, 130, 148, 159, 190, 214, 218, 230, 256,\n",
      "       273, 280, 281, 282, 287], dtype=int64),)]]\n",
      "[0.8571487506386557, 0.85290138845669927, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.83759953810044874, 0.85631795034641811]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869051393098\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00787547484481\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   7]\n",
      " [ 30  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       251\n",
      "          1       0.65      0.30      0.41        43\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 47,  51,  54,  56,  60,  67,  94,  96, 107, 124, 128, 153, 161,\n",
      "       165, 174, 177, 189, 199, 202, 213], dtype=int64),)]]\n",
      "[0.86905139309844959]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858862435338\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00787547484481\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   4]\n",
      " [ 33  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       251\n",
      "          1       0.71      0.23      0.35        43\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 47,  51,  54,  56,  60,  67,  94,  96, 107, 124, 128, 153, 161,\n",
      "       165, 174, 177, 189, 199, 202, 213], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 12,  54,  60,  67,  96, 128, 161, 167, 174, 189, 199, 213, 219, 244], dtype=int64),)]]\n",
      "[0.86905139309844959, 0.85886243533811346]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 47,  51,  54,  56,  60,  67,  94,  96, 107, 124, 128, 153, 161,\n",
      "       165, 174, 177, 189, 199, 202, 213], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 12,  54,  60,  67,  96, 128, 161, 167, 174, 189, 199, 213, 219, 244], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86905139309844959, 0.85886243533811346, 0.83503546899454539]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 47,  51,  54,  56,  60,  67,  94,  96, 107, 124, 128, 153, 161,\n",
      "       165, 174, 177, 189, 199, 202, 213], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 12,  54,  60,  67,  96, 128, 161, 167, 174, 189, 199, 213, 219, 244], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86905139309844959, 0.85886243533811346, 0.83503546899454539, 0.83503546899454539]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 47,  51,  54,  56,  60,  67,  94,  96, 107, 124, 128, 153, 161,\n",
      "       165, 174, 177, 189, 199, 202, 213], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 12,  54,  60,  67,  96, 128, 161, 167, 174, 189, 199, 213, 219, 244], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86905139309844959, 0.85886243533811346, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.825681650025\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225794496433\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   8]\n",
      " [ 37   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       251\n",
      "          1       0.43      0.14      0.21        43\n",
      "\n",
      "avg / total       0.80      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 47,  51,  54,  56,  60,  67,  94,  96, 107, 124, 128, 153, 161,\n",
      "       165, 174, 177, 189, 199, 202, 213], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 12,  54,  60,  67,  96, 128, 161, 167, 174, 189, 199, 213, 219, 244], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([ 40,  42,  43,  47,  67, 101, 124, 142, 174, 177, 189, 202, 277, 289], dtype=int64),)]]\n",
      "[0.86905139309844959, 0.85886243533811346, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.82568165002476268]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865656501565\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0895951079403\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   8]\n",
      " [ 32  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       251\n",
      "          1       0.58      0.26      0.35        43\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 47,  51,  54,  56,  60,  67,  94,  96, 107, 124, 128, 153, 161,\n",
      "       165, 174, 177, 189, 199, 202, 213], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 12,  54,  60,  67,  96, 128, 161, 167, 174, 189, 199, 213, 219, 244], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([ 40,  42,  43,  47,  67, 101, 124, 142, 174, 177, 189, 202, 277, 289], dtype=int64),)], [0.86394557823129248, 'XGBoost', (array([ 47,  59,  60,  63,  67,  94, 124, 128, 149, 155, 169, 174, 189,\n",
      "       202, 213, 219, 223, 256, 281], dtype=int64),)]]\n",
      "[0.86905139309844959, 0.85886243533811346, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.82568165002476268, 0.86565650156511331]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.897959183673\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867359389823\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.102040816327\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0933388157895\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   5]\n",
      " [ 25  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       256\n",
      "          1       0.72      0.34      0.46        38\n",
      "\n",
      "avg / total       0.89      0.90      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  8,  43,  50,  62,  71,  75,  83, 115, 145, 154, 155, 190, 199,\n",
      "       218, 225, 245, 258, 269], dtype=int64),)]]\n",
      "[0.867359389822972]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85204886247\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.118215460526\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   5]\n",
      " [ 32   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       256\n",
      "          1       0.55      0.16      0.24        38\n",
      "\n",
      "avg / total       0.84      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  8,  43,  50,  62,  71,  75,  83, 115, 145, 154, 155, 190, 199,\n",
      "       218, 225, 245, 258, 269], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([  8,  33,  50,  62, 140, 190, 199, 218, 225, 245, 252], dtype=int64),)]]\n",
      "[0.867359389822972, 0.85204886247009037]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.830783746179\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.1484375\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[256   0]\n",
      " [ 38   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       256\n",
      "\n",
      "avg / total       0.87      1.00      0.93       256\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  8,  43,  50,  62,  71,  75,  83, 115, 145, 154, 155, 190, 199,\n",
      "       218, 225, 245, 258, 269], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([  8,  33,  50,  62, 140, 190, 199, 218, 225, 245, 252], dtype=int64),)], [0.87074829931972786, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.867359389822972, 0.85204886247009037, 0.83078374617907791]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.830783746179\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.1484375\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[256   0]\n",
      " [ 38   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       256\n",
      "\n",
      "avg / total       0.87      1.00      0.93       256\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  8,  43,  50,  62,  71,  75,  83, 115, 145, 154, 155, 190, 199,\n",
      "       218, 225, 245, 258, 269], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([  8,  33,  50,  62, 140, 190, 199, 218, 225, 245, 252], dtype=int64),)], [0.87074829931972786, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87074829931972786, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.867359389822972, 0.85204886247009037, 0.83078374617907791, 0.83078374617907791]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.830783746179\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.1484375\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[256   0]\n",
      " [ 38   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       256\n",
      "\n",
      "avg / total       0.87      1.00      0.93       256\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  8,  43,  50,  62,  71,  75,  83, 115, 145, 154, 155, 190, 199,\n",
      "       218, 225, 245, 258, 269], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([  8,  33,  50,  62, 140, 190, 199, 218, 225, 245, 252], dtype=int64),)], [0.87074829931972786, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87074829931972786, 'KNN', (array([], dtype=int64),)], [0.87074829931972786, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.867359389822972, 0.85204886247009037, 0.83078374617907791, 0.83078374617907791, 0.83078374617907791]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833328275441\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.359991776316\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243  13]\n",
      " [ 32   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.92       256\n",
      "          1       0.32      0.16      0.21        38\n",
      "\n",
      "avg / total       0.81      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  8,  43,  50,  62,  71,  75,  83, 115, 145, 154, 155, 190, 199,\n",
      "       218, 225, 245, 258, 269], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([  8,  33,  50,  62, 140, 190, 199, 218, 225, 245, 252], dtype=int64),)], [0.87074829931972786, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87074829931972786, 'KNN', (array([], dtype=int64),)], [0.87074829931972786, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  8,  33,  40,  74,  75, 115, 119, 140, 145, 153, 190, 199, 225,\n",
      "       229, 245, 250, 252, 287, 293], dtype=int64),)]]\n",
      "[0.867359389822972, 0.85204886247009037, 0.83078374617907791, 0.83078374617907791, 0.83078374617907791, 0.83332827544116439]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86226594853\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.118215460526\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   5]\n",
      " [ 32   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       256\n",
      "          1       0.55      0.16      0.24        38\n",
      "\n",
      "avg / total       0.84      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  8,  43,  50,  62,  71,  75,  83, 115, 145, 154, 155, 190, 199,\n",
      "       218, 225, 245, 258, 269], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([  8,  33,  50,  62, 140, 190, 199, 218, 225, 245, 252], dtype=int64),)], [0.87074829931972786, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87074829931972786, 'KNN', (array([], dtype=int64),)], [0.87074829931972786, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  8,  33,  40,  74,  75, 115, 119, 140, 145, 153, 190, 199, 225,\n",
      "       229, 245, 250, 252, 287, 293], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([  8,  33,  60,  62,  71, 140, 145, 190, 199, 225, 234], dtype=int64),)]]\n",
      "[0.867359389822972, 0.85204886247009037, 0.83078374617907791, 0.83078374617907791, 0.83078374617907791, 0.83332827544116439, 0.86226594853009242]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869897959184\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0208333333333\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   6]\n",
      " [ 39  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       240\n",
      "          1       0.71      0.28      0.40        54\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84693877551020413, 'LogisticRegression', (array([  3,  20,  31,  37,  62,  74,  78,  98, 108, 143, 149, 150, 152,\n",
      "       167, 174, 187, 239, 246, 276, 282, 284], dtype=int64),)]]\n",
      "[0.86989795918367341]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.111574074074\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 49   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       240\n",
      "          1       1.00      0.09      0.17        54\n",
      "\n",
      "avg / total       0.86      0.83      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  3,  20,  31,  37,  62,  74,  78,  98, 108, 143, 149, 150, 152,\n",
      "       167, 174, 187, 239, 246, 276, 282, 284], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  3,  20, 152, 187, 246], dtype=int64),)]]\n",
      "[0.86989795918367341, 0.86394557823129248]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  3,  20,  31,  37,  62,  74,  78,  98, 108, 143, 149, 150, 152,\n",
      "       167, 174, 187, 239, 246, 276, 282, 284], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  3,  20, 152, 187, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86989795918367341, 0.86394557823129248, 0.84438775510204078]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  3,  20,  31,  37,  62,  74,  78,  98, 108, 143, 149, 150, 152,\n",
      "       167, 174, 187, 239, 246, 276, 282, 284], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  3,  20, 152, 187, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86989795918367341, 0.86394557823129248, 0.84438775510204078, 0.84438775510204078]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  3,  20,  31,  37,  62,  74,  78,  98, 108, 143, 149, 150, 152,\n",
      "       167, 174, 187, 239, 246, 276, 282, 284], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  3,  20, 152, 187, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86989795918367341, 0.86394557823129248, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835884353741\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.134259259259\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   4]\n",
      " [ 46   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       240\n",
      "          1       0.67      0.15      0.24        54\n",
      "\n",
      "avg / total       0.81      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  3,  20,  31,  37,  62,  74,  78,  98, 108, 143, 149, 150, 152,\n",
      "       167, 174, 187, 239, 246, 276, 282, 284], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  3,  20, 152, 187, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([  3,  31,  63, 142, 150, 187, 197, 220, 221, 232, 246, 263], dtype=int64),)]]\n",
      "[0.86989795918367341, 0.86394557823129248, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.83588435374149661]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.872448979592\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00185185185185\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   4]\n",
      " [ 40  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91       240\n",
      "          1       0.78      0.26      0.39        54\n",
      "\n",
      "avg / total       0.84      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  3,  20,  31,  37,  62,  74,  78,  98, 108, 143, 149, 150, 152,\n",
      "       167, 174, 187, 239, 246, 276, 282, 284], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  3,  20, 152, 187, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([  3,  31,  63, 142, 150, 187, 197, 220, 221, 232, 246, 263], dtype=int64),)], [0.85034013605442171, 'XGBoost', (array([  3,  20,  21,  53,  63,  74, 108, 132, 137, 152, 174, 187, 197,\n",
      "       239, 246, 276, 282, 284], dtype=int64),)]]\n",
      "[0.86989795918367341, 0.86394557823129248, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.83588435374149661, 0.87244897959183676]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.873290111487\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   9]\n",
      " [ 41   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       244\n",
      "          1       0.50      0.18      0.26        50\n",
      "\n",
      "avg / total       0.79      0.83      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([ 10,  18,  21,  38,  44,  63,  79,  81,  83,  86,  91, 119, 140,\n",
      "       160, 205, 219, 256, 283], dtype=int64),)]]\n",
      "[0.87329011148656832]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852018492982\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.229016393443\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   4]\n",
      " [ 47   3]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       244\n",
      "          1       0.43      0.06      0.11        50\n",
      "\n",
      "avg / total       0.77      0.83      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([ 10,  18,  21,  38,  44,  63,  79,  81,  83,  86,  91, 119, 140,\n",
      "       160, 205, 219, 256, 283], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 10,  16,  21, 160, 205, 212, 219], dtype=int64),)]]\n",
      "[0.87329011148656832, 0.85201849298188137]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([ 10,  18,  21,  38,  44,  63,  79,  81,  83,  86,  91, 119, 140,\n",
      "       160, 205, 219, 256, 283], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 10,  16,  21, 160, 205, 212, 219], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87329011148656832, 0.85201849298188137, 0.84098787208212189]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([ 10,  18,  21,  38,  44,  63,  79,  81,  83,  86,  91, 119, 140,\n",
      "       160, 205, 219, 256, 283], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 10,  16,  21, 160, 205, 212, 219], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87329011148656832, 0.85201849298188137, 0.84098787208212189, 0.84098787208212189]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([ 10,  18,  21,  38,  44,  63,  79,  81,  83,  86,  91, 119, 140,\n",
      "       160, 205, 219, 256, 283], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 10,  16,  21, 160, 205, 212, 219], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87329011148656832, 0.85201849298188137, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844380577765\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.277213114754\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   8]\n",
      " [ 45   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       244\n",
      "          1       0.38      0.10      0.16        50\n",
      "\n",
      "avg / total       0.76      0.82      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([ 10,  18,  21,  38,  44,  63,  79,  81,  83,  86,  91, 119, 140,\n",
      "       160, 205, 219, 256, 283], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 10,  16,  21, 160, 205, 212, 219], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([  5,  10,  30,  73,  86, 105, 133, 156, 160, 175, 202, 219, 269], dtype=int64),)]]\n",
      "[0.87329011148656832, 0.85201849298188137, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189, 0.84438057776490405]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.87499944662\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0360655737705\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   3]\n",
      " [ 37  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       244\n",
      "          1       0.81      0.26      0.39        50\n",
      "\n",
      "avg / total       0.86      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([ 10,  18,  21,  38,  44,  63,  79,  81,  83,  86,  91, 119, 140,\n",
      "       160, 205, 219, 256, 283], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 10,  16,  21, 160, 205, 212, 219], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([  5,  10,  30,  73,  86, 105, 133, 156, 160, 175, 202, 219, 269], dtype=int64),)], [0.86394557823129248, 'XGBoost', (array([ 10,  16,  44,  67,  79,  91, 133, 141, 156, 158, 160, 185, 219,\n",
      "       255, 269, 283], dtype=int64),)]]\n",
      "[0.87329011148656832, 0.85201849298188137, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189, 0.84438057776490405, 0.87499944662011286]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00185185185185\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   7]\n",
      " [ 37  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       240\n",
      "          1       0.71      0.31      0.44        54\n",
      "\n",
      "avg / total       0.83      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85034013605442171, 'LogisticRegression', (array([  1,  14,  21,  37,  40,  57,  61,  69, 101, 116, 119, 120, 136,\n",
      "       158, 164, 194, 197, 210, 221, 231, 246, 271, 280, 293], dtype=int64),)]]\n",
      "[0.86734693877551017]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.024537037037\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   5]\n",
      " [ 38  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       240\n",
      "          1       0.76      0.30      0.43        54\n",
      "\n",
      "avg / total       0.84      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  1,  14,  21,  37,  40,  57,  61,  69, 101, 116, 119, 120, 136,\n",
      "       158, 164, 194, 197, 210, 221, 231, 246, 271, 280, 293], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  1,  14,  37,  40,  61,  67,  69, 116, 136, 138, 164, 166, 194,\n",
      "       202, 218, 221, 231, 240, 246, 280, 293], dtype=int64),)]]\n",
      "[0.86734693877551017, 0.8605442176870749]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  1,  14,  21,  37,  40,  57,  61,  69, 101, 116, 119, 120, 136,\n",
      "       158, 164, 194, 197, 210, 221, 231, 246, 271, 280, 293], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  1,  14,  37,  40,  61,  67,  69, 116, 136, 138, 164, 166, 194,\n",
      "       202, 218, 221, 231, 240, 246, 280, 293], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86734693877551017, 0.8605442176870749, 0.84438775510204078]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  1,  14,  21,  37,  40,  57,  61,  69, 101, 116, 119, 120, 136,\n",
      "       158, 164, 194, 197, 210, 221, 231, 246, 271, 280, 293], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  1,  14,  37,  40,  61,  67,  69, 116, 136, 138, 164, 166, 194,\n",
      "       202, 218, 221, 231, 240, 246, 280, 293], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86734693877551017, 0.8605442176870749, 0.84438775510204078, 0.84438775510204078]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  1,  14,  21,  37,  40,  57,  61,  69, 101, 116, 119, 120, 136,\n",
      "       158, 164, 194, 197, 210, 221, 231, 246, 271, 280, 293], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  1,  14,  37,  40,  61,  67,  69, 116, 136, 138, 164, 166, 194,\n",
      "       202, 218, 221, 231, 240, 246, 280, 293], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86734693877551017, 0.8605442176870749, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0662037037037\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230  10]\n",
      " [ 37  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91       240\n",
      "          1       0.63      0.31      0.42        54\n",
      "\n",
      "avg / total       0.82      0.84      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  1,  14,  21,  37,  40,  57,  61,  69, 101, 116, 119, 120, 136,\n",
      "       158, 164, 194, 197, 210, 221, 231, 246, 271, 280, 293], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  1,  14,  37,  40,  61,  67,  69, 116, 136, 138, 164, 166, 194,\n",
      "       202, 218, 221, 231, 240, 246, 280, 293], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84013605442176875, 'RandomForest', (array([ 37,  40,  61,  64,  96, 102, 119, 136, 138, 145, 150, 151, 155,\n",
      "       163, 194, 210, 216, 221, 231, 240, 246, 247, 254, 271, 280, 289, 291], dtype=int64),)]]\n",
      "[0.86734693877551017, 0.8605442176870749, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0208333333333\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   7]\n",
      " [ 38  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       240\n",
      "          1       0.70      0.30      0.42        54\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  1,  14,  21,  37,  40,  57,  61,  69, 101, 116, 119, 120, 136,\n",
      "       158, 164, 194, 197, 210, 221, 231, 246, 271, 280, 293], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  1,  14,  37,  40,  61,  67,  69, 116, 136, 138, 164, 166, 194,\n",
      "       202, 218, 221, 231, 240, 246, 280, 293], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84013605442176875, 'RandomForest', (array([ 37,  40,  61,  64,  96, 102, 119, 136, 138, 145, 150, 151, 155,\n",
      "       163, 194, 210, 216, 221, 231, 240, 246, 247, 254, 271, 280, 289, 291], dtype=int64),)], [0.84693877551020413, 'XGBoost', (array([ 14,  37,  40,  61,  69, 119, 120, 136, 138, 151, 163, 194, 202,\n",
      "       210, 216, 221, 231, 240, 246, 247, 280, 289, 293], dtype=int64),)]]\n",
      "[0.86734693877551017, 0.8605442176870749, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.85714285714285721]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852891156463\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.145969498911\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   8]\n",
      " [ 28  23]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       243\n",
      "          1       0.74      0.45      0.56        51\n",
      "\n",
      "avg / total       0.87      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  8,  23,  43,  61,  62,  64,  65,  66,  72,  82, 119, 137, 143,\n",
      "       145, 160, 165, 177, 180, 188, 191, 196, 200, 205, 214, 218, 238,\n",
      "       261, 270, 272, 273, 278], dtype=int64),)]]\n",
      "[0.85289115646258506]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846088435374\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.043815056887\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   3]\n",
      " [ 41  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       243\n",
      "          1       0.77      0.20      0.31        51\n",
      "\n",
      "avg / total       0.84      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  8,  23,  43,  61,  62,  64,  65,  66,  72,  82, 119, 137, 143,\n",
      "       145, 160, 165, 177, 180, 188, 191, 196, 200, 205, 214, 218, 238,\n",
      "       261, 270, 272, 273, 278], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  8,  62,  65,  82, 101, 137, 143, 145, 196, 214, 218, 238, 273], dtype=int64),)]]\n",
      "[0.85289115646258506, 0.84608843537414968]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.20987654321\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   0]\n",
      " [ 51   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       243\n",
      "\n",
      "avg / total       0.83      1.00      0.91       243\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  8,  23,  43,  61,  62,  64,  65,  66,  72,  82, 119, 137, 143,\n",
      "       145, 160, 165, 177, 180, 188, 191, 196, 200, 205, 214, 218, 238,\n",
      "       261, 270, 272, 273, 278], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  8,  62,  65,  82, 101, 137, 143, 145, 196, 214, 218, 238, 273], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85289115646258506, 0.84608843537414968, 0.84183673469387754]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.20987654321\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   0]\n",
      " [ 51   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       243\n",
      "\n",
      "avg / total       0.83      1.00      0.91       243\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  8,  23,  43,  61,  62,  64,  65,  66,  72,  82, 119, 137, 143,\n",
      "       145, 160, 165, 177, 180, 188, 191, 196, 200, 205, 214, 218, 238,\n",
      "       261, 270, 272, 273, 278], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  8,  62,  65,  82, 101, 137, 143, 145, 196, 214, 218, 238, 273], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82653061224489799, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85289115646258506, 0.84608843537414968, 0.84183673469387754, 0.84183673469387754]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.20987654321\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   0]\n",
      " [ 51   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       243\n",
      "\n",
      "avg / total       0.83      1.00      0.91       243\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  8,  23,  43,  61,  62,  64,  65,  66,  72,  82, 119, 137, 143,\n",
      "       145, 160, 165, 177, 180, 188, 191, 196, 200, 205, 214, 218, 238,\n",
      "       261, 270, 272, 273, 278], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  8,  62,  65,  82, 101, 137, 143, 145, 196, 214, 218, 238, 273], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82653061224489799, 'KNN', (array([], dtype=int64),)], [0.82653061224489799, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85289115646258506, 0.84608843537414968, 0.84183673469387754, 0.84183673469387754, 0.84183673469387754]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835884353741\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0675381263617\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   2]\n",
      " [ 43   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.91       243\n",
      "          1       0.80      0.16      0.26        51\n",
      "\n",
      "avg / total       0.84      0.85      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  8,  23,  43,  61,  62,  64,  65,  66,  72,  82, 119, 137, 143,\n",
      "       145, 160, 165, 177, 180, 188, 191, 196, 200, 205, 214, 218, 238,\n",
      "       261, 270, 272, 273, 278], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  8,  62,  65,  82, 101, 137, 143, 145, 196, 214, 218, 238, 273], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82653061224489799, 'KNN', (array([], dtype=int64),)], [0.82653061224489799, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  1,   8,  23,  56,  64,  66,  82, 119, 133, 218], dtype=int64),)]]\n",
      "[0.85289115646258506, 0.84608843537414968, 0.84183673469387754, 0.84183673469387754, 0.84183673469387754, 0.83588435374149661]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861394557823\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0985233599613\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   3]\n",
      " [ 35  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       243\n",
      "          1       0.84      0.31      0.46        51\n",
      "\n",
      "avg / total       0.87      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  8,  23,  43,  61,  62,  64,  65,  66,  72,  82, 119, 137, 143,\n",
      "       145, 160, 165, 177, 180, 188, 191, 196, 200, 205, 214, 218, 238,\n",
      "       261, 270, 272, 273, 278], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  8,  62,  65,  82, 101, 137, 143, 145, 196, 214, 218, 238, 273], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82653061224489799, 'KNN', (array([], dtype=int64),)], [0.82653061224489799, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  1,   8,  23,  56,  64,  66,  82, 119, 133, 218], dtype=int64),)], [0.87074829931972786, 'XGBoost', (array([  8,  23,  64,  66,  82, 108, 119, 150, 169, 180, 181, 196, 200,\n",
      "       218, 233, 255, 261, 270, 273], dtype=int64),)]]\n",
      "[0.85289115646258506, 0.84608843537414968, 0.84183673469387754, 0.84183673469387754, 0.84183673469387754, 0.83588435374149661, 0.86139455782312924]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.855426366807\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0888429752066\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   1]\n",
      " [ 38  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       242\n",
      "          1       0.93      0.27      0.42        52\n",
      "\n",
      "avg / total       0.88      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  6,  74, 102, 153, 159, 161, 171, 174, 210, 213, 216, 270, 278,\n",
      "       286, 288], dtype=int64),)]]\n",
      "[0.85542636680737127]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863934150937\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.027972027972\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   5]\n",
      " [ 39  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       242\n",
      "          1       0.72      0.25      0.37        52\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  6,  74, 102, 153, 159, 161, 171, 174, 210, 213, 216, 270, 278,\n",
      "       286, 288], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 29,  74,  85, 117, 129, 153, 161, 171, 174, 197, 210, 213, 246,\n",
      "       270, 278, 285, 286, 288], dtype=int64),)]]\n",
      "[0.85542636680737127, 0.86393415093662196]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  6,  74, 102, 153, 159, 161, 171, 174, 210, 213, 216, 270, 278,\n",
      "       286, 288], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 29,  74,  85, 117, 129, 153, 161, 171, 174, 197, 210, 213, 246,\n",
      "       270, 278, 285, 286, 288], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85542636680737127, 0.86393415093662196, 0.84268856342182852]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  6,  74, 102, 153, 159, 161, 171, 174, 210, 213, 216, 270, 278,\n",
      "       286, 288], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 29,  74,  85, 117, 129, 153, 161, 171, 174, 197, 210, 213, 246,\n",
      "       270, 278, 285, 286, 288], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85542636680737127, 0.86393415093662196, 0.84268856342182852, 0.84268856342182852]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  6,  74, 102, 153, 159, 161, 171, 174, 210, 213, 216, 270, 278,\n",
      "       286, 288], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 29,  74,  85, 117, 129, 153, 161, 171, 174, 197, 210, 213, 246,\n",
      "       270, 278, 285, 286, 288], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85542636680737127, 0.86393415093662196, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.847812318865\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.168150031786\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   5]\n",
      " [ 45   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       242\n",
      "          1       0.58      0.13      0.22        52\n",
      "\n",
      "avg / total       0.79      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  6,  74, 102, 153, 159, 161, 171, 174, 210, 213, 216, 270, 278,\n",
      "       286, 288], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 29,  74,  85, 117, 129, 153, 161, 171, 174, 197, 210, 213, 246,\n",
      "       270, 278, 285, 286, 288], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([136, 153, 159, 161, 174, 197, 210, 221, 231, 261, 285, 288], dtype=int64),)]]\n",
      "[0.85542636680737127, 0.86393415093662196, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.84781231886492847]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862239983946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.158931977114\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   1]\n",
      " [ 35  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       242\n",
      "          1       0.94      0.33      0.49        52\n",
      "\n",
      "avg / total       0.89      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  6,  74, 102, 153, 159, 161, 171, 174, 210, 213, 216, 270, 278,\n",
      "       286, 288], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 29,  74,  85, 117, 129, 153, 161, 171, 174, 197, 210, 213, 246,\n",
      "       270, 278, 285, 286, 288], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([136, 153, 159, 161, 174, 197, 210, 221, 231, 261, 285, 288], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([ 51,  60,  74,  82,  85, 102, 121, 136, 153, 159, 161, 174, 210,\n",
      "       220, 245, 278, 286, 288], dtype=int64),)]]\n",
      "[0.85542636680737127, 0.86393415093662196, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.84781231886492847, 0.86223998394578538]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.153455284553\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   5]\n",
      " [ 29  19]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       246\n",
      "          1       0.79      0.40      0.53        48\n",
      "\n",
      "avg / total       0.88      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 34,  44,  52,  62,  70,  72,  76,  84,  88,  89,  93, 103, 118,\n",
      "       123, 129, 130, 133, 134, 155, 169, 192, 193, 234, 271], dtype=int64),)]]\n",
      "[0.86394557823129248]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0457317073171\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   1]\n",
      " [ 41   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       246\n",
      "          1       0.88      0.15      0.25        48\n",
      "\n",
      "avg / total       0.86      0.86      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 34,  44,  52,  62,  70,  72,  76,  84,  88,  89,  93, 103, 118,\n",
      "       123, 129, 130, 133, 134, 155, 169, 192, 193, 234, 271], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  34,  62,  70,  88,  89, 123, 244], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.85374149659863952]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 34,  44,  52,  62,  70,  72,  76,  84,  88,  89,  93, 103, 118,\n",
      "       123, 129, 130, 133, 134, 155, 169, 192, 193, 234, 271], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  34,  62,  70,  88,  89, 123, 244], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.85374149659863952, 0.8392857142857143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 34,  44,  52,  62,  70,  72,  76,  84,  88,  89,  93, 103, 118,\n",
      "       123, 129, 130, 133, 134, 155, 169, 192, 193, 234, 271], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  34,  62,  70,  88,  89, 123, 244], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.85374149659863952, 0.8392857142857143, 0.8392857142857143]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 34,  44,  52,  62,  70,  72,  76,  84,  88,  89,  93, 103, 118,\n",
      "       123, 129, 130, 133, 134, 155, 169, 192, 193, 234, 271], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  34,  62,  70,  88,  89, 123, 244], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.85374149659863952, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835034013605\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0955284552846\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   3]\n",
      " [ 41   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       246\n",
      "          1       0.70      0.15      0.24        48\n",
      "\n",
      "avg / total       0.83      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 34,  44,  52,  62,  70,  72,  76,  84,  88,  89,  93, 103, 118,\n",
      "       123, 129, 130, 133, 134, 155, 169, 192, 193, 234, 271], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  34,  62,  70,  88,  89, 123, 244], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 25,  30,  52,  59,  70,  88,  89,  97, 123, 244], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.85374149659863952, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.83503401360544205]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865646258503\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0208333333333\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   2]\n",
      " [ 39   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       246\n",
      "          1       0.82      0.19      0.31        48\n",
      "\n",
      "avg / total       0.86      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 34,  44,  52,  62,  70,  72,  76,  84,  88,  89,  93, 103, 118,\n",
      "       123, 129, 130, 133, 134, 155, 169, 192, 193, 234, 271], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  34,  62,  70,  88,  89, 123, 244], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 25,  30,  52,  59,  70,  88,  89,  97, 123, 244], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([ 25,  34,  52,  62,  84,  88, 103, 123, 133, 134, 234], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.85374149659863952, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.83503401360544205, 0.86564625850340127]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869055742664\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.133941093969\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   6]\n",
      " [ 38   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       248\n",
      "          1       0.57      0.17      0.27        46\n",
      "\n",
      "avg / total       0.82      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 79,  81, 163, 172, 184, 188, 209, 227, 234, 236, 251, 256, 264, 285], dtype=int64),)]]\n",
      "[0.86905574266436314]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857999090775\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.159712482468\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   3]\n",
      " [ 42   4]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       248\n",
      "          1       0.57      0.09      0.15        46\n",
      "\n",
      "avg / total       0.81      0.85      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 79,  81, 163, 172, 184, 188, 209, 227, 234, 236, 251, 256, 264, 285], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([  0, 184, 188, 234, 256, 264, 285], dtype=int64),)]]\n",
      "[0.86905574266436314, 0.85799909077471004]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 79,  81, 163, 172, 184, 188, 209, 227, 234, 236, 251, 256, 264, 285], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([  0, 184, 188, 234, 256, 264, 285], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86905574266436314, 0.85799909077471004, 0.83758650047030658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 79,  81, 163, 172, 184, 188, 209, 227, 234, 236, 251, 256, 264, 285], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([  0, 184, 188, 234, 256, 264, 285], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86905574266436314, 0.85799909077471004, 0.83758650047030658, 0.83758650047030658]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 79,  81, 163, 172, 184, 188, 209, 227, 234, 236, 251, 256, 264, 285], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([  0, 184, 188, 234, 256, 264, 285], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86905574266436314, 0.85799909077471004, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833339171491\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   9]\n",
      " [ 37   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       248\n",
      "          1       0.50      0.20      0.28        46\n",
      "\n",
      "avg / total       0.81      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 79,  81, 163, 172, 184, 188, 209, 227, 234, 236, 251, 256, 264, 285], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([  0, 184, 188, 234, 256, 264, 285], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84353741496598644, 'RandomForest', (array([  1,  11,  29,  34,  39,  48,  61,  63,  71, 101, 110, 143, 173,\n",
      "       209, 213, 228, 233, 278], dtype=int64),)]]\n",
      "[0.86905574266436314, 0.85799909077471004, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.83333917149114323]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852870996833\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0464586255259\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   7]\n",
      " [ 30  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       248\n",
      "          1       0.70      0.35      0.46        46\n",
      "\n",
      "avg / total       0.86      0.87      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 79,  81, 163, 172, 184, 188, 209, 227, 234, 236, 251, 256, 264, 285], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([  0, 184, 188, 234, 256, 264, 285], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84353741496598644, 'RandomForest', (array([  1,  11,  29,  34,  39,  48,  61,  63,  71, 101, 110, 143, 173,\n",
      "       209, 213, 228, 233, 278], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([  1,   5,  11,  34,  39,  59,  61,  71,  79, 110, 135, 143, 163,\n",
      "       166, 172, 204, 209, 213, 228, 233, 236, 256, 285], dtype=int64),)]]\n",
      "[0.86905574266436314, 0.85799909077471004, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.83333917149114323, 0.8528709968332947]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90136054421768708, 'XGBoost', (array([ 44,  69,  78,  96, 103, 111, 138, 148, 150, 177, 185, 197, 207,\n",
      "       245, 249, 254, 271], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.901360544218\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0986394557823\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.010101010101\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[256   5]\n",
      " [ 24   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95       261\n",
      "          1       0.64      0.27      0.38        33\n",
      "\n",
      "avg / total       0.88      0.90      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 30,  60,  61,  93,  97, 102, 106, 107, 115, 130, 197, 217, 280, 282], dtype=int64),)]]\n",
      "[0.85034013605442171]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.904761904762\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0952380952381\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0442354580286\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[256   5]\n",
      " [ 23  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       261\n",
      "          1       0.67      0.30      0.42        33\n",
      "\n",
      "avg / total       0.89      0.90      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 30,  60,  61,  93,  97, 102, 106, 107, 115, 130, 197, 217, 280, 282], dtype=int64),)], [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]]\n",
      "[0.85034013605442171, 0.84183673469387754]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 30,  60,  61,  93,  97, 102, 106, 107, 115, 130, 197, 217, 280, 282], dtype=int64),)], [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85034013605442171, 0.84183673469387754, 0.82653061224489799]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 30,  60,  61,  93,  97, 102, 106, 107, 115, 130, 197, 217, 280, 282], dtype=int64),)], [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88775510204081631, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85034013605442171, 0.84183673469387754, 0.82653061224489799, 0.82653061224489799]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 30,  60,  61,  93,  97, 102, 106, 107, 115, 130, 197, 217, 280, 282], dtype=int64),)], [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88775510204081631, 'KNN', (array([], dtype=int64),)], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85034013605442171, 0.84183673469387754, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.262974573319\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250  11]\n",
      " [ 26   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93       261\n",
      "          1       0.39      0.21      0.27        33\n",
      "\n",
      "avg / total       0.85      0.87      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 30,  60,  61,  93,  97, 102, 106, 107, 115, 130, 197, 217, 280, 282], dtype=int64),)], [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88775510204081631, 'KNN', (array([], dtype=int64),)], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([  1,  27,  45,  80,  90, 102, 124, 130, 166, 186, 196, 197, 216,\n",
      "       228, 262, 281, 282, 291], dtype=int64),)]]\n",
      "[0.85034013605442171, 0.84183673469387754, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852040816327\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.194705677464\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251  10]\n",
      " [ 25   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93       261\n",
      "          1       0.44      0.24      0.31        33\n",
      "\n",
      "avg / total       0.86      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 30,  60,  61,  93,  97, 102, 106, 107, 115, 130, 197, 217, 280, 282], dtype=int64),)], [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88775510204081631, 'KNN', (array([], dtype=int64),)], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([  1,  27,  45,  80,  90, 102, 124, 130, 166, 186, 196, 197, 216,\n",
      "       228, 262, 281, 282, 291], dtype=int64),)], [0.88095238095238093, 'XGBoost', (array([ 19,  61,  73,  79,  97, 100, 102, 106, 124, 130, 134, 166, 185,\n",
      "       197, 211, 250, 259, 262], dtype=int64),)]]\n",
      "[0.85034013605442171, 0.84183673469387754, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799, 0.85204081632653061]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.868224898102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0958181818182\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   8]\n",
      " [ 33  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       250\n",
      "          1       0.58      0.25      0.35        44\n",
      "\n",
      "avg / total       0.83      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  7,  21,  26,  31,  36,  39,  62,  71,  74,  77,  83, 101, 117,\n",
      "       216, 221, 265, 267, 275, 293], dtype=int64),)]]\n",
      "[0.86822489810173431]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851200663914\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0958181818182\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   5]\n",
      " [ 36   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       250\n",
      "          1       0.62      0.18      0.28        44\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  7,  21,  26,  31,  36,  39,  62,  71,  74,  77,  83, 101, 117,\n",
      "       216, 221, 265, 267, 275, 293], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  7,  21,  26,  36,  71,  77, 101, 117, 216, 221, 267, 275, 293], dtype=int64),)]]\n",
      "[0.86822489810173431, 0.85120066391419924]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  7,  21,  26,  31,  36,  39,  62,  71,  74,  77,  83, 101, 117,\n",
      "       216, 221, 265, 267, 275, 293], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  7,  21,  26,  36,  71,  77, 101, 117, 216, 221, 267, 275, 293], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86822489810173431, 0.85120066391419924, 0.83588580913059995]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  7,  21,  26,  31,  36,  39,  62,  71,  74,  77,  83, 101, 117,\n",
      "       216, 221, 265, 267, 275, 293], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  7,  21,  26,  36,  71,  77, 101, 117, 216, 221, 267, 275, 293], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86822489810173431, 0.85120066391419924, 0.83588580913059995, 0.83588580913059995]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  7,  21,  26,  31,  36,  39,  62,  71,  74,  77,  83, 101, 117,\n",
      "       216, 221, 265, 267, 275, 293], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  7,  21,  26,  36,  71,  77, 101, 117, 216, 221, 267, 275, 293], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86822489810173431, 0.85120066391419924, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.820594821622\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.149272727273\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   8]\n",
      " [ 35   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       250\n",
      "          1       0.53      0.20      0.30        44\n",
      "\n",
      "avg / total       0.82      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  7,  21,  26,  31,  36,  39,  62,  71,  74,  77,  83, 101, 117,\n",
      "       216, 221, 265, 267, 275, 293], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  7,  21,  26,  36,  71,  77, 101, 117, 216, 221, 267, 275, 293], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8537414965986394, 'RandomForest', (array([  7,  18,  26,  31,  43,  51,  62,  77,  86, 100, 162, 179, 213,\n",
      "       216, 221, 241, 253], dtype=int64),)]]\n",
      "[0.86822489810173431, 0.85120066391419924, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.82059482162153496]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858849441978\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0156363636364\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   5]\n",
      " [ 33  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       250\n",
      "          1       0.69      0.25      0.37        44\n",
      "\n",
      "avg / total       0.85      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  7,  21,  26,  31,  36,  39,  62,  71,  74,  77,  83, 101, 117,\n",
      "       216, 221, 265, 267, 275, 293], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  7,  21,  26,  36,  71,  77, 101, 117, 216, 221, 267, 275, 293], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8537414965986394, 'RandomForest', (array([  7,  18,  26,  31,  43,  51,  62,  77,  86, 100, 162, 179, 213,\n",
      "       216, 221, 241, 253], dtype=int64),)], [0.87074829931972786, 'XGBoost', (array([  7,  18,  26,  36,  39,  62, 101, 103, 124, 162, 181, 216, 221,\n",
      "       241, 265, 267], dtype=int64),)]]\n",
      "[0.86822489810173431, 0.85120066391419924, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.82059482162153496, 0.85884944197836222]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857146564788\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00800154246602\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   8]\n",
      " [ 27  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       253\n",
      "          1       0.64      0.34      0.44        41\n",
      "\n",
      "avg / total       0.86      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 12,  27,  35,  56,  72,  78,  79,  86, 124, 132, 144, 150, 158,\n",
      "       240, 243, 244, 247, 259, 267, 282, 291, 292], dtype=int64),)]]\n",
      "[0.85714656478810125]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842703742632\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.105369709824\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   5]\n",
      " [ 34   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       253\n",
      "          1       0.58      0.17      0.26        41\n",
      "\n",
      "avg / total       0.84      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 12,  27,  35,  56,  72,  78,  79,  86, 124, 132, 144, 150, 158,\n",
      "       240, 243, 244, 247, 259, 267, 282, 291, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  0,  35,  72,  78,  86, 124, 144, 243, 244, 266, 267, 282], dtype=int64),)]]\n",
      "[0.85714656478810125, 0.84270374263213421]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 12,  27,  35,  56,  72,  78,  79,  86, 124, 132, 144, 150, 158,\n",
      "       240, 243, 244, 247, 259, 267, 282, 291, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  0,  35,  72,  78,  86, 124, 144, 243, 244, 266, 267, 282], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85714656478810125, 0.84270374263213421, 0.83333477765483888]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 12,  27,  35,  56,  72,  78,  79,  86, 124, 132, 144, 150, 158,\n",
      "       240, 243, 244, 247, 259, 267, 282, 291, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  0,  35,  72,  78,  86, 124, 144, 243, 244, 266, 267, 282], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85714656478810125, 0.84270374263213421, 0.83333477765483888, 0.83333477765483888]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 12,  27,  35,  56,  72,  78,  79,  86, 124, 132, 144, 150, 158,\n",
      "       240, 243, 244, 247, 259, 267, 282, 291, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  0,  35,  72,  78,  86, 124, 144, 243, 244, 266, 267, 282], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85714656478810125, 0.84270374263213421, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840966179591\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0203412706064\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   5]\n",
      " [ 31  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       253\n",
      "          1       0.67      0.24      0.36        41\n",
      "\n",
      "avg / total       0.86      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 12,  27,  35,  56,  72,  78,  79,  86, 124, 132, 144, 150, 158,\n",
      "       240, 243, 244, 247, 259, 267, 282, 291, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  0,  35,  72,  78,  86, 124, 144, 243, 244, 266, 267, 282], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87755102040816324, 'RandomForest', (array([  0,   4,  12,  35,  50,  53,  72,  78,  86, 134, 165, 191, 240,\n",
      "       243, 244], dtype=int64),)]]\n",
      "[0.85714656478810125, 0.84270374263213421, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888, 0.84096617959054409]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.894557823129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863114180289\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.105442176871\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.121372794756\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   4]\n",
      " [ 27  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       253\n",
      "          1       0.78      0.34      0.47        41\n",
      "\n",
      "avg / total       0.88      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 12,  27,  35,  56,  72,  78,  79,  86, 124, 132, 144, 150, 158,\n",
      "       240, 243, 244, 247, 259, 267, 282, 291, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  0,  35,  72,  78,  86, 124, 144, 243, 244, 266, 267, 282], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87755102040816324, 'RandomForest', (array([  0,   4,  12,  35,  50,  53,  72,  78,  86, 134, 165, 191, 240,\n",
      "       243, 244], dtype=int64),)], [0.89455782312925169, 'XGBoost', (array([  0,  27,  35,  56,  72,  78,  79,  86, 102, 124, 150, 158, 165,\n",
      "       174, 243, 244, 282, 290], dtype=int64),)]]\n",
      "[0.85714656478810125, 0.84270374263213421, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888, 0.84096617959054409, 0.86311418028877662]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861400495589\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0601639344262\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   5]\n",
      " [ 34  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.92       244\n",
      "          1       0.76      0.32      0.45        50\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 13,  16,  23,  26,  56, 111, 133, 167, 170, 178, 179, 188, 200,\n",
      "       201, 206, 213, 236, 254, 262, 287, 290], dtype=int64),)]]\n",
      "[0.86140049558931897]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846948952166\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0360655737705\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   4]\n",
      " [ 36  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       244\n",
      "          1       0.78      0.28      0.41        50\n",
      "\n",
      "avg / total       0.85      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 13,  16,  23,  26,  56, 111, 133, 167, 170, 178, 179, 188, 200,\n",
      "       201, 206, 213, 236, 254, 262, 287, 290], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 13,  16,  23,  26, 111, 133, 145, 167, 170, 179, 188, 200, 201,\n",
      "       236, 243, 254, 262, 287], dtype=int64),)]]\n",
      "[0.86140049558931897, 0.84694895216632948]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 13,  16,  23,  26,  56, 111, 133, 167, 170, 178, 179, 188, 200,\n",
      "       201, 206, 213, 236, 254, 262, 287, 290], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 13,  16,  23,  26, 111, 133, 145, 167, 170, 179, 188, 200, 201,\n",
      "       236, 243, 254, 262, 287], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86140049558931897, 0.84694895216632948, 0.84098787208212189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 13,  16,  23,  26,  56, 111, 133, 167, 170, 178, 179, 188, 200,\n",
      "       201, 206, 213, 236, 254, 262, 287, 290], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 13,  16,  23,  26, 111, 133, 145, 167, 170, 179, 188, 200, 201,\n",
      "       236, 243, 254, 262, 287], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86140049558931897, 0.84694895216632948, 0.84098787208212189, 0.84098787208212189]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 13,  16,  23,  26,  56, 111, 133, 167, 170, 178, 179, 188, 200,\n",
      "       201, 206, 213, 236, 254, 262, 287, 290], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 13,  16,  23,  26, 111, 133, 145, 167, 170, 179, 188, 200, 201,\n",
      "       236, 243, 254, 262, 287], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86140049558931897, 0.84694895216632948, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843543264191\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233  11]\n",
      " [ 39  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90       244\n",
      "          1       0.50      0.22      0.31        50\n",
      "\n",
      "avg / total       0.80      0.83      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 13,  16,  23,  26,  56, 111, 133, 167, 170, 178, 179, 188, 200,\n",
      "       201, 206, 213, 236, 254, 262, 287, 290], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 13,  16,  23,  26, 111, 133, 145, 167, 170, 179, 188, 200, 201,\n",
      "       236, 243, 254, 262, 287], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([ 12,  13,  20,  69,  87,  91,  96, 105, 111, 114, 117, 133, 167,\n",
      "       170, 178, 182, 188, 200, 204, 208, 262, 287], dtype=int64),)]]\n",
      "[0.86140049558931897, 0.84694895216632948, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189, 0.84354326419139403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863962345642\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0119672131148\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   6]\n",
      " [ 35  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       244\n",
      "          1       0.71      0.30      0.42        50\n",
      "\n",
      "avg / total       0.85      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 13,  16,  23,  26,  56, 111, 133, 167, 170, 178, 179, 188, 200,\n",
      "       201, 206, 213, 236, 254, 262, 287, 290], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 13,  16,  23,  26, 111, 133, 145, 167, 170, 179, 188, 200, 201,\n",
      "       236, 243, 254, 262, 287], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([ 12,  13,  20,  69,  87,  91,  96, 105, 111, 114, 117, 133, 167,\n",
      "       170, 178, 182, 188, 200, 204, 208, 262, 287], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([ 13,  23,  26,  38,  69,  91, 105, 111, 117, 133, 167, 170, 178,\n",
      "       179, 206, 212, 243, 254, 262, 287, 290], dtype=int64),)]]\n",
      "[0.86140049558931897, 0.84694895216632948, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189, 0.84354326419139403, 0.86396234564187446]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867322507053\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00508415147265\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   3]\n",
      " [ 36  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       248\n",
      "          1       0.77      0.22      0.34        46\n",
      "\n",
      "avg / total       0.86      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  25,  49,  66,  72,  78,  89,  93, 152, 225, 256, 259, 289], dtype=int64),)]]\n",
      "[0.86732250705349079]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846074722621\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0823983169705\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   4]\n",
      " [ 38   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       248\n",
      "          1       0.67      0.17      0.28        46\n",
      "\n",
      "avg / total       0.83      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  25,  49,  66,  72,  78,  89,  93, 152, 225, 256, 259, 289], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  48,  66,  72,  78,  93, 152, 157, 256, 259, 285, 289], dtype=int64),)]]\n",
      "[0.86732250705349079, 0.84607472262054506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  25,  49,  66,  72,  78,  89,  93, 152, 225, 256, 259, 289], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  48,  66,  72,  78,  93, 152, 157, 256, 259, 285, 289], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86732250705349079, 0.84607472262054506, 0.83758650047030658]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  25,  49,  66,  72,  78,  89,  93, 152, 225, 256, 259, 289], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  48,  66,  72,  78,  93, 152, 157, 256, 259, 285, 289], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86732250705349079, 0.84607472262054506, 0.83758650047030658, 0.83758650047030658]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  25,  49,  66,  72,  78,  89,  93, 152, 225, 256, 259, 289], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  48,  66,  72,  78,  93, 152, 157, 256, 259, 285, 289], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86732250705349079, 0.84607472262054506, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841810039648\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.159712482468\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   5]\n",
      " [ 40   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       248\n",
      "          1       0.55      0.13      0.21        46\n",
      "\n",
      "avg / total       0.81      0.85      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  25,  49,  66,  72,  78,  89,  93, 152, 225, 256, 259, 289], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  48,  66,  72,  78,  93, 152, 157, 256, 259, 285, 289], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([ 17,  20,  26,  55,  56,  72,  78, 153, 161, 223, 275], dtype=int64),)]]\n",
      "[0.86732250705349079, 0.84607472262054506, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.84181003964811951]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863083799733\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0206872370266\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   3]\n",
      " [ 35  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       248\n",
      "          1       0.79      0.24      0.37        46\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  25,  49,  66,  72,  78,  89,  93, 152, 225, 256, 259, 289], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 25,  48,  66,  72,  78,  93, 152, 157, 256, 259, 285, 289], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([ 17,  20,  26,  55,  56,  72,  78, 153, 161, 223, 275], dtype=int64),)], [0.87074829931972786, 'XGBoost', (array([ 17,  18,  20,  25,  44,  55,  72,  78,  93, 126, 152, 259, 275, 289], dtype=int64),)]]\n",
      "[0.86732250705349079, 0.84607472262054506, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.84181003964811951, 0.86308379973296978]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.894557823129\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863940631015\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.105442176871\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0309954751131\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   7]\n",
      " [ 24  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       260\n",
      "          1       0.59      0.29      0.39        34\n",
      "\n",
      "avg / total       0.88      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([  7,  11,  21,  24,  25,  63,  78,  85,  91, 117, 192, 195, 202,\n",
      "       203, 246, 261, 291], dtype=int64),)]]\n",
      "[0.86394063101510099]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.850352454291\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[255   5]\n",
      " [ 29   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       260\n",
      "          1       0.50      0.15      0.23        34\n",
      "\n",
      "avg / total       0.85      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([  7,  11,  21,  24,  25,  63,  78,  85,  91, 117, 192, 195, 202,\n",
      "       203, 246, 261, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 11,  31,  63,  78,  85, 130, 180, 195, 271, 291], dtype=int64),)]]\n",
      "[0.86394063101510099, 0.85035245429071071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([  7,  11,  21,  24,  25,  63,  78,  85,  91, 117, 192, 195, 202,\n",
      "       203, 246, 261, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 11,  31,  63,  78,  85, 130, 180, 195, 271, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86394063101510099, 0.85035245429071071, 0.82738237456726249]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([  7,  11,  21,  24,  25,  63,  78,  85,  91, 117, 192, 195, 202,\n",
      "       203, 246, 261, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 11,  31,  63,  78,  85, 130, 180, 195, 271, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88435374149659862, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86394063101510099, 0.85035245429071071, 0.82738237456726249, 0.82738237456726249]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([  7,  11,  21,  24,  25,  63,  78,  85,  91, 117, 192, 195, 202,\n",
      "       203, 246, 261, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 11,  31,  63,  78,  85, 130, 180, 195, 271, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88435374149659862, 'KNN', (array([], dtype=int64),)], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86394063101510099, 0.85035245429071071, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.823976642322\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0642533936652\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   7]\n",
      " [ 25   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       260\n",
      "          1       0.56      0.26      0.36        34\n",
      "\n",
      "avg / total       0.87      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([  7,  11,  21,  24,  25,  63,  78,  85,  91, 117, 192, 195, 202,\n",
      "       203, 246, 261, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 11,  31,  63,  78,  85, 130, 180, 195, 271, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88435374149659862, 'KNN', (array([], dtype=int64),)], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.891156462585034, 'RandomForest', (array([  7,  25,  31,  76,  78,  81, 103, 112, 117, 158, 180, 183, 195,\n",
      "       249, 261, 270], dtype=int64),)]]\n",
      "[0.86394063101510099, 0.85035245429071071, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249, 0.82397664232193601]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.904761904762\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857999079707\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0952380952381\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.068778280543\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   7]\n",
      " [ 21  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       260\n",
      "          1       0.65      0.38      0.48        34\n",
      "\n",
      "avg / total       0.89      0.90      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([  7,  11,  21,  24,  25,  63,  78,  85,  91, 117, 192, 195, 202,\n",
      "       203, 246, 261, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 11,  31,  63,  78,  85, 130, 180, 195, 271, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.88435374149659862, 'KNN', (array([], dtype=int64),)], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.891156462585034, 'RandomForest', (array([  7,  25,  31,  76,  78,  81, 103, 112, 117, 158, 180, 183, 195,\n",
      "       249, 261, 270], dtype=int64),)], [0.90476190476190477, 'XGBoost', (array([  1,  11,  21,  24,  28,  31,  34,  41,  76,  85, 112, 117, 180,\n",
      "       195, 223, 226, 241, 250, 261, 291], dtype=int64),)]]\n",
      "[0.86394063101510099, 0.85035245429071071, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249, 0.82397664232193601, 0.85799907970711242]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869025362109\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.261602034329\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[227  15]\n",
      " [ 39  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89       242\n",
      "          1       0.46      0.25      0.33        52\n",
      "\n",
      "avg / total       0.78      0.82      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81632653061224492, 'LogisticRegression', (array([  7,   8,  53,  58,  59,  65,  77,  79,  89,  90,  91,  98, 101,\n",
      "       108, 125, 139, 140, 167, 184, 199, 233, 253, 254, 261, 275, 283,\n",
      "       289, 292], dtype=int64),)]]\n",
      "[0.86902536210855619]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857962219073\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.144787031151\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   6]\n",
      " [ 43   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       242\n",
      "          1       0.60      0.17      0.27        52\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81632653061224492, 'LogisticRegression', (array([  7,   8,  53,  58,  59,  65,  77,  79,  89,  90,  91,  98, 101,\n",
      "       108, 125, 139, 140, 167, 184, 199, 233, 253, 254, 261, 275, 283,\n",
      "       289, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  53,  59,  79,  90,  98, 139, 184, 199, 220, 253, 254, 275,\n",
      "       283, 289], dtype=int64),)]]\n",
      "[0.86902536210855619, 0.85796221907282666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81632653061224492, 'LogisticRegression', (array([  7,   8,  53,  58,  59,  65,  77,  79,  89,  90,  91,  98, 101,\n",
      "       108, 125, 139, 140, 167, 184, 199, 233, 253, 254, 261, 275, 283,\n",
      "       289, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  53,  59,  79,  90,  98, 139, 184, 199, 220, 253, 254, 275,\n",
      "       283, 289], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86902536210855619, 0.85796221907282666, 0.84268856342182852]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81632653061224492, 'LogisticRegression', (array([  7,   8,  53,  58,  59,  65,  77,  79,  89,  90,  91,  98, 101,\n",
      "       108, 125, 139, 140, 167, 184, 199, 233, 253, 254, 261, 275, 283,\n",
      "       289, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  53,  59,  79,  90,  98, 139, 184, 199, 220, 253, 254, 275,\n",
      "       283, 289], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86902536210855619, 0.85796221907282666, 0.84268856342182852, 0.84268856342182852]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81632653061224492, 'LogisticRegression', (array([  7,   8,  53,  58,  59,  65,  77,  79,  89,  90,  91,  98, 101,\n",
      "       108, 125, 139, 140, 167, 184, 199, 233, 253, 254, 261, 275, 283,\n",
      "       289, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  53,  59,  79,  90,  98, 139, 184, 199, 220, 253, 254, 275,\n",
      "       283, 289], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86902536210855619, 0.85796221907282666, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846920757461\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.284965034965\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232  10]\n",
      " [ 45   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.89       242\n",
      "          1       0.41      0.13      0.20        52\n",
      "\n",
      "avg / total       0.76      0.81      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81632653061224492, 'LogisticRegression', (array([  7,   8,  53,  58,  59,  65,  77,  79,  89,  90,  91,  98, 101,\n",
      "       108, 125, 139, 140, 167, 184, 199, 233, 253, 254, 261, 275, 283,\n",
      "       289, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  53,  59,  79,  90,  98, 139, 184, 199, 220, 253, 254, 275,\n",
      "       283, 289], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81292517006802723, 'RandomForest', (array([ 53,  79,  90,  91,  98, 101, 108, 133, 155, 187, 231, 244, 252,\n",
      "       258, 283, 284, 289], dtype=int64),)]]\n",
      "[0.86902536210855619, 0.85796221907282666, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.8469207574610772]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867348526976\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0421169739352\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   5]\n",
      " [ 36  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       242\n",
      "          1       0.76      0.31      0.44        52\n",
      "\n",
      "avg / total       0.85      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81632653061224492, 'LogisticRegression', (array([  7,   8,  53,  58,  59,  65,  77,  79,  89,  90,  91,  98, 101,\n",
      "       108, 125, 139, 140, 167, 184, 199, 233, 253, 254, 261, 275, 283,\n",
      "       289, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  53,  59,  79,  90,  98, 139, 184, 199, 220, 253, 254, 275,\n",
      "       283, 289], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81292517006802723, 'RandomForest', (array([ 53,  79,  90,  91,  98, 101, 108, 133, 155, 187, 231, 244, 252,\n",
      "       258, 283, 284, 289], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([  6,   7,   8,  31,  34,  59,  79,  89,  90,  98, 101, 119, 148,\n",
      "       180, 184, 199, 220, 244, 253, 258, 289], dtype=int64),)]]\n",
      "[0.86902536210855619, 0.85796221907282666, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.8469207574610772, 0.86734852697578646]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861385272109\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0645454545455\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   7]\n",
      " [ 28  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       250\n",
      "          1       0.70      0.36      0.48        44\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  1,  14,  31,  69,  98, 100, 114, 123, 142, 145, 163, 173, 186,\n",
      "       192, 219, 220, 232, 233, 247, 249, 257, 290, 292], dtype=int64),)]]\n",
      "[0.86138527210862215]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852031497409\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.122545454545\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   7]\n",
      " [ 35   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       250\n",
      "          1       0.56      0.20      0.30        44\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  1,  14,  31,  69,  98, 100, 114, 123, 142, 145, 163, 173, 186,\n",
      "       192, 219, 220, 232, 233, 247, 249, 257, 290, 292], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([  1,  14,  23,  31,  63, 114, 123, 142, 145, 220, 223, 232, 233,\n",
      "       278, 283, 292], dtype=int64),)]]\n",
      "[0.86138527210862215, 0.85203149740923034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  1,  14,  31,  69,  98, 100, 114, 123, 142, 145, 163, 173, 186,\n",
      "       192, 219, 220, 232, 233, 247, 249, 257, 290, 292], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([  1,  14,  23,  31,  63, 114, 123, 142, 145, 220, 223, 232, 233,\n",
      "       278, 283, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86138527210862215, 0.85203149740923034, 0.83588580913059995]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  1,  14,  31,  69,  98, 100, 114, 123, 142, 145, 163, 173, 186,\n",
      "       192, 219, 220, 232, 233, 247, 249, 257, 290, 292], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([  1,  14,  23,  31,  63, 114, 123, 142, 145, 220, 223, 232, 233,\n",
      "       278, 283, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86138527210862215, 0.85203149740923034, 0.83588580913059995, 0.83588580913059995]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  1,  14,  31,  69,  98, 100, 114, 123, 142, 145, 163, 173, 186,\n",
      "       192, 219, 220, 232, 233, 247, 249, 257, 290, 292], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([  1,  14,  23,  31,  63, 114, 123, 142, 145, 220, 223, 232, 233,\n",
      "       278, 283, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86138527210862215, 0.85203149740923034, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842673395279\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.282909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   9]\n",
      " [ 39   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91       250\n",
      "          1       0.36      0.11      0.17        44\n",
      "\n",
      "avg / total       0.79      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  1,  14,  31,  69,  98, 100, 114, 123, 142, 145, 163, 173, 186,\n",
      "       192, 219, 220, 232, 233, 247, 249, 257, 290, 292], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([  1,  14,  23,  31,  63, 114, 123, 142, 145, 220, 223, 232, 233,\n",
      "       278, 283, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 14,  31,  58,  69,  84,  98, 114, 162, 179, 218, 224, 231, 232, 243], dtype=int64),)]]\n",
      "[0.86138527210862215, 0.85203149740923034, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.84267339527912066]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866478680199\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   9]\n",
      " [ 35   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.92       250\n",
      "          1       0.50      0.20      0.29        44\n",
      "\n",
      "avg / total       0.82      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  1,  14,  31,  69,  98, 100, 114, 123, 142, 145, 163, 173, 186,\n",
      "       192, 219, 220, 232, 233, 247, 249, 257, 290, 292], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([  1,  14,  23,  31,  63, 114, 123, 142, 145, 220, 223, 232, 233,\n",
      "       278, 283, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 14,  31,  58,  69,  84,  98, 114, 162, 179, 218, 224, 231, 232, 243], dtype=int64),)], [0.85034013605442171, 'XGBoost', (array([ 14,  31, 110, 112, 114, 126, 132, 142, 145, 173, 218, 223, 224,\n",
      "       232, 233, 243, 247, 257], dtype=int64),)]]\n",
      "[0.86138527210862215, 0.85203149740923034, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.84267339527912066, 0.86647868019870866]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86313368693\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0285714285714\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   5]\n",
      " [ 37  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       245\n",
      "          1       0.71      0.24      0.36        49\n",
      "\n",
      "avg / total       0.84      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 47,  61,  81,  82, 117, 120, 190, 213, 214, 228, 231, 237, 241,\n",
      "       245, 264, 286, 288], dtype=int64),)]]\n",
      "[0.86313368692980008]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858866795972\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0530612244898\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   5]\n",
      " [ 38  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       245\n",
      "          1       0.69      0.22      0.34        49\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 47,  61,  81,  82, 117, 120, 190, 213, 214, 228, 231, 237, 241,\n",
      "       245, 264, 286, 288], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 50,  61,  81,  91,  97, 120, 171, 200, 213, 228, 231, 241, 245,\n",
      "       284, 286, 288], dtype=int64),)]]\n",
      "[0.86313368692980008, 0.85886679597162452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 47,  61,  81,  82, 117, 120, 190, 213, 214, 228, 231, 237, 241,\n",
      "       245, 264, 286, 288], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 50,  61,  81,  91,  97, 120, 171, 200, 213, 228, 231, 241, 245,\n",
      "       284, 286, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86313368692980008, 0.85886679597162452, 0.84013753194606755]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 47,  61,  81,  82, 117, 120, 190, 213, 214, 228, 231, 237, 241,\n",
      "       245, 264, 286, 288], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 50,  61,  81,  91,  97, 120, 171, 200, 213, 228, 231, 241, 245,\n",
      "       284, 286, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86313368692980008, 0.85886679597162452, 0.84013753194606755, 0.84013753194606755]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 47,  61,  81,  82, 117, 120, 190, 213, 214, 228, 231, 237, 241,\n",
      "       245, 264, 286, 288], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 50,  61,  81,  91,  97, 120, 171, 200, 213, 228, 231, 241, 245,\n",
      "       284, 286, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86313368692980008, 0.85886679597162452, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846948985369\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.248979591837\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234  11]\n",
      " [ 40   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       245\n",
      "          1       0.45      0.18      0.26        49\n",
      "\n",
      "avg / total       0.79      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 47,  61,  81,  82, 117, 120, 190, 213, 214, 228, 231, 237, 241,\n",
      "       245, 264, 286, 288], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 50,  61,  81,  91,  97, 120, 171, 200, 213, 228, 231, 241, 245,\n",
      "       284, 286, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([  1,  13,  25,  46,  52,  61,  81,  91, 120, 153, 169, 171, 200,\n",
      "       213, 231, 232, 237, 241, 266, 271], dtype=int64),)]]\n",
      "[0.86313368692980008, 0.85886679597162452, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.84694898536912266]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869051382031\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.151020408163\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   7]\n",
      " [ 40   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       245\n",
      "          1       0.56      0.18      0.28        49\n",
      "\n",
      "avg / total       0.81      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 47,  61,  81,  82, 117, 120, 190, 213, 214, 228, 231, 237, 241,\n",
      "       245, 264, 286, 288], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 50,  61,  81,  91,  97, 120, 171, 200, 213, 228, 231, 241, 245,\n",
      "       284, 286, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([  1,  13,  25,  46,  52,  61,  81,  91, 120, 153, 169, 171, 200,\n",
      "       213, 231, 232, 237, 241, 266, 271], dtype=int64),)], [0.84013605442176875, 'XGBoost', (array([ 47,  50,  61,  81,  91, 117, 120, 169, 228, 231, 239, 241, 245,\n",
      "       264, 266, 284], dtype=int64),)]]\n",
      "[0.86313368692980008, 0.85886679597162452, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.84694898536912266, 0.86905138203085197]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.855419886729\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0464586255259\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   8]\n",
      " [ 29  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       248\n",
      "          1       0.68      0.37      0.48        46\n",
      "\n",
      "avg / total       0.86      0.87      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 11,  14,  19,  23,  40,  50,  72,  90, 100, 104, 131, 141, 144,\n",
      "       155, 163, 171, 180, 189, 205, 216, 234, 238, 263, 291, 293], dtype=int64),)]]\n",
      "[0.85541988672889213]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85967810069\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0823983169705\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238  10]\n",
      " [ 32  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92       248\n",
      "          1       0.58      0.30      0.40        46\n",
      "\n",
      "avg / total       0.83      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 11,  14,  19,  23,  40,  50,  72,  90, 100, 104, 131, 141, 144,\n",
      "       155, 163, 171, 180, 189, 205, 216, 234, 238, 263, 291, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 11,  14,  19,  23,  31,  40,  49,  50,  72, 106, 131, 141, 144,\n",
      "       155, 163, 170, 180, 189, 205, 216, 234, 238, 259, 293], dtype=int64),)]]\n",
      "[0.85541988672889213, 0.8596781006904366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 11,  14,  19,  23,  40,  50,  72,  90, 100, 104, 131, 141, 144,\n",
      "       155, 163, 171, 180, 189, 205, 216, 234, 238, 263, 291, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 11,  14,  19,  23,  31,  40,  49,  50,  72, 106, 131, 141, 144,\n",
      "       155, 163, 170, 180, 189, 205, 216, 234, 238, 259, 293], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85541988672889213, 0.8596781006904366, 0.83758650047030658]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 11,  14,  19,  23,  40,  50,  72,  90, 100, 104, 131, 141, 144,\n",
      "       155, 163, 171, 180, 189, 205, 216, 234, 238, 263, 291, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 11,  14,  19,  23,  31,  40,  49,  50,  72, 106, 131, 141, 144,\n",
      "       155, 163, 170, 180, 189, 205, 216, 234, 238, 259, 293], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85541988672889213, 0.8596781006904366, 0.83758650047030658, 0.83758650047030658]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 11,  14,  19,  23,  40,  50,  72,  90, 100, 104, 131, 141, 144,\n",
      "       155, 163, 171, 180, 189, 205, 216, 234, 238, 263, 291, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 11,  14,  19,  23,  31,  40,  49,  50,  72, 106, 131, 141, 144,\n",
      "       155, 163, 170, 180, 189, 205, 216, 234, 238, 259, 293], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85541988672889213, 0.8596781006904366, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239617033\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.237026647966\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237  11]\n",
      " [ 37   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91       248\n",
      "          1       0.45      0.20      0.27        46\n",
      "\n",
      "avg / total       0.80      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 11,  14,  19,  23,  40,  50,  72,  90, 100, 104, 131, 141, 144,\n",
      "       155, 163, 171, 180, 189, 205, 216, 234, 238, 263, 291, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 11,  14,  19,  23,  31,  40,  49,  50,  72, 106, 131, 141, 144,\n",
      "       155, 163, 170, 180, 189, 205, 216, 234, 238, 259, 293], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([  8,  12,  14,  40,  50,  57, 102, 108, 141, 154, 163, 171, 189,\n",
      "       205, 216, 234, 239, 259, 291, 292], dtype=int64),)]]\n",
      "[0.85541988672889213, 0.8596781006904366, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.84523961703278505]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860532779325\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0566269284712\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   7]\n",
      " [ 34  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       248\n",
      "          1       0.63      0.26      0.37        46\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 11,  14,  19,  23,  40,  50,  72,  90, 100, 104, 131, 141, 144,\n",
      "       155, 163, 171, 180, 189, 205, 216, 234, 238, 263, 291, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 11,  14,  19,  23,  31,  40,  49,  50,  72, 106, 131, 141, 144,\n",
      "       155, 163, 170, 180, 189, 205, 216, 234, 238, 259, 293], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([  8,  12,  14,  40,  50,  57, 102, 108, 141, 154, 163, 171, 189,\n",
      "       205, 216, 234, 239, 259, 291, 292], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([ 14,  19,  31,  40,  50,  72, 141, 155, 163, 170, 171, 180, 181,\n",
      "       189, 205, 216, 234, 238, 259], dtype=int64),)]]\n",
      "[0.85541988672889213, 0.8596781006904366, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.84523961703278505, 0.86053277932480654]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.868198856044\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0332733108902\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   6]\n",
      " [ 36  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       241\n",
      "          1       0.74      0.32      0.45        53\n",
      "\n",
      "avg / total       0.84      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 19,  20,  25,  37,  39,  58,  61,  63,  80,  97, 152, 155, 168,\n",
      "       179, 181, 187, 217, 245, 260, 262, 267, 272, 290], dtype=int64),)]]\n",
      "[0.86819885604424307]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858853780477\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0127612933532\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   9]\n",
      " [ 35  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       241\n",
      "          1       0.67      0.34      0.45        53\n",
      "\n",
      "avg / total       0.83      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 19,  20,  25,  37,  39,  58,  61,  63,  80,  97, 152, 155, 168,\n",
      "       179, 181, 187, 217, 245, 260, 262, 267, 272, 290], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 19,  20,  25,  37,  39,  51,  56,  58,  61,  63,  80,  97, 152,\n",
      "       155, 164, 176, 179, 181, 187, 207, 210, 217, 238, 245, 260, 267, 272], dtype=int64),)]]\n",
      "[0.86819885604424307, 0.85885378047667782]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 19,  20,  25,  37,  39,  58,  61,  63,  80,  97, 152, 155, 168,\n",
      "       179, 181, 187, 217, 245, 260, 262, 267, 272, 290], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 19,  20,  25,  37,  39,  51,  56,  58,  61,  63,  80,  97, 152,\n",
      "       155, 164, 176, 179, 181, 187, 207, 210, 217, 238, 245, 260, 267, 272], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86819885604424307, 0.85885378047667782, 0.84353890355788297]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 19,  20,  25,  37,  39,  58,  61,  63,  80,  97, 152, 155, 168,\n",
      "       179, 181, 187, 217, 245, 260, 262, 267, 272, 290], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 19,  20,  25,  37,  39,  51,  56,  58,  61,  63,  80,  97, 152,\n",
      "       155, 164, 176, 179, 181, 187, 207, 210, 217, 238, 245, 260, 267, 272], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86819885604424307, 0.85885378047667782, 0.84353890355788297, 0.84353890355788297]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 19,  20,  25,  37,  39,  58,  61,  63,  80,  97, 152, 155, 168,\n",
      "       179, 181, 187, 217, 245, 260, 262, 267, 272, 290], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 19,  20,  25,  37,  39,  51,  56,  58,  61,  63,  80,  97, 152,\n",
      "       155, 164, 176, 179, 181, 187, 207, 210, 217, 238, 245, 260, 267, 272], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86819885604424307, 0.85885378047667782, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.173882408205\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   5]\n",
      " [ 46   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       241\n",
      "          1       0.58      0.13      0.22        53\n",
      "\n",
      "avg / total       0.79      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 19,  20,  25,  37,  39,  58,  61,  63,  80,  97, 152, 155, 168,\n",
      "       179, 181, 187, 217, 245, 260, 262, 267, 272, 290], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 19,  20,  25,  37,  39,  51,  56,  58,  61,  63,  80,  97, 152,\n",
      "       155, 164, 176, 179, 181, 187, 207, 210, 217, 238, 245, 260, 267, 272], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([ 37,  39,  58,  80, 117, 155, 176, 187, 196, 235, 245, 272], dtype=int64),)]]\n",
      "[0.86819885604424307, 0.85885378047667782, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297, 0.83588580913059995]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867350679624\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.127847803961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   9]\n",
      " [ 40  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       241\n",
      "          1       0.59      0.25      0.35        53\n",
      "\n",
      "avg / total       0.81      0.83      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 19,  20,  25,  37,  39,  58,  61,  63,  80,  97, 152, 155, 168,\n",
      "       179, 181, 187, 217, 245, 260, 262, 267, 272, 290], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 19,  20,  25,  37,  39,  51,  56,  58,  61,  63,  80,  97, 152,\n",
      "       155, 164, 176, 179, 181, 187, 207, 210, 217, 238, 245, 260, 267, 272], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([ 37,  39,  58,  80, 117, 155, 176, 187, 196, 235, 245, 272], dtype=int64),)], [0.83333333333333337, 'XGBoost', (array([ 11,  19,  20,  25,  39,  58,  61,  80,  96, 100, 155, 176, 181,\n",
      "       187, 196, 217, 224, 256, 260, 272, 274, 290], dtype=int64),)]]\n",
      "[0.86819885604424307, 0.85885378047667782, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297, 0.83588580913059995, 0.86735067962354762]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.870749876452\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.175510204082\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235  10]\n",
      " [ 38  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91       245\n",
      "          1       0.52      0.22      0.31        49\n",
      "\n",
      "avg / total       0.80      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83673469387755106, 'LogisticRegression', (array([ 26,  27,  65,  67,  81,  88,  95, 100, 112, 127, 174, 182, 184,\n",
      "       195, 210, 228, 239, 247, 258, 270, 272], dtype=int64),)]]\n",
      "[0.87074987645240631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863960148724\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126530612245\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   2]\n",
      " [ 44   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.91       245\n",
      "          1       0.71      0.10      0.18        49\n",
      "\n",
      "avg / total       0.82      0.84      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83673469387755106, 'LogisticRegression', (array([ 26,  27,  65,  67,  81,  88,  95, 100, 112, 127, 174, 182, 184,\n",
      "       195, 210, 228, 239, 247, 258, 270, 272], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 26,  81,  95, 127, 174, 195, 205], dtype=int64),)]]\n",
      "[0.87074987645240631, 0.86396014872372229]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83673469387755106, 'LogisticRegression', (array([ 26,  27,  65,  67,  81,  88,  95, 100, 112, 127, 174, 182, 184,\n",
      "       195, 210, 228, 239, 247, 258, 270, 272], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 26,  81,  95, 127, 174, 195, 205], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87074987645240631, 0.86396014872372229, 0.84013753194606755]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83673469387755106, 'LogisticRegression', (array([ 26,  27,  65,  67,  81,  88,  95, 100, 112, 127, 174, 182, 184,\n",
      "       195, 210, 228, 239, 247, 258, 270, 272], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 26,  81,  95, 127, 174, 195, 205], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87074987645240631, 0.86396014872372229, 0.84013753194606755, 0.84013753194606755]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83673469387755106, 'LogisticRegression', (array([ 26,  27,  65,  67,  81,  88,  95, 100, 112, 127, 174, 182, 184,\n",
      "       195, 210, 228, 239, 247, 258, 270, 272], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 26,  81,  95, 127, 174, 195, 205], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87074987645240631, 0.86396014872372229, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839282820109\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00408163265306\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   4]\n",
      " [ 37  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       245\n",
      "          1       0.75      0.24      0.37        49\n",
      "\n",
      "avg / total       0.85      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83673469387755106, 'LogisticRegression', (array([ 26,  27,  65,  67,  81,  88,  95, 100, 112, 127, 174, 182, 184,\n",
      "       195, 210, 228, 239, 247, 258, 270, 272], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 26,  81,  95, 127, 174, 195, 205], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86054421768707479, 'RandomForest', (array([  7,  11,  26,  27,  61,  81,  85,  88,  95, 100, 112, 122, 163,\n",
      "       182, 186, 290], dtype=int64),)]]\n",
      "[0.87074987645240631, 0.86396014872372229, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.8392828201089042]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.870743363171\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126530612245\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   8]\n",
      " [ 38  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       245\n",
      "          1       0.58      0.22      0.32        49\n",
      "\n",
      "avg / total       0.81      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.83673469387755106, 'LogisticRegression', (array([ 26,  27,  65,  67,  81,  88,  95, 100, 112, 127, 174, 182, 184,\n",
      "       195, 210, 228, 239, 247, 258, 270, 272], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 26,  81,  95, 127, 174, 195, 205], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86054421768707479, 'RandomForest', (array([  7,  11,  26,  27,  61,  81,  85,  88,  95, 100, 112, 122, 163,\n",
      "       182, 186, 290], dtype=int64),)], [0.84353741496598644, 'XGBoost', (array([ 26,  27,  61,  67,  88,  95, 100, 112, 122, 127, 168, 182, 239,\n",
      "       247, 258, 263, 272, 275, 281], dtype=int64),)]]\n",
      "[0.87074987645240631, 0.86396014872372229, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.8392828201089042, 0.8707433631711341]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.897959183673\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852912207033\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.102040816327\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0724576716795\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   7]\n",
      " [ 23  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       257\n",
      "          1       0.67      0.38      0.48        37\n",
      "\n",
      "avg / total       0.88      0.90      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  1,  19,  37,  79,  82,  84, 101, 103, 124, 150, 169, 188, 190,\n",
      "       193, 203, 213, 253, 254, 259, 265, 270], dtype=int64),)]]\n",
      "[0.8529122070334938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846076908471\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0106215164581\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   3]\n",
      " [ 29   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94       257\n",
      "          1       0.73      0.22      0.33        37\n",
      "\n",
      "avg / total       0.88      0.89      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  1,  19,  37,  79,  82,  84, 101, 103, 124, 150, 169, 188, 190,\n",
      "       193, 203, 213, 253, 254, 259, 265, 270], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  37,  45,  79,  84, 150, 190, 193, 253, 254, 259], dtype=int64),)]]\n",
      "[0.8529122070334938, 0.8460769084710994]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829933406043\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.143968871595\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[257   0]\n",
      " [ 37   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       257\n",
      "\n",
      "avg / total       0.87      1.00      0.93       257\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  1,  19,  37,  79,  82,  84, 101, 103, 124, 150, 169, 188, 190,\n",
      "       193, 203, 213, 253, 254, 259, 265, 270], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  37,  45,  79,  84, 150, 190, 193, 253, 254, 259], dtype=int64),)], [0.87414965986394555, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8529122070334938, 0.8460769084710994, 0.82993340604302335]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829933406043\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.143968871595\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[257   0]\n",
      " [ 37   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       257\n",
      "\n",
      "avg / total       0.87      1.00      0.93       257\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  1,  19,  37,  79,  82,  84, 101, 103, 124, 150, 169, 188, 190,\n",
      "       193, 203, 213, 253, 254, 259, 265, 270], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  37,  45,  79,  84, 150, 190, 193, 253, 254, 259], dtype=int64),)], [0.87414965986394555, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87414965986394555, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8529122070334938, 0.8460769084710994, 0.82993340604302335, 0.82993340604302335]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829933406043\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.143968871595\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[257   0]\n",
      " [ 37   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       257\n",
      "\n",
      "avg / total       0.87      1.00      0.93       257\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  1,  19,  37,  79,  82,  84, 101, 103, 124, 150, 169, 188, 190,\n",
      "       193, 203, 213, 253, 254, 259, 265, 270], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  37,  45,  79,  84, 150, 190, 193, 253, 254, 259], dtype=int64),)], [0.87414965986394555, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87414965986394555, 'KNN', (array([], dtype=int64),)], [0.87414965986394555, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8529122070334938, 0.8460769084710994, 0.82993340604302335, 0.82993340604302335, 0.82993340604302335]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.828224048774\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.113050793985\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   7]\n",
      " [ 29   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       257\n",
      "          1       0.53      0.22      0.31        37\n",
      "\n",
      "avg / total       0.85      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  1,  19,  37,  79,  82,  84, 101, 103, 124, 150, 169, 188, 190,\n",
      "       193, 203, 213, 253, 254, 259, 265, 270], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  37,  45,  79,  84, 150, 190, 193, 253, 254, 259], dtype=int64),)], [0.87414965986394555, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87414965986394555, 'KNN', (array([], dtype=int64),)], [0.87414965986394555, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87755102040816324, 'RandomForest', (array([ 32,  42,  43,  79,  84, 150, 157, 180, 188, 193, 251, 253, 254,\n",
      "       258, 259], dtype=int64),)]]\n",
      "[0.8529122070334938, 0.8460769084710994, 0.82993340604302335, 0.82993340604302335, 0.82993340604302335, 0.82822404877428346]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.904761904762\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86310551436\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0952380952381\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.134293826901\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   4]\n",
      " [ 24  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95       257\n",
      "          1       0.76      0.35      0.48        37\n",
      "\n",
      "avg / total       0.89      0.90      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89795918367346939, 'LogisticRegression', (array([  1,  19,  37,  79,  82,  84, 101, 103, 124, 150, 169, 188, 190,\n",
      "       193, 203, 213, 253, 254, 259, 265, 270], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  37,  45,  79,  84, 150, 190, 193, 253, 254, 259], dtype=int64),)], [0.87414965986394555, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87414965986394555, 'KNN', (array([], dtype=int64),)], [0.87414965986394555, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87755102040816324, 'RandomForest', (array([ 32,  42,  43,  79,  84, 150, 157, 180, 188, 193, 251, 253, 254,\n",
      "       258, 259], dtype=int64),)], [0.90476190476190477, 'XGBoost', (array([ 37,  42,  45,  79,  91,  97, 101, 124, 145, 157, 188, 190, 205,\n",
      "       213, 251, 254, 279], dtype=int64),)]]\n",
      "[0.8529122070334938, 0.8460769084710994, 0.82993340604302335, 0.82993340604302335, 0.82993340604302335, 0.82822404877428346, 0.86310551435974325]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860543620037\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.151020408163\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   8]\n",
      " [ 39  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       245\n",
      "          1       0.56      0.20      0.30        49\n",
      "\n",
      "avg / total       0.81      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'one_indices' (tuple)\n",
      "[[0.84013605442176875, 'LogisticRegression', (array([  8,  15,  75,  88,  92, 102, 112, 140, 150, 152, 195, 222, 223,\n",
      "       225, 232, 273, 275, 283], dtype=int64),)]]\n",
      "[0.86054362003679674]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853749531675\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.151020408163\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   8]\n",
      " [ 39  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       245\n",
      "          1       0.56      0.20      0.30        49\n",
      "\n",
      "avg / total       0.81      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84013605442176875, 'LogisticRegression', (array([  8,  15,  75,  88,  92, 102, 112, 140, 150, 152, 195, 222, 223,\n",
      "       225, 232, 273, 275, 283], dtype=int64),)], [0.84013605442176875, 'SelectKBest+LR', (array([  6,  15,  88,  92,  99, 102, 112, 150, 152, 195, 214, 222, 223,\n",
      "       225, 232, 240, 273, 283], dtype=int64),)]]\n",
      "[0.86054362003679674, 0.85374953167460144]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84013605442176875, 'LogisticRegression', (array([  8,  15,  75,  88,  92, 102, 112, 140, 150, 152, 195, 222, 223,\n",
      "       225, 232, 273, 275, 283], dtype=int64),)], [0.84013605442176875, 'SelectKBest+LR', (array([  6,  15,  88,  92,  99, 102, 112, 150, 152, 195, 214, 222, 223,\n",
      "       225, 232, 240, 273, 283], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86054362003679674, 0.85374953167460144, 0.84013753194606755]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84013605442176875, 'LogisticRegression', (array([  8,  15,  75,  88,  92, 102, 112, 140, 150, 152, 195, 222, 223,\n",
      "       225, 232, 273, 275, 283], dtype=int64),)], [0.84013605442176875, 'SelectKBest+LR', (array([  6,  15,  88,  92,  99, 102, 112, 150, 152, 195, 214, 222, 223,\n",
      "       225, 232, 240, 273, 283], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86054362003679674, 0.85374953167460144, 0.84013753194606755, 0.84013753194606755]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84013605442176875, 'LogisticRegression', (array([  8,  15,  75,  88,  92, 102, 112, 140, 150, 152, 195, 222, 223,\n",
      "       225, 232, 273, 275, 283], dtype=int64),)], [0.84013605442176875, 'SelectKBest+LR', (array([  6,  15,  88,  92,  99, 102, 112, 150, 152, 195, 214, 222, 223,\n",
      "       225, 232, 240, 273, 283], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86054362003679674, 0.85374953167460144, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836736127131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.297959183673\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234  11]\n",
      " [ 42   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       245\n",
      "          1       0.39      0.14      0.21        49\n",
      "\n",
      "avg / total       0.77      0.82      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84013605442176875, 'LogisticRegression', (array([  8,  15,  75,  88,  92, 102, 112, 140, 150, 152, 195, 222, 223,\n",
      "       225, 232, 273, 275, 283], dtype=int64),)], [0.84013605442176875, 'SelectKBest+LR', (array([  6,  15,  88,  92,  99, 102, 112, 150, 152, 195, 214, 222, 223,\n",
      "       225, 232, 240, 273, 283], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([ 15,  26,  37,  55,  75,  87,  97, 102, 108, 146, 150, 152, 155,\n",
      "       195, 221, 223, 232, 273], dtype=int64),)]]\n",
      "[0.86054362003679674, 0.85374953167460144, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.83673612713145884]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86821405739\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0938775510204\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   6]\n",
      " [ 31  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       245\n",
      "          1       0.75      0.37      0.49        49\n",
      "\n",
      "avg / total       0.86      0.87      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84013605442176875, 'LogisticRegression', (array([  8,  15,  75,  88,  92, 102, 112, 140, 150, 152, 195, 222, 223,\n",
      "       225, 232, 273, 275, 283], dtype=int64),)], [0.84013605442176875, 'SelectKBest+LR', (array([  6,  15,  88,  92,  99, 102, 112, 150, 152, 195, 214, 222, 223,\n",
      "       225, 232, 240, 273, 283], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([ 15,  26,  37,  55,  75,  87,  97, 102, 108, 146, 150, 152, 155,\n",
      "       195, 221, 223, 232, 273], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([  8,  14,  15,  57,  65,  66,  75,  99, 102, 112, 120, 134, 146,\n",
      "       150, 155, 181, 195, 200, 214, 223, 225, 232, 273, 275], dtype=int64),)]]\n",
      "[0.86054362003679674, 0.85374953167460144, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.83673612713145884, 0.86821405738974422]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856317906076\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0996062992126\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   7]\n",
      " [ 31   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       254\n",
      "          1       0.56      0.23      0.32        40\n",
      "\n",
      "avg / total       0.84      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 11,  30,  42,  44,  55,  60,  92, 101, 137, 217, 226, 239, 253,\n",
      "       269, 277, 286], dtype=int64),)]]\n",
      "[0.85631790607602698]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840139662459\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0417322834646\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   2]\n",
      " [ 34   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       254\n",
      "          1       0.75      0.15      0.25        40\n",
      "\n",
      "avg / total       0.86      0.88      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 11,  30,  42,  44,  55,  60,  92, 101, 137, 217, 226, 239, 253,\n",
      "       269, 277, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([ 11,  42,  92, 123, 137, 217, 226, 286], dtype=int64),)]]\n",
      "[0.85631790607602698, 0.84013966245863314]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 11,  30,  42,  44,  55,  60,  92, 101, 137, 217, 226, 239, 253,\n",
      "       269, 277, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([ 11,  42,  92, 123, 137, 217, 226, 286], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85631790607602698, 0.84013966245863314, 0.83248443751878443]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 11,  30,  42,  44,  55,  60,  92, 101, 137, 217, 226, 239, 253,\n",
      "       269, 277, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([ 11,  42,  92, 123, 137, 217, 226, 286], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85631790607602698, 0.84013966245863314, 0.83248443751878443, 0.83248443751878443]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 11,  30,  42,  44,  55,  60,  92, 101, 137, 217, 226, 239, 253,\n",
      "       269, 277, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([ 11,  42,  92, 123, 137, 217, 226, 286], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85631790607602698, 0.84013966245863314, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844410958321\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.186417322835\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242  12]\n",
      " [ 29  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92       254\n",
      "          1       0.48      0.28      0.35        40\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 11,  30,  42,  44,  55,  60,  92, 101, 137, 217, 226, 239, 253,\n",
      "       269, 277, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([ 11,  42,  92, 123, 137, 217, 226, 286], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86054421768707479, 'RandomForest', (array([ 11,  24,  30,  42,  60,  80,  85,  86,  94,  97,  98, 123, 170,\n",
      "       186, 208, 226, 237, 244, 253, 257, 271, 274, 277], dtype=int64),)]]\n",
      "[0.85631790607602698, 0.84013966245863314, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443, 0.84441095832071078]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863940642083\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0417322834646\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   9]\n",
      " [ 27  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       254\n",
      "          1       0.59      0.33      0.42        40\n",
      "\n",
      "avg / total       0.86      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 11,  30,  42,  44,  55,  60,  92, 101, 137, 217, 226, 239, 253,\n",
      "       269, 277, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([ 11,  42,  92, 123, 137, 217, 226, 286], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86054421768707479, 'RandomForest', (array([ 11,  24,  30,  42,  60,  80,  85,  86,  94,  97,  98, 123, 170,\n",
      "       186, 208, 226, 237, 244, 253, 257, 271, 274, 277], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([ 11,  21,  24,  30,  42,  55,  60,  85, 123, 137, 147, 158, 170,\n",
      "       193, 198, 208, 217, 226, 237, 253, 257, 269], dtype=int64),)]]\n",
      "[0.85631790607602698, 0.84013966245863314, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443, 0.84441095832071078, 0.86394064208269883]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85203368326\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.037643207856\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   5]\n",
      " [ 33  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       247\n",
      "          1       0.74      0.30      0.42        47\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87074829931972786, 'LogisticRegression', (array([  9,  31,  43,  76, 108, 116, 118, 138, 145, 165, 198, 202, 204,\n",
      "       209, 218, 220, 252, 261, 270], dtype=int64),)]]\n",
      "[0.85203368325978468]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852886176044\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0383323283659\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   3]\n",
      " [ 38   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       247\n",
      "          1       0.75      0.19      0.31        47\n",
      "\n",
      "avg / total       0.85      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  9,  31,  43,  76, 108, 116, 118, 138, 145, 165, 198, 202, 204,\n",
      "       209, 218, 220, 252, 261, 270], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 25,  31,  43,  76, 108, 116, 165, 198, 204, 209, 220, 270], dtype=int64),)]]\n",
      "[0.85203368325978468, 0.85288617604360029]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  9,  31,  43,  76, 108, 116, 118, 138, 145, 165, 198, 202, 204,\n",
      "       209, 218, 220, 252, 261, 270], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 25,  31,  43,  76, 108, 116, 165, 198, 204, 209, 220, 270], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85203368325978468, 0.85288617604360029, 0.83843684060636081]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  9,  31,  43,  76, 108, 116, 118, 138, 145, 165, 198, 202, 204,\n",
      "       209, 218, 220, 252, 261, 270], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 25,  31,  43,  76, 108, 116, 165, 198, 204, 209, 220, 270], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85203368325978468, 0.85288617604360029, 0.83843684060636081, 0.83843684060636081]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  9,  31,  43,  76, 108, 116, 118, 138, 145, 165, 198, 202, 204,\n",
      "       209, 218, 220, 252, 261, 270], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 25,  31,  43,  76, 108, 116, 165, 198, 204, 209, 220, 270], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85203368325978468, 0.85288617604360029, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846935936671\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.139633043328\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   3]\n",
      " [ 42   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       247\n",
      "          1       0.62      0.11      0.18        47\n",
      "\n",
      "avg / total       0.82      0.85      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  9,  31,  43,  76, 108, 116, 118, 138, 145, 165, 198, 202, 204,\n",
      "       209, 218, 220, 252, 261, 270], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 25,  31,  43,  76, 108, 116, 165, 198, 204, 209, 220, 270], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([ 25,  43, 108, 165, 176, 198, 252, 270], dtype=int64),)]]\n",
      "[0.85203368325978468, 0.85288617604360029, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081, 0.84693593667138278]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86310984179\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0130071496253\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   2]\n",
      " [ 38   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       247\n",
      "          1       0.82      0.19      0.31        47\n",
      "\n",
      "avg / total       0.86      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  9,  31,  43,  76, 108, 116, 118, 138, 145, 165, 198, 202, 204,\n",
      "       209, 218, 220, 252, 261, 270], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 25,  31,  43,  76, 108, 116, 165, 198, 204, 209, 220, 270], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([ 25,  43, 108, 165, 176, 198, 252, 270], dtype=int64),)], [0.86394557823129248, 'XGBoost', (array([ 43,  65,  87, 108, 116, 118, 187, 195, 198, 209, 270], dtype=int64),)]]\n",
      "[0.85203368325978468, 0.85288617604360029, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081, 0.84693593667138278, 0.86310984179046102]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865637017059\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0351153525433\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   3]\n",
      " [ 35   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       251\n",
      "          1       0.73      0.19      0.30        43\n",
      "\n",
      "avg / total       0.85      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 37,  40,  80,  87, 149, 157, 167, 215, 221, 225, 261], dtype=int64),)]]\n",
      "[0.8656370170592852]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.847792823292\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.116834985639\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   3]\n",
      " [ 38   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       251\n",
      "          1       0.62      0.12      0.20        43\n",
      "\n",
      "avg / total       0.83      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 37,  40,  80,  87, 149, 157, 167, 215, 221, 225, 261], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 37,  80,  87, 149, 157, 167, 221, 291], dtype=int64),)]]\n",
      "[0.8656370170592852, 0.84779282329150263]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 37,  40,  80,  87, 149, 157, 167, 215, 221, 225, 261], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 37,  80,  87, 149, 157, 167, 221, 291], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8656370170592852, 0.84779282329150263, 0.83503546899454539]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 37,  40,  80,  87, 149, 157, 167, 215, 221, 225, 261], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 37,  80,  87, 149, 157, 167, 221, 291], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8656370170592852, 0.84779282329150263, 0.83503546899454539, 0.83503546899454539]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 37,  40,  80,  87, 149, 157, 167, 215, 221, 225, 261], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 37,  80,  87, 149, 157, 167, 221, 291], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8656370170592852, 0.84779282329150263, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836742673616\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.144074863337\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   6]\n",
      " [ 36   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       251\n",
      "          1       0.54      0.16      0.25        43\n",
      "\n",
      "avg / total       0.82      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 37,  40,  80,  87, 149, 157, 167, 215, 221, 225, 261], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 37,  80,  87, 149, 157, 167, 221, 291], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 19,  43,  80, 156, 157, 159, 167, 185, 196, 203, 221, 225, 228], dtype=int64),)]]\n",
      "[0.8656370170592852, 0.84779282329150263, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.83674267361552435]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852886187111\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.101084035949\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   5]\n",
      " [ 28  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       251\n",
      "          1       0.75      0.35      0.48        43\n",
      "\n",
      "avg / total       0.88      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 37,  40,  80,  87, 149, 157, 167, 215, 221, 225, 261], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 37,  80,  87, 149, 157, 167, 221, 291], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 19,  43,  80, 156, 157, 159, 167, 185, 196, 203, 221, 225, 228], dtype=int64),)], [0.88775510204081631, 'XGBoost', (array([ 37,  40,  80,  87,  90, 119, 137, 149, 157, 162, 167, 175, 185,\n",
      "       187, 198, 203, 215, 225, 232, 284], dtype=int64),)]]\n",
      "[0.8656370170592852, 0.84779282329150263, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.83674267361552435, 0.85288618711119801]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.874986420058\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00135869565217\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[226   4]\n",
      " [ 46  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90       230\n",
      "          1       0.82      0.28      0.42        64\n",
      "\n",
      "avg / total       0.83      0.83      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  2,  13,  15,  21,  28,  68,  92,  95, 103, 117, 130, 135, 136,\n",
      "       145, 157, 164, 215, 229, 236, 241, 246, 249], dtype=int64),)]]\n",
      "[0.87498642005756844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862229110031\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0785326086957\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[228   2]\n",
      " [ 52  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.99      0.89       230\n",
      "          1       0.86      0.19      0.31        64\n",
      "\n",
      "avg / total       0.82      0.82      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  2,  13,  15,  21,  28,  68,  92,  95, 103, 117, 130, 135, 136,\n",
      "       145, 157, 164, 215, 229, 236, 241, 246, 249], dtype=int64),)], [0.81632653061224492, 'SelectKBest+LR', (array([ 13,  21,  28,  33,  68,  95, 103, 145, 178, 194, 215, 229, 236, 249], dtype=int64),)]]\n",
      "[0.87498642005756844, 0.86222911003100211]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.78231292517\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852892689325\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.21768707483\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.278260869565\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230   0]\n",
      " [ 64   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88       230\n",
      "\n",
      "avg / total       0.78      1.00      0.88       230\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  2,  13,  15,  21,  28,  68,  92,  95, 103, 117, 130, 135, 136,\n",
      "       145, 157, 164, 215, 229, 236, 241, 246, 249], dtype=int64),)], [0.81632653061224492, 'SelectKBest+LR', (array([ 13,  21,  28,  33,  68,  95, 103, 145, 178, 194, 215, 229, 236, 249], dtype=int64),)], [0.78231292517006801, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87498642005756844, 0.86222911003100211, 0.8528926893248725]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.78231292517\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852892689325\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.21768707483\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.278260869565\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230   0]\n",
      " [ 64   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88       230\n",
      "\n",
      "avg / total       0.78      1.00      0.88       230\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  2,  13,  15,  21,  28,  68,  92,  95, 103, 117, 130, 135, 136,\n",
      "       145, 157, 164, 215, 229, 236, 241, 246, 249], dtype=int64),)], [0.81632653061224492, 'SelectKBest+LR', (array([ 13,  21,  28,  33,  68,  95, 103, 145, 178, 194, 215, 229, 236, 249], dtype=int64),)], [0.78231292517006801, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78231292517006801, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87498642005756844, 0.86222911003100211, 0.8528926893248725, 0.8528926893248725]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.78231292517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852892689325\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.21768707483\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.278260869565\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230   0]\n",
      " [ 64   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88       230\n",
      "\n",
      "avg / total       0.78      1.00      0.88       230\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  2,  13,  15,  21,  28,  68,  92,  95, 103, 117, 130, 135, 136,\n",
      "       145, 157, 164, 215, 229, 236, 241, 246, 249], dtype=int64),)], [0.81632653061224492, 'SelectKBest+LR', (array([ 13,  21,  28,  33,  68,  95, 103, 145, 178, 194, 215, 229, 236, 249], dtype=int64),)], [0.78231292517006801, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78231292517006801, 'KNN', (array([], dtype=int64),)], [0.78231292517006801, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87498642005756844, 0.86222911003100211, 0.8528926893248725, 0.8528926893248725, 0.8528926893248725]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.785714285714\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85970627326\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.214285714286\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.258288043478\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[222   8]\n",
      " [ 55   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.97      0.88       230\n",
      "          1       0.53      0.14      0.22        64\n",
      "\n",
      "avg / total       0.74      0.79      0.73       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  2,  13,  15,  21,  28,  68,  92,  95, 103, 117, 130, 135, 136,\n",
      "       145, 157, 164, 215, 229, 236, 241, 246, 249], dtype=int64),)], [0.81632653061224492, 'SelectKBest+LR', (array([ 13,  21,  28,  33,  68,  95, 103, 145, 178, 194, 215, 229, 236, 249], dtype=int64),)], [0.78231292517006801, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78231292517006801, 'KNN', (array([], dtype=int64),)], [0.78231292517006801, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.7857142857142857, 'RandomForest', (array([  7,  21,  28,  44,  48,  54,  70,  92,  93, 100, 118, 122, 145,\n",
      "       195, 236, 249, 256], dtype=int64),)]]\n",
      "[0.87498642005756844, 0.86222911003100211, 0.8528926893248725, 0.8528926893248725, 0.8528926893248725, 0.85970627326049343]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.872457081073\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0186141304348\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[226   4]\n",
      " [ 47  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90       230\n",
      "          1       0.81      0.27      0.40        64\n",
      "\n",
      "avg / total       0.82      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  2,  13,  15,  21,  28,  68,  92,  95, 103, 117, 130, 135, 136,\n",
      "       145, 157, 164, 215, 229, 236, 241, 246, 249], dtype=int64),)], [0.81632653061224492, 'SelectKBest+LR', (array([ 13,  21,  28,  33,  68,  95, 103, 145, 178, 194, 215, 229, 236, 249], dtype=int64),)], [0.78231292517006801, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78231292517006801, 'KNN', (array([], dtype=int64),)], [0.78231292517006801, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.7857142857142857, 'RandomForest', (array([  7,  21,  28,  44,  48,  54,  70,  92,  93, 100, 118, 122, 145,\n",
      "       195, 236, 249, 256], dtype=int64),)], [0.82653061224489799, 'XGBoost', (array([  2,  11,  13,  21,  54,  68,  70,  85,  92, 107, 136, 145, 157,\n",
      "       164, 194, 214, 227, 236, 246, 257, 269], dtype=int64),)]]\n",
      "[0.87498642005756844, 0.86222911003100211, 0.8528926893248725, 0.8528926893248725, 0.8528926893248725, 0.85970627326049343, 0.87245708107338515]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0833333333333\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   4]\n",
      " [ 29  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       252\n",
      "          1       0.76      0.31      0.44        42\n",
      "\n",
      "avg / total       0.88      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 13,  26,  28,  31,  34,  74,  87, 160, 161, 164, 189, 204, 210,\n",
      "       258, 269, 282, 293], dtype=int64),)]]\n",
      "[0.85714285714285721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852891156463\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0277777777778\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   3]\n",
      " [ 34   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       252\n",
      "          1       0.73      0.19      0.30        42\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 13,  26,  28,  31,  34,  74,  87, 160, 161, 164, 189, 204, 210,\n",
      "       258, 269, 282, 293], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 26,  28,  31,  34,  74,  87, 161, 164, 189, 282, 293], dtype=int64),)]]\n",
      "[0.85714285714285721, 0.85289115646258506]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 13,  26,  28,  31,  34,  74,  87, 160, 161, 164, 189, 204, 210,\n",
      "       258, 269, 282, 293], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 26,  28,  31,  34,  74,  87, 161, 164, 189, 282, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85714285714285721, 0.85289115646258506, 0.83418367346938771]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 13,  26,  28,  31,  34,  74,  87, 160, 161, 164, 189, 204, 210,\n",
      "       258, 269, 282, 293], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 26,  28,  31,  34,  74,  87, 161, 164, 189, 282, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85714285714285721, 0.85289115646258506, 0.83418367346938771, 0.83418367346938771]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 13,  26,  28,  31,  34,  74,  87, 160, 161, 164, 189, 204, 210,\n",
      "       258, 269, 282, 293], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 26,  28,  31,  34,  74,  87, 161, 164, 189, 282, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85714285714285721, 0.85289115646258506, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840986394558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.472222222222\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238  14]\n",
      " [ 39   3]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.94      0.90       252\n",
      "          1       0.18      0.07      0.10        42\n",
      "\n",
      "avg / total       0.76      0.82      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 13,  26,  28,  31,  34,  74,  87, 160, 161, 164, 189, 204, 210,\n",
      "       258, 269, 282, 293], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 26,  28,  31,  34,  74,  87, 161, 164, 189, 282, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([ 56,  87, 138, 142, 155, 172, 177, 189, 208, 216, 228, 233, 242,\n",
      "       265, 280, 292, 293], dtype=int64),)]]\n",
      "[0.85714285714285721, 0.85289115646258506, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.8409863945578232]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 2.22044604925e-16\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   6]\n",
      " [ 30  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       252\n",
      "          1       0.67      0.29      0.40        42\n",
      "\n",
      "avg / total       0.86      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 13,  26,  28,  31,  34,  74,  87, 160, 161, 164, 189, 204, 210,\n",
      "       258, 269, 282, 293], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 26,  28,  31,  34,  74,  87, 161, 164, 189, 282, 293], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([ 56,  87, 138, 142, 155, 172, 177, 189, 208, 216, 228, 233, 242,\n",
      "       265, 280, 292, 293], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([  3,  13,  28,  33,  34,  87, 151, 160, 163, 164, 172, 189, 228,\n",
      "       229, 277, 280, 285, 293], dtype=int64),)]]\n",
      "[0.85714285714285721, 0.85289115646258506, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.8409863945578232, 0.8605442176870749]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863101109456\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0294117647059\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[229   9]\n",
      " [ 35  21]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       238\n",
      "          1       0.70      0.38      0.49        56\n",
      "\n",
      "avg / total       0.84      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  0,  11,  13,  18,  27,  48,  62,  64,  75,  76,  89,  91,  95,\n",
      "       118, 119, 124, 146, 161, 162, 165, 168, 211, 214, 238, 240, 249,\n",
      "       253, 265, 272, 276], dtype=int64),)]]\n",
      "[0.86310110945584118]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863107622737\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.125\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   6]\n",
      " [ 45  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       238\n",
      "          1       0.65      0.20      0.30        56\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  0,  11,  13,  18,  27,  48,  62,  64,  75,  76,  89,  91,  95,\n",
      "       118, 119, 124, 146, 161, 162, 165, 168, 211, 214, 238, 240, 249,\n",
      "       253, 265, 272, 276], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,  11,  13,  27,  62,  64,  89,  91, 119, 124, 162, 181, 211,\n",
      "       240, 253, 265, 272], dtype=int64),)]]\n",
      "[0.86310110945584118, 0.86310762273711339]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846089935034\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.235294117647\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   0]\n",
      " [ 56   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89       238\n",
      "\n",
      "avg / total       0.81      1.00      0.89       238\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  0,  11,  13,  18,  27,  48,  62,  64,  75,  76,  89,  91,  95,\n",
      "       118, 119, 124, 146, 161, 162, 165, 168, 211, 214, 238, 240, 249,\n",
      "       253, 265, 272, 276], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,  11,  13,  27,  62,  64,  89,  91, 119, 124, 162, 181, 211,\n",
      "       240, 253, 265, 272], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86310110945584118, 0.86310762273711339, 0.84608993503364394]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846089935034\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.235294117647\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   0]\n",
      " [ 56   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89       238\n",
      "\n",
      "avg / total       0.81      1.00      0.89       238\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  0,  11,  13,  18,  27,  48,  62,  64,  75,  76,  89,  91,  95,\n",
      "       118, 119, 124, 146, 161, 162, 165, 168, 211, 214, 238, 240, 249,\n",
      "       253, 265, 272, 276], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,  11,  13,  27,  62,  64,  89,  91, 119, 124, 162, 181, 211,\n",
      "       240, 253, 265, 272], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80952380952380953, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86310110945584118, 0.86310762273711339, 0.84608993503364394, 0.84608993503364394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846089935034\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.235294117647\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   0]\n",
      " [ 56   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.89       238\n",
      "\n",
      "avg / total       0.81      1.00      0.89       238\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  0,  11,  13,  18,  27,  48,  62,  64,  75,  76,  89,  91,  95,\n",
      "       118, 119, 124, 146, 161, 162, 165, 168, 211, 214, 238, 240, 249,\n",
      "       253, 265, 272, 276], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,  11,  13,  27,  62,  64,  89,  91, 119, 124, 162, 181, 211,\n",
      "       240, 253, 265, 272], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80952380952380953, 'KNN', (array([], dtype=int64),)], [0.80952380952380953, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86310110945584118, 0.86310762273711339, 0.84608993503364394, 0.84608993503364394, 0.84608993503364394]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.795918367347\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.855461041591\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.204081632653\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.323529411765\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[224  14]\n",
      " [ 46  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88       238\n",
      "          1       0.42      0.18      0.25        56\n",
      "\n",
      "avg / total       0.75      0.80      0.76       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  0,  11,  13,  18,  27,  48,  62,  64,  75,  76,  89,  91,  95,\n",
      "       118, 119, 124, 146, 161, 162, 165, 168, 211, 214, 238, 240, 249,\n",
      "       253, 265, 272, 276], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,  11,  13,  27,  62,  64,  89,  91, 119, 124, 162, 181, 211,\n",
      "       240, 253, 265, 272], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80952380952380953, 'KNN', (array([], dtype=int64),)], [0.80952380952380953, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.79591836734693877, 'RandomForest', (array([  0,  11,  19,  21,  27,  49,  64,  82, 112, 116, 128, 140, 159,\n",
      "       160, 174, 194, 211, 214, 215, 220, 240, 253, 265, 272], dtype=int64),)]]\n",
      "[0.86310110945584118, 0.86310762273711339, 0.84608993503364394, 0.84608993503364394, 0.84608993503364394, 0.8554610415911027]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866519857196\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.169117647059\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[226  12]\n",
      " [ 41  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90       238\n",
      "          1       0.56      0.27      0.36        56\n",
      "\n",
      "avg / total       0.79      0.82      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  0,  11,  13,  18,  27,  48,  62,  64,  75,  76,  89,  91,  95,\n",
      "       118, 119, 124, 146, 161, 162, 165, 168, 211, 214, 238, 240, 249,\n",
      "       253, 265, 272, 276], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  0,  11,  13,  27,  62,  64,  89,  91, 119, 124, 162, 181, 211,\n",
      "       240, 253, 265, 272], dtype=int64),)], [0.80952380952380953, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80952380952380953, 'KNN', (array([], dtype=int64),)], [0.80952380952380953, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.79591836734693877, 'RandomForest', (array([  0,  11,  19,  21,  27,  49,  64,  82, 112, 116, 128, 140, 159,\n",
      "       160, 174, 194, 211, 214, 215, 220, 240, 253, 265, 272], dtype=int64),)], [0.81972789115646261, 'XGBoost', (array([  0,  11,  19,  27,  52,  62,  63,  64,  76,  93,  95, 112, 116,\n",
      "       123, 156, 162, 174, 177, 210, 214, 240, 249, 253, 263, 265, 272, 276], dtype=int64),)]]\n",
      "[0.86310110945584118, 0.86310762273711339, 0.84608993503364394, 0.84608993503364394, 0.84608993503364394, 0.8554610415911027, 0.86651985719611435]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865646258503\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.120426829268\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235  11]\n",
      " [ 34  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       246\n",
      "          1       0.56      0.29      0.38        48\n",
      "\n",
      "avg / total       0.82      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 10,  35,  40,  45,  49,  54,  60,  68,  72,  74,  79,  98, 122,\n",
      "       136, 153, 160, 165, 170, 193, 206, 212, 235, 257, 280, 287], dtype=int64),)]]\n",
      "[0.86564625850340138]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.849489795918\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.120426829268\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   9]\n",
      " [ 36  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       246\n",
      "          1       0.57      0.25      0.35        48\n",
      "\n",
      "avg / total       0.82      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 10,  35,  40,  45,  49,  54,  60,  68,  72,  74,  79,  98, 122,\n",
      "       136, 153, 160, 165, 170, 193, 206, 212, 235, 257, 280, 287], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 10,  35,  40,  45,  49,  52,  54,  60,  68,  74, 122, 136, 160,\n",
      "       165, 170, 193, 212, 235, 257, 267, 287], dtype=int64),)]]\n",
      "[0.86564625850340138, 0.84948979591836737]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 10,  35,  40,  45,  49,  54,  60,  68,  72,  74,  79,  98, 122,\n",
      "       136, 153, 160, 165, 170, 193, 206, 212, 235, 257, 280, 287], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 10,  35,  40,  45,  49,  52,  54,  60,  68,  74, 122, 136, 160,\n",
      "       165, 170, 193, 212, 235, 257, 267, 287], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86564625850340138, 0.84948979591836737, 0.8392857142857143]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84693877551020413, 'LogisticRegression', (array([ 10,  35,  40,  45,  49,  54,  60,  68,  72,  74,  79,  98, 122,\n",
      "       136, 153, 160, 165, 170, 193, 206, 212, 235, 257, 280, 287], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 10,  35,  40,  45,  49,  52,  54,  60,  68,  74, 122, 136, 160,\n",
      "       165, 170, 193, 212, 235, 257, 267, 287], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86564625850340138, 0.84948979591836737, 0.8392857142857143, 0.8392857142857143]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 10,  35,  40,  45,  49,  54,  60,  68,  72,  74,  79,  98, 122,\n",
      "       136, 153, 160, 165, 170, 193, 206, 212, 235, 257, 280, 287], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 10,  35,  40,  45,  49,  52,  54,  60,  68,  74, 122, 136, 160,\n",
      "       165, 170, 193, 212, 235, 257, 267, 287], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86564625850340138, 0.84948979591836737, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   9]\n",
      " [ 39   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91       246\n",
      "          1       0.50      0.19      0.27        48\n",
      "\n",
      "avg / total       0.80      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 10,  35,  40,  45,  49,  54,  60,  68,  72,  74,  79,  98, 122,\n",
      "       136, 153, 160, 165, 170, 193, 206, 212, 235, 257, 280, 287], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 10,  35,  40,  45,  49,  52,  54,  60,  68,  74, 122, 136, 160,\n",
      "       165, 170, 193, 212, 235, 257, 267, 287], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 10,  20,  49,  57,  77,  98, 160, 171, 226, 234, 255, 261, 262,\n",
      "       266, 272, 287, 289, 292], dtype=int64),)]]\n",
      "[0.86564625850340138, 0.84948979591836737, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.84353741496598633]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0955284552846\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   7]\n",
      " [ 37  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       246\n",
      "          1       0.61      0.23      0.33        48\n",
      "\n",
      "avg / total       0.82      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 10,  35,  40,  45,  49,  54,  60,  68,  72,  74,  79,  98, 122,\n",
      "       136, 153, 160, 165, 170, 193, 206, 212, 235, 257, 280, 287], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 10,  35,  40,  45,  49,  52,  54,  60,  68,  74, 122, 136, 160,\n",
      "       165, 170, 193, 212, 235, 257, 267, 287], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 10,  20,  49,  57,  77,  98, 160, 171, 226, 234, 255, 261, 262,\n",
      "       266, 272, 287, 289, 292], dtype=int64),)], [0.85034013605442171, 'XGBoost', (array([ 10,  45,  49,  60,  68,  74,  98, 122, 153, 160, 165, 193, 212,\n",
      "       234, 235, 257, 261, 272], dtype=int64),)]]\n",
      "[0.86564625850340138, 0.84948979591836737, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.84353741496598633, 0.86394557823129248]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869899558452\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.140661848612\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230   9]\n",
      " [ 42  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       239\n",
      "          1       0.59      0.24      0.34        55\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  8,  25,  48,  59,  96,  98, 102, 113, 120, 121, 124, 146, 150,\n",
      "       154, 158, 169, 171, 184, 187, 253, 268, 290], dtype=int64),)]]\n",
      "[0.86989955845154743]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860543586834\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.163027767212\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   5]\n",
      " [ 47   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90       239\n",
      "          1       0.62      0.15      0.24        55\n",
      "\n",
      "avg / total       0.79      0.82      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  8,  25,  48,  59,  96,  98, 102, 113, 120, 121, 124, 146, 150,\n",
      "       154, 158, 169, 171, 184, 187, 253, 268, 290], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([  8,  59, 102, 124, 150, 154, 184, 187, 253, 263, 268, 290, 293], dtype=int64),)]]\n",
      "[0.86989955845154743, 0.86054358683400345]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  8,  25,  48,  59,  96,  98, 102, 113, 120, 121, 124, 146, 150,\n",
      "       154, 158, 169, 171, 184, 187, 253, 268, 290], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([  8,  59, 102, 124, 150, 154, 184, 187, 253, 263, 268, 290, 293], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86989955845154743, 0.86054358683400345, 0.8452395948975896]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  8,  25,  48,  59,  96,  98, 102, 113, 120, 121, 124, 146, 150,\n",
      "       154, 158, 169, 171, 184, 187, 253, 268, 290], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([  8,  59, 102, 124, 150, 154, 184, 187, 253, 263, 268, 290, 293], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86989955845154743, 0.86054358683400345, 0.8452395948975896, 0.8452395948975896]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  8,  25,  48,  59,  96,  98, 102, 113, 120, 121, 124, 146, 150,\n",
      "       154, 158, 169, 171, 184, 187, 253, 268, 290], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([  8,  59, 102, 124, 150, 154, 184, 187, 253, 263, 268, 290, 293], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86989955845154743, 0.86054358683400345, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856291897221\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185393685812\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   7]\n",
      " [ 46   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.90       239\n",
      "          1       0.56      0.16      0.25        55\n",
      "\n",
      "avg / total       0.78      0.82      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  8,  25,  48,  59,  96,  98, 102, 113, 120, 121, 124, 146, 150,\n",
      "       154, 158, 169, 171, 184, 187, 253, 268, 290], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([  8,  59, 102, 124, 150, 154, 184, 187, 253, 263, 268, 290, 293], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([ 66,  73,  77,  82,  98, 102, 120, 154, 157, 171, 187, 193, 244,\n",
      "       246, 257, 263], dtype=int64),)]]\n",
      "[0.86989955845154743, 0.86054358683400345, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896, 0.85629189722132892]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.873298766348\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.140661848612\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   5]\n",
      " [ 46   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       239\n",
      "          1       0.64      0.16      0.26        55\n",
      "\n",
      "avg / total       0.80      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  8,  25,  48,  59,  96,  98, 102, 113, 120, 121, 124, 146, 150,\n",
      "       154, 158, 169, 171, 184, 187, 253, 268, 290], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([  8,  59, 102, 124, 150, 154, 184, 187, 253, 263, 268, 290, 293], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([ 66,  73,  77,  82,  98, 102, 120, 154, 157, 171, 187, 193, 244,\n",
      "       246, 257, 263], dtype=int64),)], [0.82653061224489799, 'XGBoost', (array([ 66,  82, 102, 134, 147, 150, 154, 157, 171, 184, 187, 193, 203, 268], dtype=int64),)]]\n",
      "[0.86989955845154743, 0.86054358683400345, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896, 0.85629189722132892, 0.87329876634800385]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863098956808\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0187539732994\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   5]\n",
      " [ 37  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       242\n",
      "          1       0.75      0.29      0.42        52\n",
      "\n",
      "avg / total       0.84      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 14,  21,  24,  46,  67, 102, 106, 124, 137, 147, 156, 163, 174,\n",
      "       183, 206, 235, 246, 250, 282, 283], dtype=int64),)]]\n",
      "[0.86309895680808013]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854571666038\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.027972027972\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   2]\n",
      " [ 42  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       242\n",
      "          1       0.83      0.19      0.31        52\n",
      "\n",
      "avg / total       0.85      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 14,  21,  24,  46,  67, 102, 106, 124, 137, 147, 156, 163, 174,\n",
      "       183, 206, 235, 246, 250, 282, 283], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  4,  21,  67, 124, 137, 156, 174, 175, 183, 206, 250, 251], dtype=int64),)]]\n",
      "[0.86309895680808013, 0.85457166603780577]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 14,  21,  24,  46,  67, 102, 106, 124, 137, 147, 156, 163, 174,\n",
      "       183, 206, 235, 246, 250, 282, 283], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  4,  21,  67, 124, 137, 156, 174, 175, 183, 206, 250, 251], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86309895680808013, 0.85457166603780577, 0.84268856342182852]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 14,  21,  24,  46,  67, 102, 106, 124, 137, 147, 156, 163, 174,\n",
      "       183, 206, 235, 246, 250, 282, 283], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  4,  21,  67, 124, 137, 156, 174, 175, 183, 206, 250, 251], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86309895680808013, 0.85457166603780577, 0.84268856342182852, 0.84268856342182852]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 14,  21,  24,  46,  67, 102, 106, 124, 137, 147, 156, 163, 174,\n",
      "       183, 206, 235, 246, 250, 282, 283], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  4,  21,  67, 124, 137, 156, 174, 175, 183, 206, 250, 251], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86309895680808013, 0.85457166603780577, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840122352736\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.168150031786\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   6]\n",
      " [ 44   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       242\n",
      "          1       0.57      0.15      0.24        52\n",
      "\n",
      "avg / total       0.79      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 14,  21,  24,  46,  67, 102, 106, 124, 137, 147, 156, 163, 174,\n",
      "       183, 206, 235, 246, 250, 282, 283], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  4,  21,  67, 124, 137, 156, 174, 175, 183, 206, 250, 251], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([  9,  21,  43,  55, 102, 114, 120, 127, 135, 137, 140, 175, 181, 253], dtype=int64),)]]\n",
      "[0.86309895680808013, 0.85457166603780577, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.84012235273576186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863081613882\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.18229497775\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   1]\n",
      " [ 34  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93       242\n",
      "          1       0.95      0.35      0.51        52\n",
      "\n",
      "avg / total       0.89      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([ 14,  21,  24,  46,  67, 102, 106, 124, 137, 147, 156, 163, 174,\n",
      "       183, 206, 235, 246, 250, 282, 283], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([  4,  21,  67, 124, 137, 156, 174, 175, 183, 206, 250, 251], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([  9,  21,  43,  55, 102, 114, 120, 127, 135, 137, 140, 175, 181, 253], dtype=int64),)], [0.88095238095238093, 'XGBoost', (array([  3,   4,  14,  21,  67, 102, 114, 124, 127, 137, 140, 156, 175,\n",
      "       206, 235, 247, 250, 258, 283], dtype=int64),)]]\n",
      "[0.86309895680808013, 0.85457166603780577, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.84012235273576186, 0.86308161388241544]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858858174313\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0603278688525\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   6]\n",
      " [ 38  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       244\n",
      "          1       0.67      0.24      0.35        50\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 24,  28,  46,  51,  57,  75,  97, 128, 134, 170, 207, 211, 222,\n",
      "       245, 248, 263, 275, 278], dtype=int64),)]]\n",
      "[0.85885817431298206]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.849491317713\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0119672131148\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   3]\n",
      " [ 38  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       244\n",
      "          1       0.80      0.24      0.37        50\n",
      "\n",
      "avg / total       0.85      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 24,  28,  46,  51,  57,  75,  97, 128, 134, 170, 207, 211, 222,\n",
      "       245, 248, 263, 275, 278], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  28,  46,  57,  97, 128, 134, 143, 211, 222, 230, 245, 263,\n",
      "       275, 278], dtype=int64),)]]\n",
      "[0.85885817431298206, 0.84949131771305719]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 24,  28,  46,  51,  57,  75,  97, 128, 134, 170, 207, 211, 222,\n",
      "       245, 248, 263, 275, 278], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  28,  46,  57,  97, 128, 134, 143, 211, 222, 230, 245, 263,\n",
      "       275, 278], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85885817431298206, 0.84949131771305719, 0.84098787208212189]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 24,  28,  46,  51,  57,  75,  97, 128, 134, 170, 207, 211, 222,\n",
      "       245, 248, 263, 275, 278], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  28,  46,  57,  97, 128, 134, 143, 211, 222, 230, 245, 263,\n",
      "       275, 278], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85885817431298206, 0.84949131771305719, 0.84098787208212189, 0.84098787208212189]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840987872082\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.204918032787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   0]\n",
      " [ 50   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       244\n",
      "\n",
      "avg / total       0.83      1.00      0.91       244\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 24,  28,  46,  51,  57,  75,  97, 128, 134, 170, 207, 211, 222,\n",
      "       245, 248, 263, 275, 278], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  28,  46,  57,  97, 128, 134, 143, 211, 222, 230, 245, 263,\n",
      "       275, 278], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85885817431298206, 0.84949131771305719, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846951115882\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.30131147541\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234  10]\n",
      " [ 44   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.90       244\n",
      "          1       0.38      0.12      0.18        50\n",
      "\n",
      "avg / total       0.76      0.82      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 24,  28,  46,  51,  57,  75,  97, 128, 134, 170, 207, 211, 222,\n",
      "       245, 248, 263, 275, 278], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  28,  46,  57,  97, 128, 134, 143, 211, 222, 230, 245, 263,\n",
      "       275, 278], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81632653061224492, 'RandomForest', (array([ 10,  17,  19,  49,  75, 102, 112, 143, 167, 211, 242, 247, 250,\n",
      "       263, 278, 287], dtype=int64),)]]\n",
      "[0.85885817431298206, 0.84949131771305719, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189, 0.84695111588168848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86226380695\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.108524590164\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   6]\n",
      " [ 40  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91       244\n",
      "          1       0.62      0.20      0.30        50\n",
      "\n",
      "avg / total       0.82      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 24,  28,  46,  51,  57,  75,  97, 128, 134, 170, 207, 211, 222,\n",
      "       245, 248, 263, 275, 278], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  28,  46,  57,  97, 128, 134, 143, 211, 222, 230, 245, 263,\n",
      "       275, 278], dtype=int64),)], [0.82993197278911568, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82993197278911568, 'KNN', (array([], dtype=int64),)], [0.82993197278911568, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81632653061224492, 'RandomForest', (array([ 10,  17,  19,  49,  75, 102, 112, 143, 167, 211, 242, 247, 250,\n",
      "       263, 278, 287], dtype=int64),)], [0.84353741496598644, 'XGBoost', (array([  9,  10,  28,  57,  75, 105, 114, 128, 143, 198, 210, 211, 220,\n",
      "       222, 275, 278], dtype=int64),)]]\n",
      "[0.85885817431298206, 0.84949131771305719, 0.84098787208212189, 0.84098787208212189, 0.84098787208212189, 0.84695111588168848, 0.86226380694992899]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862244897959\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0232931726908\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238  11]\n",
      " [ 28  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.92       249\n",
      "          1       0.61      0.38      0.47        45\n",
      "\n",
      "avg / total       0.85      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  24,  43,  48,  56,  59,  62,  66,  67,  88,  94, 116, 140,\n",
      "       145, 150, 153, 162, 171, 181, 184, 188, 250, 257, 266, 269, 280,\n",
      "       284, 292], dtype=int64),)]]\n",
      "[0.86224489795918358]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.849489795918\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.128246318608\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   7]\n",
      " [ 36   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       249\n",
      "          1       0.56      0.20      0.30        45\n",
      "\n",
      "avg / total       0.82      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  24,  43,  48,  56,  59,  62,  66,  67,  88,  94, 116, 140,\n",
      "       145, 150, 153, 162, 171, 181, 184, 188, 250, 257, 266, 269, 280,\n",
      "       284, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 10,  17,  38,  43,  48,  56,  62,  66,  88,  94, 116, 184, 188,\n",
      "       266, 284, 292], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.84948979591836737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  24,  43,  48,  56,  59,  62,  66,  67,  88,  94, 116, 140,\n",
      "       145, 150, 153, 162, 171, 181, 184, 188, 250, 257, 266, 269, 280,\n",
      "       284, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 10,  17,  38,  43,  48,  56,  62,  66,  88,  94, 116, 184, 188,\n",
      "       266, 284, 292], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.84948979591836737, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  24,  43,  48,  56,  59,  62,  66,  67,  88,  94, 116, 140,\n",
      "       145, 150, 153, 162, 171, 181, 184, 188, 250, 257, 266, 269, 280,\n",
      "       284, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 10,  17,  38,  43,  48,  56,  62,  66,  88,  94, 116, 184, 188,\n",
      "       266, 284, 292], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.84948979591836737, 0.83673469387755117, 0.83673469387755117]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  24,  43,  48,  56,  59,  62,  66,  67,  88,  94, 116, 140,\n",
      "       145, 150, 153, 162, 171, 181, 184, 188, 250, 257, 266, 269, 280,\n",
      "       284, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 10,  17,  38,  43,  48,  56,  62,  66,  88,  94, 116, 184, 188,\n",
      "       266, 284, 292], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.84948979591836737, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840986394558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.233199464525\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237  12]\n",
      " [ 35  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.95      0.91       249\n",
      "          1       0.45      0.22      0.30        45\n",
      "\n",
      "avg / total       0.81      0.84      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  24,  43,  48,  56,  59,  62,  66,  67,  88,  94, 116, 140,\n",
      "       145, 150, 153, 162, 171, 181, 184, 188, 250, 257, 266, 269, 280,\n",
      "       284, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 10,  17,  38,  43,  48,  56,  62,  66,  88,  94, 116, 184, 188,\n",
      "       266, 284, 292], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84013605442176875, 'RandomForest', (array([ 10,  27,  33,  43,  48,  76,  77,  91,  94, 134, 138, 187, 199,\n",
      "       244, 254, 255, 257, 266, 280, 282, 284, 292], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.84948979591836737, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.8409863945578232]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.107898259705\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   5]\n",
      " [ 29  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       249\n",
      "          1       0.76      0.36      0.48        45\n",
      "\n",
      "avg / total       0.87      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 17,  24,  43,  48,  56,  59,  62,  66,  67,  88,  94, 116, 140,\n",
      "       145, 150, 153, 162, 171, 181, 184, 188, 250, 257, 266, 269, 280,\n",
      "       284, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 10,  17,  38,  43,  48,  56,  62,  66,  88,  94, 116, 184, 188,\n",
      "       266, 284, 292], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84013605442176875, 'RandomForest', (array([ 10,  27,  33,  43,  48,  76,  77,  91,  94, 134, 138, 187, 199,\n",
      "       244, 254, 255, 257, 266, 280, 282, 284, 292], dtype=int64),)], [0.88435374149659862, 'XGBoost', (array([ 10,  27,  33,  48,  59,  61,  62,  88,  94,  98,  99, 145, 171,\n",
      "       181, 182, 250, 254, 257, 266, 284, 292], dtype=int64),)]]\n",
      "[0.86224489795918358, 0.84948979591836737, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.8409863945578232, 0.86734693877551017]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852029389032\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0423636363636\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   4]\n",
      " [ 35   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       250\n",
      "          1       0.69      0.20      0.32        44\n",
      "\n",
      "avg / total       0.85      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  1,   8,  36,  71, 115, 128, 153, 168, 173, 189, 204, 210, 233], dtype=int64),)]]\n",
      "[0.8520293890318601]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.847792812224\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0423636363636\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   7]\n",
      " [ 32  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.93       250\n",
      "          1       0.63      0.27      0.38        44\n",
      "\n",
      "avg / total       0.85      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  1,   8,  36,  71, 115, 128, 153, 168, 173, 189, 204, 210, 233], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  1,   2,   6,   8,  34,  36,  41,  71, 115, 128, 138, 139, 153,\n",
      "       168, 173, 189, 194, 210, 233], dtype=int64),)]]\n",
      "[0.8520293890318601, 0.84779281222390501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  1,   8,  36,  71, 115, 128, 153, 168, 173, 189, 204, 210, 233], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  1,   2,   6,   8,  34,  36,  41,  71, 115, 128, 138, 139, 153,\n",
      "       168, 173, 189, 194, 210, 233], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8520293890318601, 0.84779281222390501, 0.83588580913059995]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  1,   8,  36,  71, 115, 128, 153, 168, 173, 189, 204, 210, 233], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  1,   2,   6,   8,  34,  36,  41,  71, 115, 128, 138, 139, 153,\n",
      "       168, 173, 189, 194, 210, 233], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8520293890318601, 0.84779281222390501, 0.83588580913059995, 0.83588580913059995]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  1,   8,  36,  71, 115, 128, 153, 168, 173, 189, 204, 210, 233], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  1,   2,   6,   8,  34,  36,  41,  71, 115, 128, 138, 139, 153,\n",
      "       168, 173, 189, 194, 210, 233], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8520293890318601, 0.84779281222390501, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836727494405\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0110909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   5]\n",
      " [ 32  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       250\n",
      "          1       0.71      0.27      0.39        44\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  1,   8,  36,  71, 115, 128, 153, 168, 173, 189, 204, 210, 233], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  1,   2,   6,   8,  34,  36,  41,  71, 115, 128, 138, 139, 153,\n",
      "       168, 173, 189, 194, 210, 233], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([  2,   6,   8,  20,  71,  96, 107, 113, 127, 138, 139, 157, 168,\n",
      "       173, 189, 210, 231], dtype=int64),)]]\n",
      "[0.8520293890318601, 0.84779281222390501, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.83672749440521865]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866502558541\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0645454545455\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   3]\n",
      " [ 32  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.93       250\n",
      "          1       0.80      0.27      0.41        44\n",
      "\n",
      "avg / total       0.87      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  1,   8,  36,  71, 115, 128, 153, 168, 173, 189, 204, 210, 233], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  1,   2,   6,   8,  34,  36,  41,  71, 115, 128, 138, 139, 153,\n",
      "       168, 173, 189, 194, 210, 233], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([  2,   6,   8,  20,  71,  96, 107, 113, 127, 138, 139, 157, 168,\n",
      "       173, 189, 210, 231], dtype=int64),)], [0.88095238095238093, 'XGBoost', (array([  2,  71, 101, 113, 115, 127, 138, 139, 153, 157, 168, 173, 180,\n",
      "       189, 210], dtype=int64),)]]\n",
      "[0.8520293890318601, 0.84779281222390501, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.83672749440521865, 0.86650255854084079]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861394557823\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.128556910569\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   4]\n",
      " [ 31  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       246\n",
      "          1       0.81      0.35      0.49        48\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  9,  10,  14,  18,  53,  56,  70, 134, 170, 181, 218, 232, 245,\n",
      "       252, 253, 258, 260, 266, 270, 276, 292], dtype=int64),)]]\n",
      "[0.86139455782312924]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852891156463\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0955284552846\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 44   4]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       246\n",
      "          1       1.00      0.08      0.15        48\n",
      "\n",
      "avg / total       0.87      0.85      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  9,  10,  14,  18,  53,  56,  70, 134, 170, 181, 218, 232, 245,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       252, 253, 258, 260, 266, 270, 276, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 56, 260, 276, 283], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85289115646258506]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  9,  10,  14,  18,  53,  56,  70, 134, 170, 181, 218, 232, 245,\n",
      "       252, 253, 258, 260, 266, 270, 276, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 56, 260, 276, 283], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85289115646258506, 0.8392857142857143]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  9,  10,  14,  18,  53,  56,  70, 134, 170, 181, 218, 232, 245,\n",
      "       252, 253, 258, 260, 266, 270, 276, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 56, 260, 276, 283], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85289115646258506, 0.8392857142857143, 0.8392857142857143]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  9,  10,  14,  18,  53,  56,  70, 134, 170, 181, 218, 232, 245,\n",
      "       252, 253, 258, 260, 266, 270, 276, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 56, 260, 276, 283], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85289115646258506, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0955284552846\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   7]\n",
      " [ 37  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       246\n",
      "          1       0.61      0.23      0.33        48\n",
      "\n",
      "avg / total       0.82      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  9,  10,  14,  18,  53,  56,  70, 134, 170, 181, 218, 232, 245,\n",
      "       252, 253, 258, 260, 266, 270, 276, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 56, 260, 276, 283], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 10,  59,  70, 134, 144, 164, 170, 181, 210, 212, 217, 218, 232,\n",
      "       236, 246, 252, 276, 283], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85289115646258506, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.84353741496598644]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00406504065041\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   3]\n",
      " [ 37  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       246\n",
      "          1       0.79      0.23      0.35        48\n",
      "\n",
      "avg / total       0.85      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  9,  10,  14,  18,  53,  56,  70, 134, 170, 181, 218, 232, 245,\n",
      "       252, 253, 258, 260, 266, 270, 276, 292], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 56, 260, 276, 283], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 10,  59,  70, 134, 144, 164, 170, 181, 210, 212, 217, 218, 232,\n",
      "       236, 246, 252, 276, 283], dtype=int64),)], [0.86394557823129248, 'XGBoost', (array([ 10,  56,  69,  80, 134, 140, 210, 217, 218, 245, 253, 260, 270, 276], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85289115646258506, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.84353741496598644, 0.8537414965986394]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860528440826\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0690909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   8]\n",
      " [ 32  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       250\n",
      "          1       0.60      0.27      0.37        44\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 32,  34,  56,  61, 101, 104, 117, 135, 157, 162, 177, 182, 195,\n",
      "       212, 228, 248, 254, 267, 268, 269], dtype=int64),)]]\n",
      "[0.86052844082649094]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848656167855\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0958181818182\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   1]\n",
      " [ 40   4]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       250\n",
      "          1       0.80      0.09      0.16        44\n",
      "\n",
      "avg / total       0.85      0.86      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 32,  34,  56,  61, 101, 104, 117, 135, 157, 162, 177, 182, 195,\n",
      "       212, 228, 248, 254, 267, 268, 269], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 32,  34,  86, 104, 177], dtype=int64),)]]\n",
      "[0.86052844082649094, 0.84865616785490605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 32,  34,  56,  61, 101, 104, 117, 135, 157, 162, 177, 182, 195,\n",
      "       212, 228, 248, 254, 267, 268, 269], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 32,  34,  86, 104, 177], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86052844082649094, 0.84865616785490605, 0.83588580913059995]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 32,  34,  56,  61, 101, 104, 117, 135, 157, 162, 177, 182, 195,\n",
      "       212, 228, 248, 254, 267, 268, 269], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 32,  34,  86, 104, 177], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86052844082649094, 0.84865616785490605, 0.83588580913059995, 0.83588580913059995]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 32,  34,  56,  61, 101, 104, 117, 135, 157, 162, 177, 182, 195,\n",
      "       212, 228, 248, 254, 267, 268, 269], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 32,  34,  86, 104, 177], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86052844082649094, 0.84865616785490605, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842705961685\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0690909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   6]\n",
      " [ 34  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.92       250\n",
      "          1       0.62      0.23      0.33        44\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 32,  34,  56,  61, 101, 104, 117, 135, 157, 162, 177, 182, 195,\n",
      "       212, 228, 248, 254, 267, 268, 269], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 32,  34,  86, 104, 177], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 34,  40,  63,  81,  86,  88, 104, 134, 174, 177, 195, 212, 228,\n",
      "       239, 267, 268], dtype=int64),)]]\n",
      "[0.86052844082649094, 0.84865616785490605, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.84270596168548184]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860543608969\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0912727272727\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   2]\n",
      " [ 32  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       250\n",
      "          1       0.86      0.27      0.41        44\n",
      "\n",
      "avg / total       0.88      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 32,  34,  56,  61, 101, 104, 117, 135, 157, 162, 177, 182, 195,\n",
      "       212, 228, 248, 254, 267, 268, 269], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 32,  34,  86, 104, 177], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 34,  40,  63,  81,  86,  88, 104, 134, 174, 177, 195, 212, 228,\n",
      "       239, 267, 268], dtype=int64),)], [0.88435374149659862, 'XGBoost', (array([  2,  15,  86,  88, 104, 162, 177, 179, 195, 228, 239, 248, 267, 268], dtype=int64),)]]\n",
      "[0.86052844082649094, 0.84865616785490605, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.84270596168548184, 0.8605436089691989]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859654189146\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0980014025245\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   5]\n",
      " [ 30  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       248\n",
      "          1       0.76      0.35      0.48        46\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 31,  33,  37,  63, 102, 109, 139, 142, 152, 159, 169, 192, 208,\n",
      "       214, 218, 231, 233, 260, 271, 284, 286], dtype=int64),)]]\n",
      "[0.85965418914551106]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842679875358\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0722300140252\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   5]\n",
      " [ 31  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       248\n",
      "          1       0.75      0.33      0.45        46\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 31,  33,  37,  63, 102, 109, 139, 142, 152, 159, 169, 192, 208,\n",
      "       214, 218, 231, 233, 260, 271, 284, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  1,  27,  31,  33,  37,  63, 102, 118, 138, 139, 142, 152, 180,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       192, 208, 214, 218, 236, 284, 286], dtype=int64),)]]\n",
      "[0.85965418914551106, 0.84267987535759958]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 31,  33,  37,  63, 102, 109, 139, 142, 152, 159, 169, 192, 208,\n",
      "       214, 218, 231, 233, 260, 271, 284, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  1,  27,  31,  33,  37,  63, 102, 118, 138, 139, 142, 152, 180,\n",
      "       192, 208, 214, 218, 236, 284, 286], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85965418914551106, 0.84267987535759958, 0.83758650047030658]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 31,  33,  37,  63, 102, 109, 139, 142, 152, 159, 169, 192, 208,\n",
      "       214, 218, 231, 233, 260, 271, 284, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  1,  27,  31,  33,  37,  63, 102, 118, 138, 139, 142, 152, 180,\n",
      "       192, 208, 214, 218, 236, 284, 286], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85965418914551106, 0.84267987535759958, 0.83758650047030658, 0.83758650047030658]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 31,  33,  37,  63, 102, 109, 139, 142, 152, 159, 169, 192, 208,\n",
      "       214, 218, 231, 233, 260, 271, 284, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  1,  27,  31,  33,  37,  63, 102, 118, 138, 139, 142, 152, 180,\n",
      "       192, 208, 214, 218, 236, 284, 286], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85965418914551106, 0.84267987535759958, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829922598534\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0206872370266\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   4]\n",
      " [ 34  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       248\n",
      "          1       0.75      0.26      0.39        46\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 31,  33,  37,  63, 102, 109, 139, 142, 152, 159, 169, 192, 208,\n",
      "       214, 218, 231, 233, 260, 271, 284, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  1,  27,  31,  33,  37,  63, 102, 118, 138, 139, 142, 152, 180,\n",
      "       192, 208, 214, 218, 236, 284, 286], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87074829931972786, 'RandomForest', (array([ 23,  33,  82, 102, 109, 128, 141, 152, 155, 172, 191, 217, 218,\n",
      "       231, 233, 236], dtype=int64),)]]\n",
      "[0.85965418914551106, 0.84267987535759958, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.82992259853382666]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857142237357\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0566269284712\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   5]\n",
      " [ 36  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       248\n",
      "          1       0.67      0.22      0.33        46\n",
      "\n",
      "avg / total       0.84      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 31,  33,  37,  63, 102, 109, 139, 142, 152, 159, 169, 192, 208,\n",
      "       214, 218, 231, 233, 260, 271, 284, 286], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  1,  27,  31,  33,  37,  63, 102, 118, 138, 139, 142, 152, 180,\n",
      "       192, 208, 214, 218, 236, 284, 286], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87074829931972786, 'RandomForest', (array([ 23,  33,  82, 102, 109, 128, 141, 152, 155, 172, 191, 217, 218,\n",
      "       231, 233, 236], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([  0,  31,  33,  35,  37,  63,  84, 102, 138, 176, 208, 214, 218,\n",
      "       284, 286], dtype=int64),)]]\n",
      "[0.85965418914551106, 0.84267987535759958, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.82992259853382666, 0.85714223735738349]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857975212433\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0888429752066\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   3]\n",
      " [ 36  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       242\n",
      "          1       0.84      0.31      0.45        52\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 14,  47,  55,  62,  69,  70,  87,  89, 118, 130, 136, 143, 156,\n",
      "       157, 166, 243, 251, 253, 256], dtype=int64),)]]\n",
      "[0.85797521243257791]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853747367959\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0746980292435\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   4]\n",
      " [ 42  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       242\n",
      "          1       0.71      0.19      0.30        52\n",
      "\n",
      "avg / total       0.83      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 14,  47,  55,  62,  69,  70,  87,  89, 118, 130, 136, 143, 156,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       157, 166, 243, 251, 253, 256], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 47,  55,  62,  65,  70,  89, 130, 143, 156, 166, 202, 251, 253, 256], dtype=int64),)]]\n",
      "[0.85797521243257791, 0.85374736795924255]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 14,  47,  55,  62,  69,  70,  87,  89, 118, 130, 136, 143, 156,\n",
      "       157, 166, 243, 251, 253, 256], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 47,  55,  62,  65,  70,  89, 130, 143, 156, 166, 202, 251, 253, 256], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85797521243257791, 0.85374736795924255, 0.84268856342182852]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 14,  47,  55,  62,  69,  70,  87,  89, 118, 130, 136, 143, 156,\n",
      "       157, 166, 243, 251, 253, 256], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 47,  55,  62,  65,  70,  89, 130, 143, 156, 166, 202, 251, 253, 256], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85797521243257791, 0.85374736795924255, 0.84268856342182852, 0.84268856342182852]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 14,  47,  55,  62,  69,  70,  87,  89, 118, 130, 136, 143, 156,\n",
      "       157, 166, 243, 251, 253, 256], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 47,  55,  62,  65,  70,  89, 130, 143, 156, 166, 202, 251, 253, 256], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85797521243257791, 0.85374736795924255, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.847777610878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.121424030515\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   7]\n",
      " [ 41  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91       242\n",
      "          1       0.61      0.21      0.31        52\n",
      "\n",
      "avg / total       0.81      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 14,  47,  55,  62,  69,  70,  87,  89, 118, 130, 136, 143, 156,\n",
      "       157, 166, 243, 251, 253, 256], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 47,  55,  62,  65,  70,  89, 130, 143, 156, 166, 202, 251, 253, 256], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([  6,   7,  10,  38,  50,  55,  62,  69,  70,  83,  89, 143, 144,\n",
      "       146, 166, 187, 253, 278], dtype=int64),)]]\n",
      "[0.85797521243257791, 0.85374736795924255, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.84777761087840375]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856307087499\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0421169739352\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   4]\n",
      " [ 37  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       242\n",
      "          1       0.79      0.29      0.42        52\n",
      "\n",
      "avg / total       0.85      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 14,  47,  55,  62,  69,  70,  87,  89, 118, 130, 136, 143, 156,\n",
      "       157, 166, 243, 251, 253, 256], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([ 47,  55,  62,  65,  70,  89, 130, 143, 156, 166, 202, 251, 253, 256], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([  6,   7,  10,  38,  50,  55,  62,  69,  70,  83,  89, 143, 144,\n",
      "       146, 166, 187, 253, 278], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([  7,  38,  39,  62,  70,  83,  87, 125, 142, 143, 144, 157, 166,\n",
      "       168, 187, 243, 251, 253, 256], dtype=int64),)]]\n",
      "[0.85797521243257791, 0.85374736795924255, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.84777761087840375, 0.85630708749923246]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865636972789\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0530612244898\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   7]\n",
      " [ 36  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       245\n",
      "          1       0.65      0.27      0.38        49\n",
      "\n",
      "avg / total       0.83      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([ 13,  30,  45,  55,  58,  59,  68,  79,  91,  92,  98, 127, 136,\n",
      "       144, 175, 198, 230, 268, 269, 292], dtype=int64),)]]\n",
      "[0.86563697278889418]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.864793157002\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   3]\n",
      " [ 46   3]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91       245\n",
      "          1       0.50      0.06      0.11        49\n",
      "\n",
      "avg / total       0.78      0.83      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([ 13,  30,  45,  55,  58,  59,  68,  79,  91,  92,  98, 127, 136,\n",
      "       144, 175, 198, 230, 268, 269, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 68,  79, 136, 198, 220, 269], dtype=int64),)]]\n",
      "[0.86563697278889418, 0.86479315700170989]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([ 13,  30,  45,  55,  58,  59,  68,  79,  91,  92,  98, 127, 136,\n",
      "       144, 175, 198, 230, 268, 269, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 68,  79, 136, 198, 220, 269], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86563697278889418, 0.86479315700170989, 0.84013753194606755]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([ 13,  30,  45,  55,  58,  59,  68,  79,  91,  92,  98, 127, 136,\n",
      "       144, 175, 198, 230, 268, 269, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 68,  79, 136, 198, 220, 269], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86563697278889418, 0.86479315700170989, 0.84013753194606755, 0.84013753194606755]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([ 13,  30,  45,  55,  58,  59,  68,  79,  91,  92,  98, 127, 136,\n",
      "       144, 175, 198, 230, 268, 269, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 68,  79, 136, 198, 220, 269], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86563697278889418, 0.86479315700170989, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835065838483\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.248979591837\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   8]\n",
      " [ 43   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.90       245\n",
      "          1       0.43      0.12      0.19        49\n",
      "\n",
      "avg / total       0.78      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([ 13,  30,  45,  55,  58,  59,  68,  79,  91,  92,  98, 127, 136,\n",
      "       144, 175, 198, 230, 268, 269, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 68,  79, 136, 198, 220, 269], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([ 13,  32,  40,  45,  58,  92, 136, 173, 175, 198, 207, 212, 270, 287], dtype=int64),)]]\n",
      "[0.86563697278889418, 0.86479315700170989, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.83506583848275451]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869051370963\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0775510204082\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   8]\n",
      " [ 36  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       245\n",
      "          1       0.62      0.27      0.37        49\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([ 13,  30,  45,  55,  58,  59,  68,  79,  91,  92,  98, 127, 136,\n",
      "       144, 175, 198, 230, 268, 269, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 68,  79, 136, 198, 220, 269], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([ 13,  32,  40,  45,  58,  92, 136, 173, 175, 198, 207, 212, 270, 287], dtype=int64),)], [0.85034013605442171, 'XGBoost', (array([ 26,  30,  45,  58,  59,  60,  68,  72, 136, 144, 175, 183, 193,\n",
      "       194, 198, 202, 219, 257, 270, 287, 292], dtype=int64),)]]\n",
      "[0.86563697278889418, 0.86479315700170989, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.83506583848275451, 0.86905137096325413]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869051404166\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239  12]\n",
      " [ 31  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92       251\n",
      "          1       0.50      0.28      0.36        43\n",
      "\n",
      "avg / total       0.83      0.85      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  1,   4,  18,  30,  43,  54,  59,  62,  65,  80,  84,  91, 123,\n",
      "       130, 131, 142, 151, 186, 198, 207, 231, 243, 258, 281], dtype=int64),)]]\n",
      "[0.86905140416604743]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857142237357\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0895951079403\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   3]\n",
      " [ 37   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       251\n",
      "          1       0.67      0.14      0.23        43\n",
      "\n",
      "avg / total       0.84      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  1,   4,  18,  30,  43,  54,  59,  62,  65,  80,  84,  91, 123,\n",
      "       130, 131, 142, 151, 186, 198, 207, 231, 243, 258, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  4,  18,  43,  54,  62, 130, 142, 207, 231], dtype=int64),)]]\n",
      "[0.86905140416604743, 0.85714223735738349]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  1,   4,  18,  30,  43,  54,  59,  62,  65,  80,  84,  91, 123,\n",
      "       130, 131, 142, 151, 186, 198, 207, 231, 243, 258, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  4,  18,  43,  54,  62, 130, 142, 207, 231], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86905140416604743, 0.85714223735738349, 0.83503546899454539]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  1,   4,  18,  30,  43,  54,  59,  62,  65,  80,  84,  91, 123,\n",
      "       130, 131, 142, 151, 186, 198, 207, 231, 243, 258, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  4,  18,  43,  54,  62, 130, 142, 207, 231], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86905140416604743, 0.85714223735738349, 0.83503546899454539, 0.83503546899454539]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  1,   4,  18,  30,  43,  54,  59,  62,  65,  80,  84,  91, 123,\n",
      "       130, 131, 142, 151, 186, 198, 207, 231, 243, 258, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  4,  18,  43,  54,  62, 130, 142, 207, 231], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86905140416604743, 0.85714223735738349, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.84269076034\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00787547484481\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   5]\n",
      " [ 32  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       251\n",
      "          1       0.69      0.26      0.37        43\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  1,   4,  18,  30,  43,  54,  59,  62,  65,  80,  84,  91, 123,\n",
      "       130, 131, 142, 151, 186, 198, 207, 231, 243, 258, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  4,  18,  43,  54,  62, 130, 142, 207, 231], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([  4,  10,  18,  43,  46,  54,  80,  91, 123, 130, 184, 200, 223,\n",
      "       224, 229, 231], dtype=int64),)]]\n",
      "[0.86905140416604743, 0.85714223735738349, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.84269076033998058]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.869890870387\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00787547484481\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   5]\n",
      " [ 32  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       251\n",
      "          1       0.69      0.26      0.37        43\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  1,   4,  18,  30,  43,  54,  59,  62,  65,  80,  84,  91, 123,\n",
      "       130, 131, 142, 151, 186, 198, 207, 231, 243, 258, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  4,  18,  43,  54,  62, 130, 142, 207, 231], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([  4,  10,  18,  43,  46,  54,  80,  91, 123, 130, 184, 200, 223,\n",
      "       224, 229, 231], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([  1,   4,  10,  24,  43,  46,  54,  62,  80, 107, 130, 184, 224,\n",
      "       231, 280, 281], dtype=int64),)]]\n",
      "[0.86905140416604743, 0.85714223735738349, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.84269076033998058, 0.86989087038731849]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861396134956\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0421169739352\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   4]\n",
      " [ 37  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       242\n",
      "          1       0.79      0.29      0.42        52\n",
      "\n",
      "avg / total       0.85      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  3,  10,  15,  31,  50,  53,  57,  64,  88,  93, 122, 137, 155,\n",
      "       158, 176, 196, 224, 261, 292], dtype=int64),)]]\n",
      "[0.8613961349558078]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857968743422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0046090273363\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   7]\n",
      " [ 36  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       242\n",
      "          1       0.70      0.31      0.43        52\n",
      "\n",
      "avg / total       0.84      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  3,  10,  15,  31,  50,  53,  57,  64,  88,  93, 122, 137, 155,\n",
      "       158, 176, 196, 224, 261, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  3,  10,  19,  50,  53,  57,  64,  93, 110, 122, 137, 149, 155,\n",
      "       158, 176, 180, 224, 229, 243, 251, 252, 261, 273], dtype=int64),)]]\n",
      "[0.8613961349558078, 0.8579687434216966]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  3,  10,  15,  31,  50,  53,  57,  64,  88,  93, 122, 137, 155,\n",
      "       158, 176, 196, 224, 261, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  3,  10,  19,  50,  53,  57,  64,  93, 110, 122, 137, 149, 155,\n",
      "       158, 176, 180, 224, 229, 243, 251, 252, 261, 273], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8613961349558078, 0.8579687434216966, 0.84268856342182852]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  3,  10,  15,  31,  50,  53,  57,  64,  88,  93, 122, 137, 155,\n",
      "       158, 176, 196, 224, 261, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  3,  10,  19,  50,  53,  57,  64,  93, 110, 122, 137, 149, 155,\n",
      "       158, 176, 180, 224, 229, 243, 251, 252, 261, 273], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8613961349558078, 0.8579687434216966, 0.84268856342182852, 0.84268856342182852]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  3,  10,  15,  31,  50,  53,  57,  64,  88,  93, 122, 137, 155,\n",
      "       158, 176, 196, 224, 261, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  3,  10,  19,  50,  53,  57,  64,  93, 110, 122, 137, 149, 155,\n",
      "       158, 176, 180, 224, 229, 243, 251, 252, 261, 273], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8613961349558078, 0.8579687434216966, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840139684594\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.144787031151\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   7]\n",
      " [ 42  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91       242\n",
      "          1       0.59      0.19      0.29        52\n",
      "\n",
      "avg / total       0.80      0.83      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  3,  10,  15,  31,  50,  53,  57,  64,  88,  93, 122, 137, 155,\n",
      "       158, 176, 196, 224, 261, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  3,  10,  19,  50,  53,  57,  64,  93, 110, 122, 137, 149, 155,\n",
      "       158, 176, 180, 224, 229, 243, 251, 252, 261, 273], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83333333333333337, 'RandomForest', (array([ 12,  53,  57,  65, 110, 122, 155, 171, 180, 186, 196, 216, 224,\n",
      "       273, 284, 292, 293], dtype=int64),)]]\n",
      "[0.8613961349558078, 0.8579687434216966, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.84013968459382882]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861383097326\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0046090273363\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   5]\n",
      " [ 38  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       242\n",
      "          1       0.74      0.27      0.39        52\n",
      "\n",
      "avg / total       0.84      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  3,  10,  15,  31,  50,  53,  57,  64,  88,  93, 122, 137, 155,\n",
      "       158, 176, 196, 224, 261, 292], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  3,  10,  19,  50,  53,  57,  64,  93, 110, 122, 137, 149, 155,\n",
      "       158, 176, 180, 224, 229, 243, 251, 252, 261, 273], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83333333333333337, 'RandomForest', (array([ 12,  53,  57,  65, 110, 122, 155, 171, 180, 186, 196, 216, 224,\n",
      "       273, 284, 292, 293], dtype=int64),)], [0.8537414965986394, 'XGBoost', (array([ 10,  53,  57,  64,  73,  94,  95, 110, 137, 155, 176, 180, 186,\n",
      "       224, 243, 252, 261, 292, 293], dtype=int64),)]]\n",
      "[0.8613961349558078, 0.8579687434216966, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.84013968459382882, 0.86138309732566543]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856292517007\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.240861776809\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   4]\n",
      " [ 28  23]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       243\n",
      "          1       0.85      0.45      0.59        51\n",
      "\n",
      "avg / total       0.89      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.891156462585034, 'LogisticRegression', (array([  3,   4,   5,  17,  26,  54,  69,  70,  77, 114, 124, 135, 147,\n",
      "       163, 165, 176, 180, 183, 188, 199, 205, 207, 234, 238, 240, 256, 273], dtype=int64),)]]\n",
      "[0.85629251700680264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846088435374\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.122246429436\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   1]\n",
      " [ 36  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       243\n",
      "          1       0.94      0.29      0.45        51\n",
      "\n",
      "avg / total       0.88      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.891156462585034, 'LogisticRegression', (array([  3,   4,   5,  17,  26,  54,  69,  70,  77, 114, 124, 135, 147,\n",
      "       163, 165, 176, 180, 183, 188, 199, 205, 207, 234, 238, 240, 256, 273], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 17,  70,  77, 114, 147, 171, 180, 183, 188, 207, 234, 240, 256,\n",
      "       273, 280, 290], dtype=int64),)]]\n",
      "[0.85629251700680264, 0.84608843537414968]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.20987654321\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   0]\n",
      " [ 51   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       243\n",
      "\n",
      "avg / total       0.83      1.00      0.91       243\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.891156462585034, 'LogisticRegression', (array([  3,   4,   5,  17,  26,  54,  69,  70,  77, 114, 124, 135, 147,\n",
      "       163, 165, 176, 180, 183, 188, 199, 205, 207, 234, 238, 240, 256, 273], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 17,  70,  77, 114, 147, 171, 180, 183, 188, 207, 234, 240, 256,\n",
      "       273, 280, 290], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85629251700680264, 0.84608843537414968, 0.84183673469387754]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.20987654321\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   0]\n",
      " [ 51   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       243\n",
      "\n",
      "avg / total       0.83      1.00      0.91       243\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.891156462585034, 'LogisticRegression', (array([  3,   4,   5,  17,  26,  54,  69,  70,  77, 114, 124, 135, 147,\n",
      "       163, 165, 176, 180, 183, 188, 199, 205, 207, 234, 238, 240, 256, 273], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 17,  70,  77, 114, 147, 171, 180, 183, 188, 207, 234, 240, 256,\n",
      "       273, 280, 290], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82653061224489799, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85629251700680264, 0.84608843537414968, 0.84183673469387754, 0.84183673469387754]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.20987654321\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   0]\n",
      " [ 51   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       243\n",
      "\n",
      "avg / total       0.83      1.00      0.91       243\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.891156462585034, 'LogisticRegression', (array([  3,   4,   5,  17,  26,  54,  69,  70,  77, 114, 124, 135, 147,\n",
      "       163, 165, 176, 180, 183, 188, 199, 205, 207, 234, 238, 240, 256, 273], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 17,  70,  77, 114, 147, 171, 180, 183, 188, 207, 234, 240, 256,\n",
      "       273, 280, 290], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82653061224489799, 'KNN', (array([], dtype=int64),)], [0.82653061224489799, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85629251700680264, 0.84608843537414968, 0.84183673469387754, 0.84183673469387754, 0.84183673469387754]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.138707334786\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233  10]\n",
      " [ 38  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91       243\n",
      "          1       0.57      0.25      0.35        51\n",
      "\n",
      "avg / total       0.81      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.891156462585034, 'LogisticRegression', (array([  3,   4,   5,  17,  26,  54,  69,  70,  77, 114, 124, 135, 147,\n",
      "       163, 165, 176, 180, 183, 188, 199, 205, 207, 234, 238, 240, 256, 273], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 17,  70,  77, 114, 147, 171, 180, 183, 188, 207, 234, 240, 256,\n",
      "       273, 280, 290], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82653061224489799, 'KNN', (array([], dtype=int64),)], [0.82653061224489799, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 17,  22,  70,  77,  88,  90,  93, 115, 120, 124, 146, 147, 152,\n",
      "       165, 182, 218, 226, 234, 237, 238, 240, 246, 290], dtype=int64),)]]\n",
      "[0.85629251700680264, 0.84608843537414968, 0.84183673469387754, 0.84183673469387754, 0.84183673469387754, 0.8392857142857143]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856292517007\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0273541515372\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   6]\n",
      " [ 35  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       243\n",
      "          1       0.73      0.31      0.44        51\n",
      "\n",
      "avg / total       0.85      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.891156462585034, 'LogisticRegression', (array([  3,   4,   5,  17,  26,  54,  69,  70,  77, 114, 124, 135, 147,\n",
      "       163, 165, 176, 180, 183, 188, 199, 205, 207, 234, 238, 240, 256, 273], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 17,  70,  77, 114, 147, 171, 180, 183, 188, 207, 234, 240, 256,\n",
      "       273, 280, 290], dtype=int64),)], [0.82653061224489799, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.82653061224489799, 'KNN', (array([], dtype=int64),)], [0.82653061224489799, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 17,  22,  70,  77,  88,  90,  93, 115, 120, 124, 146, 147, 152,\n",
      "       165, 182, 218, 226, 234, 237, 238, 240, 246, 290], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([  5,  17,  26,  70,  77,  93, 108, 114, 124, 146, 154, 165, 176,\n",
      "       180, 183, 205, 211, 234, 240, 264, 273, 290], dtype=int64),)]]\n",
      "[0.85629251700680264, 0.84608843537414968, 0.84183673469387754, 0.84183673469387754, 0.84183673469387754, 0.8392857142857143, 0.85629251700680264]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.90476190476190477, 'SelectKBest+LR', (array([ 30,  45,  60,  61,  90,  93,  97, 102, 106, 130, 197, 211, 262,\n",
      "       280, 282], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.904761904762\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.855442176871\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0952380952381\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.141905950895\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[259   8]\n",
      " [ 20   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       267\n",
      "          1       0.47      0.26      0.33        27\n",
      "\n",
      "avg / total       0.89      0.90      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90476190476190477, 'LogisticRegression', (array([  6,  12,  19,  47, 104, 111, 164, 171, 200, 207, 218, 242, 260,\n",
      "       272, 284], dtype=int64),)]]\n",
      "[0.85544217687074831]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.305035372451\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[258   9]\n",
      " [ 23   4]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       267\n",
      "          1       0.31      0.15      0.20        27\n",
      "\n",
      "avg / total       0.86      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90476190476190477, 'LogisticRegression', (array([  6,  12,  19,  47, 104, 111, 164, 171, 200, 207, 218, 242, 260,\n",
      "       272, 284], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 10,  12,  19,  33, 111, 127, 131, 200, 207, 242, 260, 272, 284], dtype=int64),)]]\n",
      "[0.85544217687074831, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.908163265306\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.821428571429\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0918367346939\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.101123595506\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[267   0]\n",
      " [ 27   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       267\n",
      "\n",
      "avg / total       0.91      1.00      0.95       267\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90476190476190477, 'LogisticRegression', (array([  6,  12,  19,  47, 104, 111, 164, 171, 200, 207, 218, 242, 260,\n",
      "       272, 284], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 10,  12,  19,  33, 111, 127, 131, 200, 207, 242, 260, 272, 284], dtype=int64),)], [0.90816326530612246, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85544217687074831, 0.83673469387755117, 0.82142857142857151]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.908163265306\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.821428571429\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0918367346939\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.101123595506\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[267   0]\n",
      " [ 27   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       267\n",
      "\n",
      "avg / total       0.91      1.00      0.95       267\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'one_indices' (tuple)\n",
      "[[0.90476190476190477, 'LogisticRegression', (array([  6,  12,  19,  47, 104, 111, 164, 171, 200, 207, 218, 242, 260,\n",
      "       272, 284], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 10,  12,  19,  33, 111, 127, 131, 200, 207, 242, 260, 272, 284], dtype=int64),)], [0.90816326530612246, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.90816326530612246, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85544217687074831, 0.83673469387755117, 0.82142857142857151, 0.82142857142857151]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.908163265306\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.821428571429\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0918367346939\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.101123595506\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[267   0]\n",
      " [ 27   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       267\n",
      "\n",
      "avg / total       0.91      1.00      0.95       267\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90476190476190477, 'LogisticRegression', (array([  6,  12,  19,  47, 104, 111, 164, 171, 200, 207, 218, 242, 260,\n",
      "       272, 284], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 10,  12,  19,  33, 111, 127, 131, 200, 207, 242, 260, 272, 284], dtype=int64),)], [0.90816326530612246, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.90816326530612246, 'KNN', (array([], dtype=int64),)], [0.90816326530612246, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85544217687074831, 0.83673469387755117, 0.82142857142857151, 0.82142857142857151, 0.82142857142857151]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.908163265306\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827380952381\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0918367346939\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.101123595506\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   7]\n",
      " [ 20   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       267\n",
      "          1       0.50      0.26      0.34        27\n",
      "\n",
      "avg / total       0.89      0.91      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90476190476190477, 'LogisticRegression', (array([  6,  12,  19,  47, 104, 111, 164, 171, 200, 207, 218, 242, 260,\n",
      "       272, 284], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 10,  12,  19,  33, 111, 127, 131, 200, 207, 242, 260, 272, 284], dtype=int64),)], [0.90816326530612246, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.90816326530612246, 'KNN', (array([], dtype=int64),)], [0.90816326530612246, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.90816326530612246, 'RandomForest', (array([111, 115, 131, 138, 146, 148, 156, 178, 200, 260, 272, 277, 283, 284], dtype=int64),)]]\n",
      "[0.85544217687074831, 0.83673469387755117, 0.82142857142857151, 0.82142857142857151, 0.82142857142857151, 0.82738095238095244]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.918367346939\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0816326530612\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0212234706617\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[262   5]\n",
      " [ 19   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.96       267\n",
      "          1       0.62      0.30      0.40        27\n",
      "\n",
      "avg / total       0.90      0.92      0.91       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90476190476190477, 'LogisticRegression', (array([  6,  12,  19,  47, 104, 111, 164, 171, 200, 207, 218, 242, 260,\n",
      "       272, 284], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 10,  12,  19,  33, 111, 127, 131, 200, 207, 242, 260, 272, 284], dtype=int64),)], [0.90816326530612246, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.90816326530612246, 'KNN', (array([], dtype=int64),)], [0.90816326530612246, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.90816326530612246, 'RandomForest', (array([111, 115, 131, 138, 146, 148, 156, 178, 200, 260, 272, 277, 283, 284], dtype=int64),)], [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]]\n",
      "[0.85544217687074831, 0.83673469387755117, 0.82142857142857151, 0.82142857142857151, 0.82142857142857151, 0.82738095238095244, 0.85714285714285721]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862235612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00800154246602\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   4]\n",
      " [ 31  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       253\n",
      "          1       0.71      0.24      0.36        41\n",
      "\n",
      "avg / total       0.86      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  20,  33,  43,  44,  68,  76, 169, 231, 243, 244, 245, 263, 271], dtype=int64),)]]\n",
      "[0.86223561224467671]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843536739843\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.133712522896\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   6]\n",
      " [ 34   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       253\n",
      "          1       0.54      0.17      0.26        41\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  20,  33,  43,  44,  68,  76, 169, 231, 243, 244, 245, 263, 271], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 33,  44,  68,  76, 161, 169, 238, 244, 245, 259, 263, 271, 286], dtype=int64),)]]\n",
      "[0.86223561224467671, 0.84353673984252397]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  20,  33,  43,  44,  68,  76, 169, 231, 243, 244, 245, 263, 271], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 33,  44,  68,  76, 161, 169, 238, 244, 245, 259, 263, 271, 286], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86223561224467671, 0.84353673984252397, 0.83333477765483888]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  20,  33,  43,  44,  68,  76, 169, 231, 243, 244, 245, 263, 271], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 33,  44,  68,  76, 161, 169, 238, 244, 245, 259, 263, 271, 286], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86223561224467671, 0.84353673984252397, 0.83333477765483888, 0.83333477765483888]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  20,  33,  43,  44,  68,  76, 169, 231, 243, 244, 245, 263, 271], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 33,  44,  68,  76, 161, 169, 238, 244, 245, 259, 263, 271, 286], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86223561224467671, 0.84353673984252397, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.82906130701\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.190398149041\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   7]\n",
      " [ 35   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       253\n",
      "          1       0.46      0.15      0.22        41\n",
      "\n",
      "avg / total       0.82      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  20,  33,  43,  44,  68,  76, 169, 231, 243, 244, 245, 263, 271], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 33,  44,  68,  76, 161, 169, 238, 244, 245, 259, 263, 271, 286], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 15,  21,  32,  46, 127, 130, 134, 159, 165, 169, 245, 270, 286], dtype=int64),)]]\n",
      "[0.86223561224467671, 0.84353673984252397, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888, 0.82906130700980485]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85120715506\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0930299816832\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   4]\n",
      " [ 28  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       253\n",
      "          1       0.76      0.32      0.45        41\n",
      "\n",
      "avg / total       0.88      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  20,  33,  43,  44,  68,  76, 169, 231, 243, 244, 245, 263, 271], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 33,  44,  68,  76, 161, 169, 238, 244, 245, 259, 263, 271, 286], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 15,  21,  32,  46, 127, 130, 134, 159, 165, 169, 245, 270, 286], dtype=int64),)], [0.891156462585034, 'XGBoost', (array([  4,  15,  23,  24,  43,  44,  50,  68, 127, 161, 165, 231, 236,\n",
      "       245, 256, 258, 271], dtype=int64),)]]\n",
      "[0.86223561224467671, 0.84353673984252397, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888, 0.82906130700980485, 0.85120715506027622]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859693877551\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.04953145917\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   7]\n",
      " [ 33  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       249\n",
      "          1       0.63      0.27      0.38        45\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 20,  25,  32,  33,  68,  73,  92, 129, 134, 167, 182, 185, 187,\n",
      "       191, 198, 222, 262, 285, 292], dtype=int64),)]]\n",
      "[0.85969387755102034]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852891156463\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.206961178046\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   1]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "          1       0.00      0.00      0.00        45\n",
      "\n",
      "avg / total       0.72      0.84      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 20,  25,  32,  33,  68,  73,  92, 129, 134, 167, 182, 185, 187,\n",
      "       191, 198, 222, 262, 285, 292], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([191], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85289115646258506]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 20,  25,  32,  33,  68,  73,  92, 129, 134, 167, 182, 185, 187,\n",
      "       191, 198, 222, 262, 285, 292], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([191], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85289115646258506, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 20,  25,  32,  33,  68,  73,  92, 129, 134, 167, 182, 185, 187,\n",
      "       191, 198, 222, 262, 285, 292], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([191], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85289115646258506, 0.83673469387755117, 0.83673469387755117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 20,  25,  32,  33,  68,  73,  92, 129, 134, 167, 182, 185, 187,\n",
      "       191, 198, 222, 262, 285, 292], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([191], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85289115646258506, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0757697456493\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 38   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       249\n",
      "          1       0.70      0.16      0.25        45\n",
      "\n",
      "avg / total       0.84      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 20,  25,  32,  33,  68,  73,  92, 129, 134, 167, 182, 185, 187,\n",
      "       191, 198, 222, 262, 285, 292], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([191], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86054421768707479, 'RandomForest', (array([ 33,  68, 105, 134, 167, 187, 213, 222, 229, 285], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85289115646258506, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83673469387755095]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0232931726908\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 36   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       249\n",
      "          1       0.75      0.20      0.32        45\n",
      "\n",
      "avg / total       0.85      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([ 20,  25,  32,  33,  68,  73,  92, 129, 134, 167, 182, 185, 187,\n",
      "       191, 198, 222, 262, 285, 292], dtype=int64),)], [0.84353741496598644, 'SelectKBest+LR', (array([191], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86054421768707479, 'RandomForest', (array([ 33,  68, 105, 134, 167, 187, 213, 222, 229, 285], dtype=int64),)], [0.86734693877551017, 'XGBoost', (array([ 20,  48,  68,  73,  80, 129, 167, 187, 200, 262, 285, 292], dtype=int64),)]]\n",
      "[0.85969387755102034, 0.85289115646258506, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83673469387755095, 0.86394557823129248]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866496598639\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.156944444444\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   3]\n",
      " [ 48   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       240\n",
      "          1       0.67      0.11      0.19        54\n",
      "\n",
      "avg / total       0.80      0.83      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  0,  19,  55,  73,  85,  95,  98, 107, 285], dtype=int64),)]]\n",
      "[0.86649659863945583]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858843537415\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0888888888889\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   7]\n",
      " [ 41  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91       240\n",
      "          1       0.65      0.24      0.35        54\n",
      "\n",
      "avg / total       0.81      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  0,  19,  55,  73,  85,  95,  98, 107, 285], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  0,  19,  36,  45,  53,  56,  57,  64,  73,  85,  95,  98, 107,\n",
      "       151, 168, 181, 256, 261, 265, 285], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.858843537414966]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  0,  19,  55,  73,  85,  95,  98, 107, 285], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  0,  19,  36,  45,  53,  56,  57,  64,  73,  85,  95,  98, 107,\n",
      "       151, 168, 181, 256, 261, 265, 285], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.858843537414966, 0.84438775510204078]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  0,  19,  55,  73,  85,  95,  98, 107, 285], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  0,  19,  36,  45,  53,  56,  57,  64,  73,  85,  95,  98, 107,\n",
      "       151, 168, 181, 256, 261, 265, 285], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.858843537414966, 0.84438775510204078, 0.84438775510204078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  0,  19,  55,  73,  85,  95,  98, 107, 285], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  0,  19,  36,  45,  53,  56,  57,  64,  73,  85,  95,  98, 107,\n",
      "       151, 168, 181, 256, 261, 265, 285], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.858843537414966, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0888888888889\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   3]\n",
      " [ 45   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91       240\n",
      "          1       0.75      0.17      0.27        54\n",
      "\n",
      "avg / total       0.82      0.84      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  0,  19,  55,  73,  85,  95,  98, 107, 285], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  0,  19,  36,  45,  53,  56,  57,  64,  73,  85,  95,  98, 107,\n",
      "       151, 168, 181, 256, 261, 265, 285], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([  0,  19,  36,  53,  64, 107, 118, 151, 168, 180, 181, 185], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.858843537414966, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.83418367346938771]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.864795918367\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00185185185185\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   4]\n",
      " [ 40  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91       240\n",
      "          1       0.78      0.26      0.39        54\n",
      "\n",
      "avg / total       0.84      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82653061224489799, 'LogisticRegression', (array([  0,  19,  55,  73,  85,  95,  98, 107, 285], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  0,  19,  36,  45,  53,  56,  57,  64,  73,  85,  95,  98, 107,\n",
      "       151, 168, 181, 256, 261, 265, 285], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([  0,  19,  36,  53,  64, 107, 118, 151, 168, 180, 181, 185], dtype=int64),)], [0.85034013605442171, 'XGBoost', (array([  0,  19,  21,  53,  55,  56,  66,  95, 151, 152, 168, 176, 180,\n",
      "       181, 185, 205, 236, 261], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.858843537414966, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.83418367346938771, 0.86479591836734693]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.871611090503\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0457987738911\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   3]\n",
      " [ 42  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.91       235\n",
      "          1       0.85      0.29      0.43        59\n",
      "\n",
      "avg / total       0.85      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  7,  27,  31,  34,  75,  94,  99, 143, 169, 179, 184, 185, 191,\n",
      "       207, 239, 262, 265, 267, 268, 292], dtype=int64),)]]\n",
      "[0.87161109050324415]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865654326782\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0390191128741\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   2]\n",
      " [ 47  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       235\n",
      "          1       0.86      0.20      0.33        59\n",
      "\n",
      "avg / total       0.84      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  7,  27,  31,  34,  75,  94,  99, 143, 169, 179, 184, 185, 191,\n",
      "       207, 239, 262, 265, 267, 268, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  27,  31,  75,  94, 120, 179, 184, 191, 262, 265, 268, 290, 293], dtype=int64),)]]\n",
      "[0.87161109050324415, 0.86565432678215659]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.799319727891\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848640966509\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.200680272109\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.251063829787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   0]\n",
      " [ 59   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       235\n",
      "\n",
      "avg / total       0.80      1.00      0.89       235\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  7,  27,  31,  34,  75,  94,  99, 143, 169, 179, 184, 185, 191,\n",
      "       207, 239, 262, 265, 267, 268, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  27,  31,  75,  94, 120, 179, 184, 191, 262, 265, 268, 290, 293], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87161109050324415, 0.86565432678215659, 0.8486409665094049]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.799319727891\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848640966509\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.200680272109\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.251063829787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   0]\n",
      " [ 59   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       235\n",
      "\n",
      "avg / total       0.80      1.00      0.89       235\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  7,  27,  31,  34,  75,  94,  99, 143, 169, 179, 184, 185, 191,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       207, 239, 262, 265, 267, 268, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  27,  31,  75,  94, 120, 179, 184, 191, 262, 265, 268, 290, 293], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79931972789115646, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87161109050324415, 0.86565432678215659, 0.8486409665094049, 0.8486409665094049]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.799319727891\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848640966509\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.200680272109\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.251063829787\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   0]\n",
      " [ 59   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       235\n",
      "\n",
      "avg / total       0.80      1.00      0.89       235\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  7,  27,  31,  34,  75,  94,  99, 143, 169, 179, 184, 185, 191,\n",
      "       207, 239, 262, 265, 267, 268, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  27,  31,  75,  94, 120, 179, 184, 191, 262, 265, 268, 290, 293], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79931972789115646, 'KNN', (array([], dtype=int64),)], [0.79931972789115646, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87161109050324415, 0.86565432678215659, 0.8486409665094049, 0.8486409665094049, 0.8486409665094049]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835900955138\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.187450414713\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230   5]\n",
      " [ 51   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89       235\n",
      "          1       0.62      0.14      0.22        59\n",
      "\n",
      "avg / total       0.78      0.81      0.76       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  7,  27,  31,  34,  75,  94,  99, 143, 169, 179, 184, 185, 191,\n",
      "       207, 239, 262, 265, 267, 268, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  27,  31,  75,  94, 120, 179, 184, 191, 262, 265, 268, 290, 293], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79931972789115646, 'KNN', (array([], dtype=int64),)], [0.79931972789115646, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.80952380952380953, 'RandomForest', (array([  7,  27,  75,  94, 106, 179, 184, 190, 191, 197, 249, 261, 293], dtype=int64),)]]\n",
      "[0.87161109050324415, 0.86565432678215659, 0.8486409665094049, 0.8486409665094049, 0.8486409665094049, 0.83590095513811224]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865641311287\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.187450414713\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[227   8]\n",
      " [ 48  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.89       235\n",
      "          1       0.58      0.19      0.28        59\n",
      "\n",
      "avg / total       0.78      0.81      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([  7,  27,  31,  34,  75,  94,  99, 143, 169, 179, 184, 185, 191,\n",
      "       207, 239, 262, 265, 267, 268, 292], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  7,  27,  31,  75,  94, 120, 179, 184, 191, 262, 265, 268, 290, 293], dtype=int64),)], [0.79931972789115646, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79931972789115646, 'KNN', (array([], dtype=int64),)], [0.79931972789115646, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.80952380952380953, 'RandomForest', (array([  7,  27,  75,  94, 106, 179, 184, 190, 191, 197, 249, 261, 293], dtype=int64),)], [0.80952380952380953, 'XGBoost', (array([  4,   7,  27,  31,  75,  94,  99, 106, 143, 179, 184, 191, 197,\n",
      "       214, 215, 223, 252, 276, 293], dtype=int64),)]]\n",
      "[0.87161109050324415, 0.86565432678215659, 0.8486409665094049, 0.8486409665094049, 0.8486409665094049, 0.83590095513811224, 0.86564131128720978]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863088138231\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0629683865966\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   2]\n",
      " [ 35  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       247\n",
      "          1       0.86      0.26      0.39        47\n",
      "\n",
      "avg / total       0.87      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 164, 190, 213, 223, 292], dtype=int64),)]]\n",
      "[0.8630881382312855]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851176829842\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0123180291153\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   2]\n",
      " [ 37  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       247\n",
      "          1       0.83      0.21      0.34        47\n",
      "\n",
      "avg / total       0.86      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 164, 190, 213, 223, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 190, 204, 292], dtype=int64),)]]\n",
      "[0.8630881382312855, 0.85117682984245802]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 164, 190, 213, 223, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 190, 204, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8630881382312855, 0.85117682984245802, 0.83843684060636081]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 164, 190, 213, 223, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 190, 204, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8630881382312855, 0.85117682984245802, 0.83843684060636081, 0.83843684060636081]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 164, 190, 213, 223, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 190, 204, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8630881382312855, 0.85117682984245802, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.81885940016\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0130071496253\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   4]\n",
      " [ 36  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       247\n",
      "          1       0.73      0.23      0.35        47\n",
      "\n",
      "avg / total       0.85      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 164, 190, 213, 223, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 190, 204, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 12,  68,  73,  79,  84,  99, 109, 116, 124, 164, 190, 192, 227,\n",
      "       252, 276], dtype=int64),)]]\n",
      "[0.8630881382312855, 0.85117682984245802, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081, 0.81885940016010839]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.855426366807\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.113618744078\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   4]\n",
      " [ 31  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       247\n",
      "          1       0.80      0.34      0.48        47\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 164, 190, 213, 223, 292], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 57,  62,  79,  84, 102, 116, 117, 124, 140, 190, 204, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 12,  68,  73,  79,  84,  99, 109, 116, 124, 164, 190, 192, 227,\n",
      "       252, 276], dtype=int64),)], [0.88095238095238093, 'XGBoost', (array([ 12,  23,  28,  74,  79,  84, 116, 124, 140, 164, 177, 190, 192,\n",
      "       201, 213, 227, 252, 276, 277, 292], dtype=int64),)]]\n",
      "[0.8630881382312855, 0.85117682984245802, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081, 0.81885940016010839, 0.85542636680737127]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854589031099\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0486840836788\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239  14]\n",
      " [ 23  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.94      0.93       253\n",
      "          1       0.56      0.44      0.49        41\n",
      "\n",
      "avg / total       0.86      0.87      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 12,  23,  32,  56,  65,  69,  75,  87,  89,  92,  96, 105, 106,\n",
      "       108, 117, 136, 140, 145, 159, 165, 168, 186, 209, 213, 215, 217,\n",
      "       231, 248, 261, 265, 269, 275], dtype=int64),)]]\n",
      "[0.8545890310986658]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853740865746\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.133712522896\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241  12]\n",
      " [ 28  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.92       253\n",
      "          1       0.52      0.32      0.39        41\n",
      "\n",
      "avg / total       0.84      0.86      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 12,  23,  32,  56,  65,  69,  75,  87,  89,  92,  96, 105, 106,\n",
      "       108, 117, 136, 140, 145, 159, 165, 168, 186, 209, 213, 215, 217,\n",
      "       231, 248, 261, 265, 269, 275], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 22,  23,  27,  32,  56,  65,  69,  75, 103, 105, 106, 108, 117,\n",
      "       140, 145, 161, 168, 181, 186, 209, 213, 215, 217, 265, 275], dtype=int64),)]]\n",
      "[0.8545890310986658, 0.85374086574556818]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 12,  23,  32,  56,  65,  69,  75,  87,  89,  92,  96, 105, 106,\n",
      "       108, 117, 136, 140, 145, 159, 165, 168, 186, 209, 213, 215, 217,\n",
      "       231, 248, 261, 265, 269, 275], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 22,  23,  27,  32,  56,  65,  69,  75, 103, 105, 106, 108, 117,\n",
      "       140, 145, 161, 168, 181, 186, 209, 213, 215, 217, 265, 275], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8545890310986658, 0.85374086574556818, 0.83333477765483888]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 12,  23,  32,  56,  65,  69,  75,  87,  89,  92,  96, 105, 106,\n",
      "       108, 117, 136, 140, 145, 159, 165, 168, 186, 209, 213, 215, 217,\n",
      "       231, 248, 261, 265, 269, 275], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 22,  23,  27,  32,  56,  65,  69,  75, 103, 105, 106, 108, 117,\n",
      "       140, 145, 161, 168, 181, 186, 209, 213, 215, 217, 265, 275], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8545890310986658, 0.85374086574556818, 0.83333477765483888, 0.83333477765483888]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 12,  23,  32,  56,  65,  69,  75,  87,  89,  92,  96, 105, 106,\n",
      "       108, 117, 136, 140, 145, 159, 165, 168, 186, 209, 213, 215, 217,\n",
      "       231, 248, 261, 265, 269, 275], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 22,  23,  27,  32,  56,  65,  69,  75, 103, 105, 106, 108, 117,\n",
      "       140, 145, 161, 168, 181, 186, 209, 213, 215, 217, 265, 275], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8545890310986658, 0.85374086574556818, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.821421283415\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0203412706064\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   4]\n",
      " [ 32   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       253\n",
      "          1       0.69      0.22      0.33        41\n",
      "\n",
      "avg / total       0.86      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 12,  23,  32,  56,  65,  69,  75,  87,  89,  92,  96, 105, 106,\n",
      "       108, 117, 136, 140, 145, 159, 165, 168, 186, 209, 213, 215, 217,\n",
      "       231, 248, 261, 265, 269, 275], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 22,  23,  27,  32,  56,  65,  69,  75, 103, 105, 106, 108, 117,\n",
      "       140, 145, 161, 168, 181, 186, 209, 213, 215, 217, 265, 275], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87755102040816324, 'RandomForest', (array([ 26,  27,  32,  56,  69, 108, 195, 209, 213, 217, 221, 261, 265], dtype=int64),)]]\n",
      "[0.8545890310986658, 0.85374086574556818, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888, 0.82142128341545717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.908163265306\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.855445884516\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0918367346939\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.234744047045\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   5]\n",
      " [ 22  19]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       253\n",
      "          1       0.79      0.46      0.58        41\n",
      "\n",
      "avg / total       0.90      0.91      0.90       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87414965986394555, 'LogisticRegression', (array([ 12,  23,  32,  56,  65,  69,  75,  87,  89,  92,  96, 105, 106,\n",
      "       108, 117, 136, 140, 145, 159, 165, 168, 186, 209, 213, 215, 217,\n",
      "       231, 248, 261, 265, 269, 275], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 22,  23,  27,  32,  56,  65,  69,  75, 103, 105, 106, 108, 117,\n",
      "       140, 145, 161, 168, 181, 186, 209, 213, 215, 217, 265, 275], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87755102040816324, 'RandomForest', (array([ 26,  27,  32,  56,  69, 108, 195, 209, 213, 217, 221, 261, 265], dtype=int64),)], [0.90816326530612246, 'XGBoost', (array([  3,  12,  17,  32,  56,  65,  69,  75,  96, 106, 108, 140, 161,\n",
      "       164, 168, 179, 209, 213, 221, 248, 265, 269, 272, 286], dtype=int64),)]]\n",
      "[0.8545890310986658, 0.85374086574556818, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888, 0.82142128341545717, 0.85544588451599246]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0538617886179\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   3]\n",
      " [ 35  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       246\n",
      "          1       0.81      0.27      0.41        48\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  0,  10,  11,  34,  36,  87,  95, 100, 111, 140, 156, 168, 202,\n",
      "       222, 225, 256], dtype=int64),)]]\n",
      "[0.86394557823129248]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848639455782\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0706300813008\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   2]\n",
      " [ 41   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       246\n",
      "          1       0.78      0.15      0.25        48\n",
      "\n",
      "avg / total       0.84      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  0,  10,  11,  34,  36,  87,  95, 100, 111, 140, 156, 168, 202,\n",
      "       222, 225, 256], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  0,  11,  34,  95, 100, 111, 168, 225, 282], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84863945578231303]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  0,  10,  11,  34,  36,  87,  95, 100, 111, 140, 156, 168, 202,\n",
      "       222, 225, 256], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  0,  11,  34,  95, 100, 111, 168, 225, 282], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84863945578231303, 0.8392857142857143]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  0,  10,  11,  34,  36,  87,  95, 100, 111, 140, 156, 168, 202,\n",
      "       222, 225, 256], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  0,  11,  34,  95, 100, 111, 168, 225, 282], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84863945578231303, 0.8392857142857143, 0.8392857142857143]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  0,  10,  11,  34,  36,  87,  95, 100, 111, 140, 156, 168, 202,\n",
      "       222, 225, 256], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  0,  11,  34,  95, 100, 111, 168, 225, 282], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84863945578231303, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.120426829268\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   6]\n",
      " [ 39   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91       246\n",
      "          1       0.60      0.19      0.29        48\n",
      "\n",
      "avg / total       0.82      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  0,  10,  11,  34,  36,  87,  95, 100, 111, 140, 156, 168, 202,\n",
      "       222, 225, 256], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  0,  11,  34,  95, 100, 111, 168, 225, 282], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  0,   3,   8,  10,  38,  61,  79,  87, 156, 162, 168, 178, 206,\n",
      "       224, 282], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84863945578231303, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.84353741496598644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00406504065041\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   3]\n",
      " [ 37  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       246\n",
      "          1       0.79      0.23      0.35        48\n",
      "\n",
      "avg / total       0.85      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([  0,  10,  11,  34,  36,  87,  95, 100, 111, 140, 156, 168, 202,\n",
      "       222, 225, 256], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([  0,  11,  34,  95, 100, 111, 168, 225, 282], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  0,   3,   8,  10,  38,  61,  79,  87, 156, 162, 168, 178, 206,\n",
      "       224, 282], dtype=int64),)], [0.86394557823129248, 'XGBoost', (array([  0,   8,  34,  67,  68,  79, 140, 168, 185, 199, 225, 232, 256, 282], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84863945578231303, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.84353741496598644, 0.86734693877551017]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866493859409\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0738441582507\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   3]\n",
      " [ 31  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       251\n",
      "          1       0.80      0.28      0.41        43\n",
      "\n",
      "avg / total       0.88      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  4,  12,  17,  35,  39,  47,  77,  99, 104, 118, 132, 192, 207,\n",
      "       218, 287], dtype=int64),)]]\n",
      "[0.86649385940901424]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85034602955\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.116834985639\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   5]\n",
      " [ 36   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       251\n",
      "          1       0.58      0.16      0.25        43\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  4,  12,  17,  35,  39,  47,  77,  99, 104, 118, 132, 192, 207,\n",
      "       218, 287], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 12,  17,  32,  35,  47,  77,  96, 161, 218, 260, 278, 287], dtype=int64),)]]\n",
      "[0.86649385940901424, 0.85034602955022043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  4,  12,  17,  35,  39,  47,  77,  99, 104, 118, 132, 192, 207,\n",
      "       218, 287], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 12,  17,  32,  35,  47,  77,  96, 161, 218, 260, 278, 287], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86649385940901424, 0.85034602955022043, 0.83503546899454539]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  4,  12,  17,  35,  39,  47,  77,  99, 104, 118, 132, 192, 207,\n",
      "       218, 287], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 12,  17,  32,  35,  47,  77,  96, 161, 218, 260, 278, 287], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86649385940901424, 0.85034602955022043, 0.83503546899454539, 0.83503546899454539]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  4,  12,  17,  35,  39,  47,  77,  99, 104, 118, 132, 192, 207,\n",
      "       218, 287], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 12,  17,  32,  35,  47,  77,  96, 161, 218, 260, 278, 287], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86649385940901424, 0.85034602955022043, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.831623278806\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.144074863337\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   6]\n",
      " [ 36   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       251\n",
      "          1       0.54      0.16      0.25        43\n",
      "\n",
      "avg / total       0.82      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  4,  12,  17,  35,  39,  47,  77,  99, 104, 118, 132, 192, 207,\n",
      "       218, 287], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 12,  17,  32,  35,  47,  77,  96, 161, 218, 260, 278, 287], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 12,  17,  35,  70,  88,  96, 118, 151, 179, 186, 220, 258, 278], dtype=int64),)]]\n",
      "[0.86649385940901424, 0.85034602955022043, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.83162327880593556]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863953668645\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.116834985639\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   4]\n",
      " [ 37   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       251\n",
      "          1       0.60      0.14      0.23        43\n",
      "\n",
      "avg / total       0.83      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  4,  12,  17,  35,  39,  47,  77,  99, 104, 118, 132, 192, 207,\n",
      "       218, 287], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 12,  17,  32,  35,  47,  77,  96, 161, 218, 260, 278, 287], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 12,  17,  35,  70,  88,  96, 118, 151, 179, 186, 220, 258, 278], dtype=int64),)], [0.86054421768707479, 'XGBoost', (array([ 17,  33,  44,  47,  77,  88, 142, 218, 226, 267], dtype=int64),)]]\n",
      "[0.86649385940901424, 0.85034602955022043, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.83162327880593556, 0.86395366864524326]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866509027552\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0308555399719\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   9]\n",
      " [ 31  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.92       248\n",
      "          1       0.62      0.33      0.43        46\n",
      "\n",
      "avg / total       0.84      0.86      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  5,  11,  21,  34,  62,  94, 121, 124, 130, 140, 145, 147, 155,\n",
      "       165, 166, 182, 184, 188, 216, 229, 242, 244, 285, 288], dtype=int64),)]]\n",
      "[0.8665090275517221]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846931609241\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0566269284712\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   3]\n",
      " [ 38   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       248\n",
      "          1       0.73      0.17      0.28        46\n",
      "\n",
      "avg / total       0.84      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  5,  11,  21,  34,  62,  94, 121, 124, 130, 140, 145, 147, 155,\n",
      "       165, 166, 182, 184, 188, 216, 229, 242, 244, 285, 288], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 11,  34, 121, 124, 130, 140, 184, 188, 216, 244, 288], dtype=int64),)]]\n",
      "[0.8665090275517221, 0.84693160924066502]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  5,  11,  21,  34,  62,  94, 121, 124, 130, 140, 145, 147, 155,\n",
      "       165, 166, 182, 184, 188, 216, 229, 242, 244, 285, 288], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 11,  34, 121, 124, 130, 140, 184, 188, 216, 244, 288], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8665090275517221, 0.84693160924066502, 0.83758650047030658]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  5,  11,  21,  34,  62,  94, 121, 124, 130, 140, 145, 147, 155,\n",
      "       165, 166, 182, 184, 188, 216, 229, 242, 244, 285, 288], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 11,  34, 121, 124, 130, 140, 184, 188, 216, 244, 288], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8665090275517221, 0.84693160924066502, 0.83758650047030658, 0.83758650047030658]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  5,  11,  21,  34,  62,  94, 121, 124, 130, 140, 145, 147, 155,\n",
      "       165, 166, 182, 184, 188, 216, 229, 242, 244, 285, 288], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 11,  34, 121, 124, 130, 140, 184, 188, 216, 244, 288], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8665090275517221, 0.84693160924066502, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.8358727715\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.133941093969\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   9]\n",
      " [ 35  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.92       248\n",
      "          1       0.55      0.24      0.33        46\n",
      "\n",
      "avg / total       0.82      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  5,  11,  21,  34,  62,  94, 121, 124, 130, 140, 145, 147, 155,\n",
      "       165, 166, 182, 184, 188, 216, 229, 242, 244, 285, 288], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 11,  34, 121, 124, 130, 140, 184, 188, 216, 244, 288], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 10,  20,  61, 121, 124, 138, 140, 155, 165, 174, 177, 178, 182,\n",
      "       188, 191, 202, 216, 244, 285, 290], dtype=int64),)]]\n",
      "[0.8665090275517221, 0.84693160924066502, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.8358727715004578]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866506852769\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0206872370266\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   4]\n",
      " [ 34  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       248\n",
      "          1       0.75      0.26      0.39        46\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  5,  11,  21,  34,  62,  94, 121, 124, 130, 140, 145, 147, 155,\n",
      "       165, 166, 182, 184, 188, 216, 229, 242, 244, 285, 288], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 11,  34, 121, 124, 130, 140, 184, 188, 216, 244, 288], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([ 10,  20,  61, 121, 124, 138, 140, 155, 165, 174, 177, 178, 182,\n",
      "       188, 191, 202, 216, 244, 285, 290], dtype=int64),)], [0.87074829931972786, 'XGBoost', (array([ 13,  20,  34,  47,  52,  87,  93, 121, 130, 140, 145, 182, 188,\n",
      "       242, 244, 276], dtype=int64),)]]\n",
      "[0.8665090275517221, 0.84693160924066502, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.8358727715004578, 0.86650685276876549]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861385294244\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0450787401575\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244  10]\n",
      " [ 23  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.94       254\n",
      "          1       0.63      0.42      0.51        40\n",
      "\n",
      "avg / total       0.88      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 18,  35,  36,  38,  39,  40,  45,  52,  59,  63,  64,  66,  81,\n",
      "       128, 140, 146, 147, 159, 161, 206, 208, 213, 220, 250, 262, 274, 283], dtype=int64),)]]\n",
      "[0.86138529424381771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.897959183673\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848627951014\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.102040816327\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.13188976378\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   6]\n",
      " [ 24  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       254\n",
      "          1       0.73      0.40      0.52        40\n",
      "\n",
      "avg / total       0.89      0.90      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 18,  35,  36,  38,  39,  40,  45,  52,  59,  63,  64,  66,  81,\n",
      "       128, 140, 146, 147, 159, 161, 206, 208, 213, 220, 250, 262, 274, 283], dtype=int64),)], [0.89795918367346939, 'SelectKBest+LR', (array([ 18,  36,  38,  39,  40,  45,  59,  63, 128, 140, 146, 147, 156,\n",
      "       161, 206, 213, 250, 262, 274, 283, 284, 292], dtype=int64),)]]\n",
      "[0.86138529424381771, 0.84862795101445831]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 18,  35,  36,  38,  39,  40,  45,  52,  59,  63,  64,  66,  81,\n",
      "       128, 140, 146, 147, 159, 161, 206, 208, 213, 220, 250, 262, 274, 283], dtype=int64),)], [0.89795918367346939, 'SelectKBest+LR', (array([ 18,  36,  38,  39,  40,  45,  59,  63, 128, 140, 146, 147, 156,\n",
      "       161, 206, 213, 250, 262, 274, 283, 284, 292], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86138529424381771, 0.84862795101445831, 0.83248443751878443]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 18,  35,  36,  38,  39,  40,  45,  52,  59,  63,  64,  66,  81,\n",
      "       128, 140, 146, 147, 159, 161, 206, 208, 213, 220, 250, 262, 274, 283], dtype=int64),)], [0.89795918367346939, 'SelectKBest+LR', (array([ 18,  36,  38,  39,  40,  45,  59,  63, 128, 140, 146, 147, 156,\n",
      "       161, 206, 213, 250, 262, 274, 283, 284, 292], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86138529424381771, 0.84862795101445831, 0.83248443751878443, 0.83248443751878443]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 18,  35,  36,  38,  39,  40,  45,  52,  59,  63,  64,  66,  81,\n",
      "       128, 140, 146, 147, 159, 161, 206, 208, 213, 220, 250, 262, 274, 283], dtype=int64),)], [0.89795918367346939, 'SelectKBest+LR', (array([ 18,  36,  38,  39,  40,  45,  59,  63, 128, 140, 146, 147, 156,\n",
      "       161, 206, 213, 250, 262, 274, 283, 284, 292], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86138529424381771, 0.84862795101445831, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834200297001\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.302165354331\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236  18]\n",
      " [ 27  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.91       254\n",
      "          1       0.42      0.33      0.37        40\n",
      "\n",
      "avg / total       0.83      0.85      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 18,  35,  36,  38,  39,  40,  45,  52,  59,  63,  64,  66,  81,\n",
      "       128, 140, 146, 147, 159, 161, 206, 208, 213, 220, 250, 262, 274, 283], dtype=int64),)], [0.89795918367346939, 'SelectKBest+LR', (array([ 18,  36,  38,  39,  40,  45,  59,  63, 128, 140, 146, 147, 156,\n",
      "       161, 206, 213, 250, 262, 274, 283, 284, 292], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([ 18,  20,  21,  22,  28,  35,  38,  40,  45,  64,  67,  72,  78,\n",
      "       109, 128, 146, 161, 180, 194, 220, 222, 223, 225, 234, 250, 262,\n",
      "       268, 272, 274, 283, 287], dtype=int64),)]]\n",
      "[0.86138529424381771, 0.84862795101445831, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443, 0.83420029700119891]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860556624464\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0127952755906\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244  10]\n",
      " [ 25  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93       254\n",
      "          1       0.60      0.38      0.46        40\n",
      "\n",
      "avg / total       0.87      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 18,  35,  36,  38,  39,  40,  45,  52,  59,  63,  64,  66,  81,\n",
      "       128, 140, 146, 147, 159, 161, 206, 208, 213, 220, 250, 262, 274, 283], dtype=int64),)], [0.89795918367346939, 'SelectKBest+LR', (array([ 18,  36,  38,  39,  40,  45,  59,  63, 128, 140, 146, 147, 156,\n",
      "       161, 206, 213, 250, 262, 274, 283, 284, 292], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([ 18,  20,  21,  22,  28,  35,  38,  40,  45,  64,  67,  72,  78,\n",
      "       109, 128, 146, 161, 180, 194, 220, 222, 223, 225, 234, 250, 262,\n",
      "       268, 272, 274, 283, 287], dtype=int64),)], [0.88095238095238093, 'XGBoost', (array([ 13,  20,  35,  38,  40,  45,  46,  59,  64,  78,  81, 109, 114,\n",
      "       140, 147, 158, 159, 161, 180, 206, 222, 244, 253, 262, 274], dtype=int64),)]]\n",
      "[0.86138529424381771, 0.84862795101445831, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443, 0.83420029700119891, 0.8605566244641456]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857993197279\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.120426829268\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234  12]\n",
      " [ 33  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       246\n",
      "          1       0.56      0.31      0.40        48\n",
      "\n",
      "avg / total       0.82      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 18,  24,  26,  75,  89,  93, 103, 104, 113, 115, 138, 146, 148,\n",
      "       165, 175, 178, 179, 191, 194, 206, 214, 227, 228, 231, 232, 236, 278], dtype=int64),)]]\n",
      "[0.85799319727891155]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859693877551\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0706300813008\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   5]\n",
      " [ 38  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       246\n",
      "          1       0.67      0.21      0.32        48\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 18,  24,  26,  75,  89,  93, 103, 104, 113, 115, 138, 146, 148,\n",
      "       165, 175, 178, 179, 191, 194, 206, 214, 227, 228, 231, 232, 236, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 24,  75, 103, 104, 115, 124, 138, 165, 191, 214, 226, 228, 232,\n",
      "       263, 278], dtype=int64),)]]\n",
      "[0.85799319727891155, 0.85969387755102034]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 18,  24,  26,  75,  89,  93, 103, 104, 113, 115, 138, 146, 148,\n",
      "       165, 175, 178, 179, 191, 194, 206, 214, 227, 228, 231, 232, 236, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 24,  75, 103, 104, 115, 124, 138, 165, 191, 214, 226, 228, 232,\n",
      "       263, 278], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85799319727891155, 0.85969387755102034, 0.8392857142857143]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 18,  24,  26,  75,  89,  93, 103, 104, 113, 115, 138, 146, 148,\n",
      "       165, 175, 178, 179, 191, 194, 206, 214, 227, 228, 231, 232, 236, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 24,  75, 103, 104, 115, 124, 138, 165, 191, 214, 226, 228, 232,\n",
      "       263, 278], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85799319727891155, 0.85969387755102034, 0.8392857142857143, 0.8392857142857143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 18,  24,  26,  75,  89,  93, 103, 104, 113, 115, 138, 146, 148,\n",
      "       165, 175, 178, 179, 191, 194, 206, 214, 227, 228, 231, 232, 236, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 24,  75, 103, 104, 115, 124, 138, 165, 191, 214, 226, 228, 232,\n",
      "       263, 278], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85799319727891155, 0.85969387755102034, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85119047619\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.145325203252\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   6]\n",
      " [ 40   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.91       246\n",
      "          1       0.57      0.17      0.26        48\n",
      "\n",
      "avg / total       0.81      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 18,  24,  26,  75,  89,  93, 103, 104, 113, 115, 138, 146, 148,\n",
      "       165, 175, 178, 179, 191, 194, 206, 214, 227, 228, 231, 232, 236, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 24,  75, 103, 104, 115, 124, 138, 165, 191, 214, 226, 228, 232,\n",
      "       263, 278], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84353741496598644, 'RandomForest', (array([ 75, 113, 132, 148, 149, 165, 167, 175, 214, 231, 236, 266, 278, 293], dtype=int64),)]]\n",
      "[0.85799319727891155, 0.85969387755102034, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.85119047619047628]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866496598639\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0787601626016\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   4]\n",
      " [ 33  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       246\n",
      "          1       0.79      0.31      0.45        48\n",
      "\n",
      "avg / total       0.87      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 18,  24,  26,  75,  89,  93, 103, 104, 113, 115, 138, 146, 148,\n",
      "       165, 175, 178, 179, 191, 194, 206, 214, 227, 228, 231, 232, 236, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+LR', (array([ 24,  75, 103, 104, 115, 124, 138, 165, 191, 214, 226, 228, 232,\n",
      "       263, 278], dtype=int64),)], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83673469387755106, 'KNN', (array([], dtype=int64),)], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84353741496598644, 'RandomForest', (array([ 75, 113, 132, 148, 149, 165, 167, 175, 214, 231, 236, 266, 278, 293], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([ 24,  26,  34,  89, 103, 113, 114, 138, 165, 167, 175, 191, 194,\n",
      "       214, 231, 232, 251, 266, 278], dtype=int64),)]]\n",
      "[0.85799319727891155, 0.85969387755102034, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.85119047619047628, 0.86649659863945583]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.864803997714\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0102560087685\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   8]\n",
      " [ 35  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       241\n",
      "          1       0.69      0.34      0.46        53\n",
      "\n",
      "avg / total       0.84      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  2,  29,  33,  34,  69,  80,  85, 118, 128, 138, 171, 179, 180,\n",
      "       202, 208, 216, 225, 235, 238, 242, 243, 245, 257, 269, 275, 286], dtype=int64),)]]\n",
      "[0.86480399771369987]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859686777687\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.10483050184\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   7]\n",
      " [ 41  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91       241\n",
      "          1       0.63      0.23      0.33        53\n",
      "\n",
      "avg / total       0.81      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  2,  29,  33,  34,  69,  80,  85, 118, 128, 138, 171, 179, 180,\n",
      "       202, 208, 216, 225, 235, 238, 242, 243, 245, 257, 269, 275, 286], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  2,  30,  33,  34,  69,  80, 107, 128, 138, 179, 180, 202, 216,\n",
      "       225, 235, 242, 269, 275, 286], dtype=int64),)]]\n",
      "[0.86480399771369987, 0.85968677768706769]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  2,  29,  33,  34,  69,  80,  85, 118, 128, 138, 171, 179, 180,\n",
      "       202, 208, 216, 225, 235, 238, 242, 243, 245, 257, 269, 275, 286], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  2,  30,  33,  34,  69,  80, 107, 128, 138, 179, 180, 202, 216,\n",
      "       225, 235, 242, 269, 275, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86480399771369987, 0.85968677768706769, 0.84353890355788297]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  2,  29,  33,  34,  69,  80,  85, 118, 128, 138, 171, 179, 180,\n",
      "       202, 208, 216, 225, 235, 238, 242, 243, 245, 257, 269, 275, 286], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  2,  30,  33,  34,  69,  80, 107, 128, 138, 179, 180, 202, 216,\n",
      "       225, 235, 242, 269, 275, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86480399771369987, 0.85968677768706769, 0.84353890355788297, 0.84353890355788297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  2,  29,  33,  34,  69,  80,  85, 118, 128, 138, 171, 179, 180,\n",
      "       202, 208, 216, 225, 235, 238, 242, 243, 245, 257, 269, 275, 286], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  2,  30,  33,  34,  69,  80, 107, 128, 138, 179, 180, 202, 216,\n",
      "       225, 235, 242, 269, 275, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86480399771369987, 0.85968677768706769, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844382719345\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[228  13]\n",
      " [ 40  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90       241\n",
      "          1       0.50      0.25      0.33        53\n",
      "\n",
      "avg / total       0.79      0.82      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  2,  29,  33,  34,  69,  80,  85, 118, 128, 138, 171, 179, 180,\n",
      "       202, 208, 216, 225, 235, 238, 242, 243, 245, 257, 269, 275, 286], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  2,  30,  33,  34,  69,  80, 107, 128, 138, 179, 180, 202, 216,\n",
      "       225, 235, 242, 269, 275, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([  2,  12,  33,  34,  50,  56,  81,  85,  97, 107, 126, 137, 146,\n",
      "       171, 184, 222, 228, 229, 242, 243, 245, 269, 275, 277, 284, 286], dtype=int64),)]]\n",
      "[0.86480399771369987, 0.85968677768706769, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297, 0.84438271934506737]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.872448426212\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0793079151335\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   3]\n",
      " [ 37  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       241\n",
      "          1       0.84      0.30      0.44        53\n",
      "\n",
      "avg / total       0.86      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8537414965986394, 'LogisticRegression', (array([  2,  29,  33,  34,  69,  80,  85, 118, 128, 138, 171, 179, 180,\n",
      "       202, 208, 216, 225, 235, 238, 242, 243, 245, 257, 269, 275, 286], dtype=int64),)], [0.83673469387755106, 'SelectKBest+LR', (array([  2,  30,  33,  34,  69,  80, 107, 128, 138, 179, 180, 202, 216,\n",
      "       225, 235, 242, 269, 275, 286], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81972789115646261, 'RandomForest', (array([  2,  12,  33,  34,  50,  56,  81,  85,  97, 107, 126, 137, 146,\n",
      "       171, 184, 222, 228, 229, 242, 243, 245, 269, 275, 277, 284, 286], dtype=int64),)], [0.86394557823129248, 'XGBoost', (array([  2,  25,  30,  33,  34,  69, 107, 126, 137, 144, 146, 180, 202,\n",
      "       225, 242, 243, 245, 269, 275], dtype=int64),)]]\n",
      "[0.86480399771369987, 0.85968677768706769, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297, 0.84438271934506737, 0.87244842621194962]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856292517007\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0277777777778\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   5]\n",
      " [ 30  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       252\n",
      "          1       0.71      0.29      0.41        42\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  16,  22,  49,  55,  61,  63,  73,  78,  97, 102, 116, 143,\n",
      "       151, 198, 199, 204], dtype=int64),)]]\n",
      "[0.85629251700680287]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852891156463\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0277777777778\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   3]\n",
      " [ 34   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       252\n",
      "          1       0.73      0.19      0.30        42\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  16,  22,  49,  55,  61,  63,  73,  78,  97, 102, 116, 143,\n",
      "       151, 198, 199, 204], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 15,  22,  63,  73, 102, 116, 143, 198, 199, 250, 288], dtype=int64),)]]\n",
      "[0.85629251700680287, 0.85289115646258506]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  16,  22,  49,  55,  61,  63,  73,  78,  97, 102, 116, 143,\n",
      "       151, 198, 199, 204], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 15,  22,  63,  73, 102, 116, 143, 198, 199, 250, 288], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85629251700680287, 0.85289115646258506, 0.83418367346938771]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  16,  22,  49,  55,  61,  63,  73,  78,  97, 102, 116, 143,\n",
      "       151, 198, 199, 204], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 15,  22,  63,  73, 102, 116, 143, 198, 199, 250, 288], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85629251700680287, 0.85289115646258506, 0.83418367346938771, 0.83418367346938771]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  16,  22,  49,  55,  61,  63,  73,  78,  97, 102, 116, 143,\n",
      "       151, 198, 199, 204], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 15,  22,  63,  73, 102, 116, 143, 198, 199, 250, 288], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85629251700680287, 0.85289115646258506, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840986394558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0555555555556\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   3]\n",
      " [ 35   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       252\n",
      "          1       0.70      0.17      0.27        42\n",
      "\n",
      "avg / total       0.85      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  16,  22,  49,  55,  61,  63,  73,  78,  97, 102, 116, 143,\n",
      "       151, 198, 199, 204], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 15,  22,  63,  73, 102, 116, 143, 198, 199, 250, 288], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87074829931972786, 'RandomForest', (array([ 35,  73, 102, 113, 151, 198, 199, 239, 245, 288], dtype=int64),)]]\n",
      "[0.85629251700680287, 0.85289115646258506, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.8409863945578232]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854591836735\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   2]\n",
      " [ 34   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       252\n",
      "          1       0.80      0.19      0.31        42\n",
      "\n",
      "avg / total       0.87      0.88      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([ 15,  16,  22,  49,  55,  61,  63,  73,  78,  97, 102, 116, 143,\n",
      "       151, 198, 199, 204], dtype=int64),)], [0.87414965986394555, 'SelectKBest+LR', (array([ 15,  22,  63,  73, 102, 116, 143, 198, 199, 250, 288], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87074829931972786, 'RandomForest', (array([ 35,  73, 102, 113, 151, 198, 199, 239, 245, 288], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([ 55,  61, 102, 153, 198, 199, 239, 253, 284, 288], dtype=int64),)]]\n",
      "[0.85629251700680287, 0.85289115646258506, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.8409863945578232, 0.85459183673469374]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859710600691\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.144074863337\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237  14]\n",
      " [ 28  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.92       251\n",
      "          1       0.52      0.35      0.42        43\n",
      "\n",
      "avg / total       0.84      0.86      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([  0,   9,  10,  56,  69,  91,  95,  96, 100, 102, 105, 113, 120,\n",
      "       127, 167, 171, 178, 183, 201, 208, 211, 215, 223, 225, 228, 241,\n",
      "       258, 260, 273], dtype=int64),)]]\n",
      "[0.8597106006912113]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.855435021669\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0895951079403\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   7]\n",
      " [ 33  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       251\n",
      "          1       0.59      0.23      0.33        43\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([  0,   9,  10,  56,  69,  91,  95,  96, 100, 102, 105, 113, 120,\n",
      "       127, 167, 171, 178, 183, 201, 208, 211, 215, 223, 225, 228, 241,\n",
      "       258, 260, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  56,  95, 100, 102, 105, 113, 167, 171, 178, 183, 201, 208,\n",
      "       215, 223, 228, 260], dtype=int64),)]]\n",
      "[0.8597106006912113, 0.85543502166880681]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([  0,   9,  10,  56,  69,  91,  95,  96, 100, 102, 105, 113, 120,\n",
      "       127, 167, 171, 178, 183, 201, 208, 211, 215, 223, 225, 228, 241,\n",
      "       258, 260, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  56,  95, 100, 102, 105, 113, 167, 171, 178, 183, 201, 208,\n",
      "       215, 223, 228, 260], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.8597106006912113, 0.85543502166880681, 0.83503546899454539]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([  0,   9,  10,  56,  69,  91,  95,  96, 100, 102, 105, 113, 120,\n",
      "       127, 167, 171, 178, 183, 201, 208, 211, 215, 223, 225, 228, 241,\n",
      "       258, 260, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  56,  95, 100, 102, 105, 113, 167, 171, 178, 183, 201, 208,\n",
      "       215, 223, 228, 260], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.8597106006912113, 0.85543502166880681, 0.83503546899454539, 0.83503546899454539]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([  0,   9,  10,  56,  69,  91,  95,  96, 100, 102, 105, 113, 120,\n",
      "       127, 167, 171, 178, 183, 201, 208, 211, 215, 223, 225, 228, 241,\n",
      "       258, 260, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  56,  95, 100, 102, 105, 113, 167, 171, 178, 183, 201, 208,\n",
      "       215, 223, 228, 260], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.8597106006912113, 0.85543502166880681, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.823980991888\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.253034374131\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   9]\n",
      " [ 37   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       251\n",
      "          1       0.40      0.14      0.21        43\n",
      "\n",
      "avg / total       0.80      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([  0,   9,  10,  56,  69,  91,  95,  96, 100, 102, 105, 113, 120,\n",
      "       127, 167, 171, 178, 183, 201, 208, 211, 215, 223, 225, 228, 241,\n",
      "       258, 260, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  56,  95, 100, 102, 105, 113, 167, 171, 178, 183, 201, 208,\n",
      "       215, 223, 228, 260], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84353741496598644, 'RandomForest', (array([  9,  11,  14,  56,  69, 119, 138, 169, 178, 183, 201, 220, 240,\n",
      "       247, 281], dtype=int64),)]]\n",
      "[0.8597106006912113, 0.85543502166880681, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.82398099188784923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85627453216\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.128323913648\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   5]\n",
      " [ 27  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       251\n",
      "          1       0.76      0.37      0.50        43\n",
      "\n",
      "avg / total       0.88      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8571428571428571, 'LogisticRegression', (array([  0,   9,  10,  56,  69,  91,  95,  96, 100, 102, 105, 113, 120,\n",
      "       127, 167, 171, 178, 183, 201, 208, 211, 215, 223, 225, 228, 241,\n",
      "       258, 260, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([ 10,  56,  95, 100, 102, 105, 113, 167, 171, 178, 183, 201, 208,\n",
      "       215, 223, 228, 260], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84353741496598644, 'RandomForest', (array([  9,  11,  14,  56,  69, 119, 138, 169, 178, 183, 201, 220, 240,\n",
      "       247, 281], dtype=int64),)], [0.891156462585034, 'XGBoost', (array([  9,  10,  14,  38,  56,  69,  91,  95, 113, 127, 138, 159, 161,\n",
      "       183, 197, 201, 208, 223, 225, 228, 281], dtype=int64),)]]\n",
      "[0.8597106006912113, 0.85543502166880681, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.82398099188784923, 0.856274532160469]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.873333452199\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.138369374635\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[224  12]\n",
      " [ 41  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.89       236\n",
      "          1       0.59      0.29      0.39        58\n",
      "\n",
      "avg / total       0.79      0.82      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81972789115646261, 'LogisticRegression', (array([ 20,  35,  50,  58,  68,  85,  92, 118, 123, 146, 164, 183, 185,\n",
      "       206, 214, 217, 218, 232, 237, 245, 247, 248, 250, 255, 262, 271,\n",
      "       280, 281, 292], dtype=int64),)]]\n",
      "[0.87333345219933312]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.868211871539\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.116890707189\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   4]\n",
      " [ 48  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90       236\n",
      "          1       0.71      0.17      0.28        58\n",
      "\n",
      "avg / total       0.81      0.82      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81972789115646261, 'LogisticRegression', (array([ 20,  35,  50,  58,  68,  85,  92, 118, 123, 146, 164, 183, 185,\n",
      "       206, 214, 217, 218, 232, 237, 245, 247, 248, 250, 255, 262, 271,\n",
      "       280, 281, 292], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 58,  68, 123, 146, 183, 206, 217, 232, 237, 245, 248, 250, 255, 292], dtype=int64),)]]\n",
      "[0.87333345219933312, 0.86821187153918977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.802721088435\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.847790626373\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.197278911565\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.245762711864\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   0]\n",
      " [ 58   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       236\n",
      "\n",
      "avg / total       0.80      1.00      0.89       236\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81972789115646261, 'LogisticRegression', (array([ 20,  35,  50,  58,  68,  85,  92, 118, 123, 146, 164, 183, 185,\n",
      "       206, 214, 217, 218, 232, 237, 245, 247, 248, 250, 255, 262, 271,\n",
      "       280, 281, 292], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 58,  68, 123, 146, 183, 206, 217, 232, 237, 245, 248, 250, 255, 292], dtype=int64),)], [0.80272108843537415, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87333345219933312, 0.86821187153918977, 0.84779062637335045]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.802721088435\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.847790626373\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.197278911565\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.245762711864\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   0]\n",
      " [ 58   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       236\n",
      "\n",
      "avg / total       0.80      1.00      0.89       236\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81972789115646261, 'LogisticRegression', (array([ 20,  35,  50,  58,  68,  85,  92, 118, 123, 146, 164, 183, 185,\n",
      "       206, 214, 217, 218, 232, 237, 245, 247, 248, 250, 255, 262, 271,\n",
      "       280, 281, 292], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 58,  68, 123, 146, 183, 206, 217, 232, 237, 245, 248, 250, 255, 292], dtype=int64),)], [0.80272108843537415, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80272108843537415, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87333345219933312, 0.86821187153918977, 0.84779062637335045, 0.84779062637335045]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.802721088435\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.847790626373\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.197278911565\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.245762711864\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   0]\n",
      " [ 58   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89       236\n",
      "\n",
      "avg / total       0.80      1.00      0.89       236\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81972789115646261, 'LogisticRegression', (array([ 20,  35,  50,  58,  68,  85,  92, 118, 123, 146, 164, 183, 185,\n",
      "       206, 214, 217, 218, 232, 237, 245, 247, 248, 250, 255, 262, 271,\n",
      "       280, 281, 292], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 58,  68, 123, 146, 183, 206, 217, 232, 237, 245, 248, 250, 255, 292], dtype=int64),)], [0.80272108843537415, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80272108843537415, 'KNN', (array([], dtype=int64),)], [0.80272108843537415, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87333345219933312, 0.86821187153918977, 0.84779062637335045, 0.84779062637335045, 0.84779062637335045]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.80612244898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841829546289\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.19387755102\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.224284044418\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[231   5]\n",
      " [ 52   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89       236\n",
      "          1       0.55      0.10      0.17        58\n",
      "\n",
      "avg / total       0.76      0.81      0.75       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81972789115646261, 'LogisticRegression', (array([ 20,  35,  50,  58,  68,  85,  92, 118, 123, 146, 164, 183, 185,\n",
      "       206, 214, 217, 218, 232, 237, 245, 247, 248, 250, 255, 262, 271,\n",
      "       280, 281, 292], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 58,  68, 123, 146, 183, 206, 217, 232, 237, 245, 248, 250, 255, 292], dtype=int64),)], [0.80272108843537415, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80272108843537415, 'KNN', (array([], dtype=int64),)], [0.80272108843537415, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.80612244897959184, 'RandomForest', (array([  0,   8,  17,  45, 146, 167, 204, 212, 214, 275, 292], dtype=int64),)]]\n",
      "[0.87333345219933312, 0.86821187153918977, 0.84779062637335045, 0.84779062637335045, 0.84779062637335045, 0.84182954628914286]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.870780257008\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0119812974868\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   4]\n",
      " [ 42  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.98      0.91       236\n",
      "          1       0.80      0.28      0.41        58\n",
      "\n",
      "avg / total       0.84      0.84      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81972789115646261, 'LogisticRegression', (array([ 20,  35,  50,  58,  68,  85,  92, 118, 123, 146, 164, 183, 185,\n",
      "       206, 214, 217, 218, 232, 237, 245, 247, 248, 250, 255, 262, 271,\n",
      "       280, 281, 292], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 58,  68, 123, 146, 183, 206, 217, 232, 237, 245, 248, 250, 255, 292], dtype=int64),)], [0.80272108843537415, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.80272108843537415, 'KNN', (array([], dtype=int64),)], [0.80272108843537415, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.80612244897959184, 'RandomForest', (array([  0,   8,  17,  45, 146, 167, 204, 212, 214, 275, 292], dtype=int64),)], [0.84353741496598644, 'XGBoost', (array([  0,  35,  44,  58,  92, 101, 118, 123, 146, 152, 164, 168, 185,\n",
      "       194, 204, 206, 214, 232, 237, 250], dtype=int64),)]]\n",
      "[0.87333345219933312, 0.86821187153918977, 0.84779062637335045, 0.84779062637335045, 0.84779062637335045, 0.84182954628914286, 0.87078025700821315]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861396146023\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.198554618734\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241  10]\n",
      " [ 34   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92       251\n",
      "          1       0.47      0.21      0.29        43\n",
      "\n",
      "avg / total       0.82      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  2,  27,  32,  71, 127, 142, 150, 158, 164, 188, 192, 200, 202,\n",
      "       220, 228, 230, 254, 278, 281], dtype=int64),)]]\n",
      "[0.86139614602340542]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852899191539\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225794496433\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   6]\n",
      " [ 39   4]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       251\n",
      "          1       0.40      0.09      0.15        43\n",
      "\n",
      "avg / total       0.80      0.85      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  2,  27,  32,  71, 127, 142, 150, 158, 164, 188, 192, 200, 202,\n",
      "       220, 228, 230, 254, 278, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 32,  71,  89, 142, 164, 188, 192, 200, 254, 278], dtype=int64),)]]\n",
      "[0.86139614602340542, 0.85289919153854699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  2,  27,  32,  71, 127, 142, 150, 158, 164, 188, 192, 200, 202,\n",
      "       220, 228, 230, 254, 278, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 32,  71,  89, 142, 164, 188, 192, 200, 254, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86139614602340542, 0.85289919153854699, 0.83503546899454539]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  2,  27,  32,  71, 127, 142, 150, 158, 164, 188, 192, 200, 202,\n",
      "       220, 228, 230, 254, 278, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 32,  71,  89, 142, 164, 188, 192, 200, 254, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86139614602340542, 0.85289919153854699, 0.83503546899454539, 0.83503546899454539]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835035468995\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.146258503401\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.171314741036\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   0]\n",
      " [ 43   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       251\n",
      "\n",
      "avg / total       0.85      1.00      0.92       251\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  2,  27,  32,  71, 127, 142, 150, 158, 164, 188, 192, 200, 202,\n",
      "       220, 228, 230, 254, 278, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 32,  71,  89, 142, 164, 188, 192, 200, 254, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86139614602340542, 0.85289919153854699, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.837579998257\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.116834985639\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   4]\n",
      " [ 37   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       251\n",
      "          1       0.60      0.14      0.23        43\n",
      "\n",
      "avg / total       0.83      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  2,  27,  32,  71, 127, 142, 150, 158, 164, 188, 192, 200, 202,\n",
      "       220, 228, 230, 254, 278, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 32,  71,  89, 142, 164, 188, 192, 200, 254, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86054421768707479, 'RandomForest', (array([ 11, 109, 155, 185, 200, 214, 242, 271, 278, 289], dtype=int64),)]]\n",
      "[0.86139614602340542, 0.85289919153854699, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.83757999825663199]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863944969513\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00787547484481\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   7]\n",
      " [ 30  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       251\n",
      "          1       0.65      0.30      0.41        43\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  2,  27,  32,  71, 127, 142, 150, 158, 164, 188, 192, 200, 202,\n",
      "       220, 228, 230, 254, 278, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 32,  71,  89, 142, 164, 188, 192, 200, 254, 278], dtype=int64),)], [0.8537414965986394, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8537414965986394, 'KNN', (array([], dtype=int64),)], [0.8537414965986394, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86054421768707479, 'RandomForest', (array([ 11, 109, 155, 185, 200, 214, 242, 271, 278, 289], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([ 11,  23,  27,  40,  49,  80, 109, 127, 142, 150, 164, 173, 185,\n",
      "       188, 200, 211, 228, 246, 271, 289], dtype=int64),)]]\n",
      "[0.86139614602340542, 0.85289919153854699, 0.83503546899454539, 0.83503546899454539, 0.83503546899454539, 0.83757999825663199, 0.86394496951341671]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.107881136951\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248  10]\n",
      " [ 25  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93       258\n",
      "          1       0.52      0.31      0.39        36\n",
      "\n",
      "avg / total       0.86      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  3,  12,  18,  44,  48,  51,  60,  84,  86, 155, 158, 159, 193,\n",
      "       195, 216, 235, 251, 255, 261, 273, 283], dtype=int64),)]]\n",
      "[0.86394557823129248]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.202842377261\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   8]\n",
      " [ 30   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       258\n",
      "          1       0.43      0.17      0.24        36\n",
      "\n",
      "avg / total       0.84      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  3,  12,  18,  44,  48,  51,  60,  84,  86, 155, 158, 159, 193,\n",
      "       195, 216, 235, 251, 255, 261, 273, 283], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([  3,  48,  84,  86,  94, 134, 155, 158, 159, 193, 195, 251, 255, 273], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84183673469387754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829081632653\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.139534883721\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[258   0]\n",
      " [ 36   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93       258\n",
      "\n",
      "avg / total       0.88      1.00      0.93       258\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  3,  12,  18,  44,  48,  51,  60,  84,  86, 155, 158, 159, 193,\n",
      "       195, 216, 235, 251, 255, 261, 273, 283], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([  3,  48,  84,  86,  94, 134, 155, 158, 159, 193, 195, 251, 255, 273], dtype=int64),)], [0.87755102040816324, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84183673469387754, 0.82908163265306134]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829081632653\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.139534883721\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[258   0]\n",
      " [ 36   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93       258\n",
      "\n",
      "avg / total       0.88      1.00      0.93       258\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  3,  12,  18,  44,  48,  51,  60,  84,  86, 155, 158, 159, 193,\n",
      "       195, 216, 235, 251, 255, 261, 273, 283], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([  3,  48,  84,  86,  94, 134, 155, 158, 159, 193, 195, 251, 255, 273], dtype=int64),)], [0.87755102040816324, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87755102040816324, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84183673469387754, 0.82908163265306134, 0.82908163265306134]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829081632653\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.139534883721\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[258   0]\n",
      " [ 36   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93       258\n",
      "\n",
      "avg / total       0.88      1.00      0.93       258\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  3,  12,  18,  44,  48,  51,  60,  84,  86, 155, 158, 159, 193,\n",
      "       195, 216, 235, 251, 255, 261, 273, 283], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([  3,  48,  84,  86,  94, 134, 155, 158, 159, 193, 195, 251, 255, 273], dtype=int64),)], [0.87755102040816324, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87755102040816324, 'KNN', (array([], dtype=int64),)], [0.87755102040816324, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84183673469387754, 0.82908163265306134, 0.82908163265306134, 0.82908163265306134]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.823979591837\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.392764857881\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244  14]\n",
      " [ 30   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92       258\n",
      "          1       0.30      0.17      0.21        36\n",
      "\n",
      "avg / total       0.82      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  3,  12,  18,  44,  48,  51,  60,  84,  86, 155, 158, 159, 193,\n",
      "       195, 216, 235, 251, 255, 261, 273, 283], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([  3,  48,  84,  86,  94, 134, 155, 158, 159, 193, 195, 251, 255, 273], dtype=int64),)], [0.87755102040816324, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87755102040816324, 'KNN', (array([], dtype=int64),)], [0.87755102040816324, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([  3,   7,  23,  48,  52,  77,  86,  92, 143, 149, 155, 159, 164,\n",
      "       171, 195, 197, 209, 216, 235, 238], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84183673469387754, 0.82908163265306134, 0.82908163265306134, 0.82908163265306134, 0.82397959183673475]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.852891156463\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.202842377261\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   9]\n",
      " [ 29   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       258\n",
      "          1       0.44      0.19      0.27        36\n",
      "\n",
      "avg / total       0.84      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  3,  12,  18,  44,  48,  51,  60,  84,  86, 155, 158, 159, 193,\n",
      "       195, 216, 235, 251, 255, 261, 273, 283], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([  3,  48,  84,  86,  94, 134, 155, 158, 159, 193, 195, 251, 255, 273], dtype=int64),)], [0.87755102040816324, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.87755102040816324, 'KNN', (array([], dtype=int64),)], [0.87755102040816324, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.85034013605442171, 'RandomForest', (array([  3,   7,  23,  48,  52,  77,  86,  92, 143, 149, 155, 159, 164,\n",
      "       171, 195, 197, 209, 216, 235, 238], dtype=int64),)], [0.87074829931972786, 'XGBoost', (array([  3,   4,  48,  53,  60,  61,  77,  86,  94, 134, 155, 159, 171,\n",
      "       195, 216, 274], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.84183673469387754, 0.82908163265306134, 0.82908163265306134, 0.82908163265306134, 0.82397959183673475, 0.85289115646258506]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.901360544218\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853714823688\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0986394557823\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.160826771654\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   5]\n",
      " [ 24  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       254\n",
      "          1       0.76      0.40      0.52        40\n",
      "\n",
      "avg / total       0.89      0.90      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 10,  21,  25,  46,  52,  59,  69,  72,  78, 124, 145, 160, 174,\n",
      "       201, 204, 210, 229, 232, 250, 262, 277], dtype=int64),)]]\n",
      "[0.85371482368807683]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836720970056\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0450787401575\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   2]\n",
      " [ 31   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       254\n",
      "          1       0.82      0.23      0.35        40\n",
      "\n",
      "avg / total       0.88      0.89      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 10,  21,  25,  46,  52,  59,  69,  72,  78, 124, 145, 160, 174,\n",
      "       201, 204, 210, 229, 232, 250, 262, 277], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 46,  52,  59,  69,  78, 201, 208, 229, 232, 250, 277], dtype=int64),)]]\n",
      "[0.85371482368807683, 0.83672097005634871]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 10,  21,  25,  46,  52,  59,  69,  72,  78, 124, 145, 160, 174,\n",
      "       201, 204, 210, 229, 232, 250, 262, 277], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 46,  52,  59,  69,  78, 201, 208, 229, 232, 250, 277], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85371482368807683, 0.83672097005634871, 0.83248443751878443]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 10,  21,  25,  46,  52,  59,  69,  72,  78, 124, 145, 160, 174,\n",
      "       201, 204, 210, 229, 232, 250, 262, 277], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 46,  52,  59,  69,  78, 201, 208, 229, 232, 250, 277], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85371482368807683, 0.83672097005634871, 0.83248443751878443, 0.83248443751878443]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.832484437519\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.157480314961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[254   0]\n",
      " [ 40   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       254\n",
      "\n",
      "avg / total       0.86      1.00      0.93       254\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 10,  21,  25,  46,  52,  59,  69,  72,  78, 124, 145, 160, 174,\n",
      "       201, 204, 210, 229, 232, 250, 262, 277], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 46,  52,  59,  69,  78, 201, 208, 229, 232, 250, 277], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85371482368807683, 0.83672097005634871, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834172157634\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0996062992126\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   6]\n",
      " [ 32   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       254\n",
      "          1       0.57      0.20      0.30        40\n",
      "\n",
      "avg / total       0.84      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 10,  21,  25,  46,  52,  59,  69,  72,  78, 124, 145, 160, 174,\n",
      "       201, 204, 210, 229, 232, 250, 262, 277], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 46,  52,  59,  69,  78, 201, 208, 229, 232, 250, 277], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87074829931972786, 'RandomForest', (array([  7,  21,  25,  46,  59,  72,  78, 126, 145, 165, 178, 201, 250, 293], dtype=int64),)]]\n",
      "[0.85371482368807683, 0.83672097005634871, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443, 0.83417215763393526]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851187659487\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0127952755906\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   5]\n",
      " [ 30  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       254\n",
      "          1       0.67      0.25      0.36        40\n",
      "\n",
      "avg / total       0.86      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.90136054421768708, 'LogisticRegression', (array([ 10,  21,  25,  46,  52,  59,  69,  72,  78, 124, 145, 160, 174,\n",
      "       201, 204, 210, 229, 232, 250, 262, 277], dtype=int64),)], [0.88775510204081631, 'SelectKBest+LR', (array([ 46,  52,  59,  69,  78, 201, 208, 229, 232, 250, 277], dtype=int64),)], [0.86394557823129248, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86394557823129248, 'KNN', (array([], dtype=int64),)], [0.86394557823129248, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87074829931972786, 'RandomForest', (array([  7,  21,  25,  46,  59,  72,  78, 126, 145, 165, 178, 201, 250, 293], dtype=int64),)], [0.88095238095238093, 'XGBoost', (array([ 21,  46,  52,  59,  72,  78, 123, 126, 145, 159, 241, 246, 250,\n",
      "       286, 293], dtype=int64),)]]\n",
      "[0.85371482368807683, 0.83672097005634871, 0.83248443751878443, 0.83248443751878443, 0.83248443751878443, 0.83417215763393526, 0.85118765948685038]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861394557823\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00294511378849\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 35  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       249\n",
      "          1       0.77      0.22      0.34        45\n",
      "\n",
      "avg / total       0.86      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 20,  23,  60,  73,  80, 121, 123, 124, 163, 223, 262, 274, 286], dtype=int64),)]]\n",
      "[0.86139455782312924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854591836735\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.102008032129\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 39   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       249\n",
      "          1       0.67      0.13      0.22        45\n",
      "\n",
      "avg / total       0.83      0.86      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 20,  23,  60,  73,  80, 121, 123, 124, 163, 223, 262, 274, 286], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 55,  60,  73, 123, 124, 163, 215, 231, 286], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85459183673469374]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 20,  23,  60,  73,  80, 121, 123, 124, 163, 223, 262, 274, 286], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 55,  60,  73, 123, 124, 163, 215, 231, 286], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85459183673469374, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 20,  23,  60,  73,  80, 121, 123, 124, 163, 223, 262, 274, 286], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 55,  60,  73, 123, 124, 163, 215, 231, 286], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85459183673469374, 0.83673469387755117, 0.83673469387755117]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 20,  23,  60,  73,  80, 121, 123, 124, 163, 223, 262, 274, 286], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 55,  60,  73, 123, 124, 163, 215, 231, 286], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85459183673469374, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0232931726908\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 36   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       249\n",
      "          1       0.75      0.20      0.32        45\n",
      "\n",
      "avg / total       0.85      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 20,  23,  60,  73,  80, 121, 123, 124, 163, 223, 262, 274, 286], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 55,  60,  73, 123, 124, 163, 215, 231, 286], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86734693877551017, 'RandomForest', (array([ 55,  94, 121, 124, 147, 161, 163, 197, 200, 210, 274, 286], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85459183673469374, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83418367346938782]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858843537415\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.160374832664\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 29  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       249\n",
      "          1       0.84      0.36      0.50        45\n",
      "\n",
      "avg / total       0.89      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87074829931972786, 'LogisticRegression', (array([ 20,  23,  60,  73,  80, 121, 123, 124, 163, 223, 262, 274, 286], dtype=int64),)], [0.8571428571428571, 'SelectKBest+LR', (array([ 55,  60,  73, 123, 124, 163, 215, 231, 286], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86734693877551017, 'RandomForest', (array([ 55,  94, 121, 124, 147, 161, 163, 197, 200, 210, 274, 286], dtype=int64),)], [0.891156462585034, 'XGBoost', (array([ 20,  22,  28,  31,  36,  55, 112, 124, 163, 171, 174, 188, 200,\n",
      "       204, 210, 215, 262, 269, 286], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.85459183673469374, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83418367346938782, 0.85884353741496611]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854591836735\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0555555555556\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241  11]\n",
      " [ 23  19]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93       252\n",
      "          1       0.63      0.45      0.53        42\n",
      "\n",
      "avg / total       0.87      0.88      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 19,  30,  39,  43,  46,  58,  66,  69,  73,  85,  87, 109, 121,\n",
      "       123, 125, 127, 137, 141, 149, 156, 174, 189, 194, 213, 225, 242,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       245, 250, 265, 292], dtype=int64),)]]\n",
      "[0.85459183673469374]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.84268707483\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.111111111111\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   5]\n",
      " [ 27  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       252\n",
      "          1       0.75      0.36      0.48        42\n",
      "\n",
      "avg / total       0.88      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 19,  30,  39,  43,  46,  58,  66,  69,  73,  85,  87, 109, 121,\n",
      "       123, 125, 127, 137, 141, 149, 156, 174, 189, 194, 213, 225, 242,\n",
      "       245, 250, 265, 292], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  30,  39,  58,  85,  87,  88, 106, 109, 121, 127, 141, 149,\n",
      "       174, 189, 194, 216, 242, 245, 250], dtype=int64),)]]\n",
      "[0.85459183673469374, 0.8426870748299321]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 19,  30,  39,  43,  46,  58,  66,  69,  73,  85,  87, 109, 121,\n",
      "       123, 125, 127, 137, 141, 149, 156, 174, 189, 194, 213, 225, 242,\n",
      "       245, 250, 265, 292], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  30,  39,  58,  85,  87,  88, 106, 109, 121, 127, 141, 149,\n",
      "       174, 189, 194, 216, 242, 245, 250], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85459183673469374, 0.8426870748299321, 0.83418367346938771]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 19,  30,  39,  43,  46,  58,  66,  69,  73,  85,  87, 109, 121,\n",
      "       123, 125, 127, 137, 141, 149, 156, 174, 189, 194, 213, 225, 242,\n",
      "       245, 250, 265, 292], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  30,  39,  58,  85,  87,  88, 106, 109, 121, 127, 141, 149,\n",
      "       174, 189, 194, 216, 242, 245, 250], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85459183673469374, 0.8426870748299321, 0.83418367346938771, 0.83418367346938771]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 19,  30,  39,  43,  46,  58,  66,  69,  73,  85,  87, 109, 121,\n",
      "       123, 125, 127, 137, 141, 149, 156, 174, 189, 194, 213, 225, 242,\n",
      "       245, 250, 265, 292], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  30,  39,  58,  85,  87,  88, 106, 109, 121, 127, 141, 149,\n",
      "       174, 189, 194, 216, 242, 245, 250], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85459183673469374, 0.8426870748299321, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.361111111111\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236  16]\n",
      " [ 33   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91       252\n",
      "          1       0.36      0.21      0.27        42\n",
      "\n",
      "avg / total       0.80      0.83      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 19,  30,  39,  43,  46,  58,  66,  69,  73,  85,  87, 109, 121,\n",
      "       123, 125, 127, 137, 141, 149, 156, 174, 189, 194, 213, 225, 242,\n",
      "       245, 250, 265, 292], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  30,  39,  58,  85,  87,  88, 106, 109, 121, 127, 141, 149,\n",
      "       174, 189, 194, 216, 242, 245, 250], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83333333333333337, 'RandomForest', (array([  5,  31,  58,  87,  88,  98, 109, 118, 121, 125, 127, 144, 147,\n",
      "       149, 167, 194, 201, 204, 231, 242, 246, 258, 259, 260, 276], dtype=int64),)]]\n",
      "[0.85459183673469374, 0.8426870748299321, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.84353741496598644]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856292517007\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.111111111111\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   7]\n",
      " [ 25  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       252\n",
      "          1       0.71      0.40      0.52        42\n",
      "\n",
      "avg / total       0.88      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 19,  30,  39,  43,  46,  58,  66,  69,  73,  85,  87, 109, 121,\n",
      "       123, 125, 127, 137, 141, 149, 156, 174, 189, 194, 213, 225, 242,\n",
      "       245, 250, 265, 292], dtype=int64),)], [0.891156462585034, 'SelectKBest+LR', (array([ 19,  30,  39,  58,  85,  87,  88, 106, 109, 121, 127, 141, 149,\n",
      "       174, 189, 194, 216, 242, 245, 250], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83333333333333337, 'RandomForest', (array([  5,  31,  58,  87,  88,  98, 109, 118, 121, 125, 127, 144, 147,\n",
      "       149, 167, 194, 201, 204, 231, 242, 246, 258, 259, 260, 276], dtype=int64),)], [0.891156462585034, 'XGBoost', (array([ 30,  33,  39,  43,  58,  87,  94,  96, 109, 116, 118, 121, 123,\n",
      "       125, 127, 137, 141, 181, 189, 194, 242, 245, 260, 265], dtype=int64),)]]\n",
      "[0.85459183673469374, 0.8426870748299321, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.84353741496598644, 0.85629251700680264]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858849419843\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.118295930011\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   6]\n",
      " [ 44  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       239\n",
      "          1       0.65      0.20      0.31        55\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  8,  21,  28,  77,  91,  92,  98, 103, 104, 105, 168, 180, 193,\n",
      "       243, 248, 270, 289], dtype=int64),)]]\n",
      "[0.85884941984316676]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863934106666\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.118295930011\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[236   3]\n",
      " [ 47   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       239\n",
      "          1       0.73      0.15      0.24        55\n",
      "\n",
      "avg / total       0.81      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  8,  21,  28,  77,  91,  92,  98, 103, 104, 105, 168, 180, 193,\n",
      "       243, 248, 270, 289], dtype=int64),)], [0.82993197278911568, 'SelectKBest+LR', (array([ 21,  28,  45,  77,  92, 105, 168, 232, 243, 262, 289], dtype=int64),)]]\n",
      "[0.85884941984316676, 0.86393410666623094]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  8,  21,  28,  77,  91,  92,  98, 103, 104, 105, 168, 180, 193,\n",
      "       243, 248, 270, 289], dtype=int64),)], [0.82993197278911568, 'SelectKBest+LR', (array([ 21,  28,  45,  77,  92, 105, 168, 232, 243, 262, 289], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85884941984316676, 0.86393410666623094, 0.8452395948975896]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  8,  21,  28,  77,  91,  92,  98, 103, 104, 105, 168, 180, 193,\n",
      "       243, 248, 270, 289], dtype=int64),)], [0.82993197278911568, 'SelectKBest+LR', (array([ 21,  28,  45,  77,  92, 105, 168, 232, 243, 262, 289], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85884941984316676, 0.86393410666623094, 0.8452395948975896, 0.8452395948975896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  8,  21,  28,  77,  91,  92,  98, 103, 104, 105, 168, 180, 193,\n",
      "       243, 248, 270, 289], dtype=int64),)], [0.82993197278911568, 'SelectKBest+LR', (array([ 21,  28,  45,  77,  92, 105, 168, 232, 243, 262, 289], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85884941984316676, 0.86393410666623094, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854606385092\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.140661848612\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   5]\n",
      " [ 46   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       239\n",
      "          1       0.64      0.16      0.26        55\n",
      "\n",
      "avg / total       0.80      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  8,  21,  28,  77,  91,  92,  98, 103, 104, 105, 168, 180, 193,\n",
      "       243, 248, 270, 289], dtype=int64),)], [0.82993197278911568, 'SelectKBest+LR', (array([ 21,  28,  45,  77,  92, 105, 168, 232, 243, 262, 289], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([ 20,  32,  45,  86,  97, 103, 105, 106, 130, 168, 184, 218, 232, 289], dtype=int64),)]]\n",
      "[0.85884941984316676, 0.86393410666623094, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896, 0.8546063850919281]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.868214024187\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.118295930011\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   7]\n",
      " [ 43  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       239\n",
      "          1       0.63      0.22      0.32        55\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  8,  21,  28,  77,  91,  92,  98, 103, 104, 105, 168, 180, 193,\n",
      "       243, 248, 270, 289], dtype=int64),)], [0.82993197278911568, 'SelectKBest+LR', (array([ 21,  28,  45,  77,  92, 105, 168, 232, 243, 262, 289], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([ 20,  32,  45,  86,  97, 103, 105, 106, 130, 168, 184, 218, 232, 289], dtype=int64),)], [0.82993197278911568, 'XGBoost', (array([  0,   8,   9,  28,  45,  76,  77,  91, 103, 105, 143, 165, 168,\n",
      "       180, 232, 243, 262, 289, 290], dtype=int64),)]]\n",
      "[0.85884941984316676, 0.86393410666623094, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896, 0.8546063850919281, 0.86821402418695104]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.8758693266\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.139633043328\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237  10]\n",
      " [ 35  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       247\n",
      "          1       0.55      0.26      0.35        47\n",
      "\n",
      "avg / total       0.82      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  46,  47,  49,  58,  68,  69,  79,  90,  97, 126, 131, 135,\n",
      "       146, 156, 198, 229, 266, 272, 284, 289, 292], dtype=int64),)]]\n",
      "[0.87586932659998384]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863971000503\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.291584115772\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237  10]\n",
      " [ 41   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       247\n",
      "          1       0.38      0.13      0.19        47\n",
      "\n",
      "avg / total       0.78      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  46,  47,  49,  58,  68,  69,  79,  90,  97, 126, 131, 135,\n",
      "       146, 156, 198, 229, 266, 272, 284, 289, 292], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 46,  47,  49,  68,  69, 101, 106, 131, 133, 136, 146, 156, 229,\n",
      "       272, 284, 292], dtype=int64),)]]\n",
      "[0.87586932659998384, 0.86397100050330999]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  46,  47,  49,  58,  68,  69,  79,  90,  97, 126, 131, 135,\n",
      "       146, 156, 198, 229, 266, 272, 284, 289, 292], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 46,  47,  49,  68,  69, 101, 106, 131, 133, 136, 146, 156, 229,\n",
      "       272, 284, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87586932659998384, 0.86397100050330999, 0.83843684060636081]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  46,  47,  49,  58,  68,  69,  79,  90,  97, 126, 131, 135,\n",
      "       146, 156, 198, 229, 266, 272, 284, 289, 292], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 46,  47,  49,  68,  69, 101, 106, 131, 133, 136, 146, 156, 229,\n",
      "       272, 284, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87586932659998384, 0.86397100050330999, 0.83843684060636081, 0.83843684060636081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  46,  47,  49,  58,  68,  69,  79,  90,  97, 126, 131, 135,\n",
      "       146, 156, 198, 229, 266, 272, 284, 289, 292], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 46,  47,  49,  68,  69, 101, 106, 131, 133, 136, 146, 156, 229,\n",
      "       272, 284, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87586932659998384, 0.86397100050330999, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851192031188\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.266258937032\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235  12]\n",
      " [ 38   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.95      0.90       247\n",
      "          1       0.43      0.19      0.26        47\n",
      "\n",
      "avg / total       0.79      0.83      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  46,  47,  49,  58,  68,  69,  79,  90,  97, 126, 131, 135,\n",
      "       146, 156, 198, 229, 266, 272, 284, 289, 292], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 46,  47,  49,  68,  69, 101, 106, 131, 133, 136, 146, 156, 229,\n",
      "       272, 284, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([ 10,  14,  46,  49,  68,  79,  82,  97, 126, 147, 150, 153, 169,\n",
      "       197, 198, 212, 215, 229, 251, 289, 292], dtype=int64),)]]\n",
      "[0.87586932659998384, 0.86397100050330999, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081, 0.85119203118795916]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.880112350284\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0636575071066\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   8]\n",
      " [ 34  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       247\n",
      "          1       0.62      0.28      0.38        47\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  46,  47,  49,  58,  68,  69,  79,  90,  97, 126, 131, 135,\n",
      "       146, 156, 198, 229, 266, 272, 284, 289, 292], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([ 46,  47,  49,  68,  69, 101, 106, 131, 133, 136, 146, 156, 229,\n",
      "       272, 284, 292], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([ 10,  14,  46,  49,  68,  79,  82,  97, 126, 147, 150, 153, 169,\n",
      "       197, 198, 212, 215, 229, 251, 289, 292], dtype=int64),)], [0.8571428571428571, 'XGBoost', (array([ 14,  25,  32,  46,  49,  69,  72,  75,  90,  97, 131, 146, 147,\n",
      "       150, 169, 229, 251, 283, 284, 289, 292], dtype=int64),)]]\n",
      "[0.87586932659998384, 0.86397100050330999, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081, 0.85119203118795916, 0.88011235028362489]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.864777966724\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0690909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   7]\n",
      " [ 33  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       250\n",
      "          1       0.61      0.25      0.35        44\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  0,  18,  19,  31,  69,  86, 101, 103, 105, 124, 130, 133, 177,\n",
      "       212, 218, 254, 259, 284], dtype=int64),)]]\n",
      "[0.86477796672380647]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856289711371\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0958181818182\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   7]\n",
      " [ 34  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       250\n",
      "          1       0.59      0.23      0.33        44\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  0,  18,  19,  31,  69,  86, 101, 103, 105, 124, 130, 133, 177,\n",
      "       212, 218, 254, 259, 284], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  0,  19,  31,  69,  79,  86, 101, 103, 105, 130, 133, 177, 186,\n",
      "       200, 226, 250, 281], dtype=int64),)]]\n",
      "[0.86477796672380647, 0.85628971137077459]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  0,  18,  19,  31,  69,  86, 101, 103, 105, 124, 130, 133, 177,\n",
      "       212, 218, 254, 259, 284], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  0,  19,  31,  69,  79,  86, 101, 103, 105, 130, 133, 177, 186,\n",
      "       200, 226, 250, 281], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86477796672380647, 0.85628971137077459, 0.83588580913059995]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  0,  18,  19,  31,  69,  86, 101, 103, 105, 124, 130, 133, 177,\n",
      "       212, 218, 254, 259, 284], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  0,  19,  31,  69,  79,  86, 101, 103, 105, 130, 133, 177, 186,\n",
      "       200, 226, 250, 281], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86477796672380647, 0.85628971137077459, 0.83588580913059995, 0.83588580913059995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  0,  18,  19,  31,  69,  86, 101, 103, 105, 124, 130, 133, 177,\n",
      "       212, 218, 254, 259, 284], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  0,  19,  31,  69,  79,  86, 101, 103, 105, 130, 133, 177, 186,\n",
      "       200, 226, 250, 281], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86477796672380647, 0.85628971137077459, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839274109909\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.389818181818\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235  15]\n",
      " [ 37   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.94      0.90       250\n",
      "          1       0.32      0.16      0.21        44\n",
      "\n",
      "avg / total       0.78      0.82      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  0,  18,  19,  31,  69,  86, 101, 103, 105, 124, 130, 133, 177,\n",
      "       212, 218, 254, 259, 284], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  0,  19,  31,  69,  79,  86, 101, 103, 105, 130, 133, 177, 186,\n",
      "       200, 226, 250, 281], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8231292517006803, 'RandomForest', (array([  0,  10,  31,  37,  69,  79,  84,  85,  86,  97, 103, 105, 124,\n",
      "       130, 185, 198, 200, 226, 234, 259, 264, 291], dtype=int64),)]]\n",
      "[0.86477796672380647, 0.85628971137077459, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.83927410990947982]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860504529282\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0110909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   7]\n",
      " [ 30  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       250\n",
      "          1       0.67      0.32      0.43        44\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  0,  18,  19,  31,  69,  86, 101, 103, 105, 124, 130, 133, 177,\n",
      "       212, 218, 254, 259, 284], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([  0,  19,  31,  69,  79,  86, 101, 103, 105, 130, 133, 177, 186,\n",
      "       200, 226, 250, 281], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8231292517006803, 'RandomForest', (array([  0,  10,  31,  37,  69,  79,  84,  85,  86,  97, 103, 105, 124,\n",
      "       130, 185, 198, 200, 226, 234, 259, 264, 291], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([ 10,  31,  33,  65,  69,  79,  86, 103, 105, 121, 130, 133, 157,\n",
      "       174, 198, 200, 218, 233, 259, 261, 264], dtype=int64),)]]\n",
      "[0.86477796672380647, 0.85628971137077459, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.83927410990947982, 0.86050452928156551]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.870758619855\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.137690846408\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[228   5]\n",
      " [ 50  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89       233\n",
      "          1       0.69      0.18      0.29        61\n",
      "\n",
      "avg / total       0.79      0.81      0.77       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81292517006802723, 'LogisticRegression', (array([  8,  23,  35, 109, 111, 119, 124, 125, 139, 155, 181, 204, 224,\n",
      "       231, 243, 262], dtype=int64),)]]\n",
      "[0.87075861985462399]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.809523809524\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.86056097403\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.190476190476\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.158376134525\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[227   6]\n",
      " [ 50  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.97      0.89       233\n",
      "          1       0.65      0.18      0.28        61\n",
      "\n",
      "avg / total       0.78      0.81      0.76       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81292517006802723, 'LogisticRegression', (array([  8,  23,  35, 109, 111, 119, 124, 125, 139, 155, 181, 204, 224,\n",
      "       231, 243, 262], dtype=int64),)], [0.80952380952380953, 'SelectKBest+LR', (array([  1,   8,  23,  33,  35,  94, 109, 111, 124, 130, 148, 181, 189,\n",
      "       225, 231, 243, 262], dtype=int64),)]]\n",
      "[0.87075861985462399, 0.86056097403005893]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.792517006803\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.850341657849\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.207482993197\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.261802575107\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   0]\n",
      " [ 61   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       233\n",
      "\n",
      "avg / total       0.79      1.00      0.88       233\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81292517006802723, 'LogisticRegression', (array([  8,  23,  35, 109, 111, 119, 124, 125, 139, 155, 181, 204, 224,\n",
      "       231, 243, 262], dtype=int64),)], [0.80952380952380953, 'SelectKBest+LR', (array([  1,   8,  23,  33,  35,  94, 109, 111, 124, 130, 148, 181, 189,\n",
      "       225, 231, 243, 262], dtype=int64),)], [0.79251700680272108, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87075861985462399, 0.86056097403005893, 0.85034165784911153]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.792517006803\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.850341657849\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.207482993197\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.261802575107\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   0]\n",
      " [ 61   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       233\n",
      "\n",
      "avg / total       0.79      1.00      0.88       233\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81292517006802723, 'LogisticRegression', (array([  8,  23,  35, 109, 111, 119, 124, 125, 139, 155, 181, 204, 224,\n",
      "       231, 243, 262], dtype=int64),)], [0.80952380952380953, 'SelectKBest+LR', (array([  1,   8,  23,  33,  35,  94, 109, 111, 124, 130, 148, 181, 189,\n",
      "       225, 231, 243, 262], dtype=int64),)], [0.79251700680272108, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79251700680272108, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87075861985462399, 0.86056097403005893, 0.85034165784911153, 0.85034165784911153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.792517006803\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.850341657849\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.207482993197\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.261802575107\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   0]\n",
      " [ 61   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       233\n",
      "\n",
      "avg / total       0.79      1.00      0.88       233\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81292517006802723, 'LogisticRegression', (array([  8,  23,  35, 109, 111, 119, 124, 125, 139, 155, 181, 204, 224,\n",
      "       231, 243, 262], dtype=int64),)], [0.80952380952380953, 'SelectKBest+LR', (array([  1,   8,  23,  33,  35,  94, 109, 111, 124, 130, 148, 181, 189,\n",
      "       225, 231, 243, 262], dtype=int64),)], [0.79251700680272108, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79251700680272108, 'KNN', (array([], dtype=int64),)], [0.79251700680272108, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87075861985462399, 0.86056097403005893, 0.85034165784911153, 0.85034165784911153, 0.85034165784911153]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.795918367347\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835026791998\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.204081632653\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.241117286991\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[226   7]\n",
      " [ 53   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.97      0.88       233\n",
      "          1       0.53      0.13      0.21        61\n",
      "\n",
      "avg / total       0.75      0.80      0.74       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81292517006802723, 'LogisticRegression', (array([  8,  23,  35, 109, 111, 119, 124, 125, 139, 155, 181, 204, 224,\n",
      "       231, 243, 262], dtype=int64),)], [0.80952380952380953, 'SelectKBest+LR', (array([  1,   8,  23,  33,  35,  94, 109, 111, 124, 130, 148, 181, 189,\n",
      "       225, 231, 243, 262], dtype=int64),)], [0.79251700680272108, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79251700680272108, 'KNN', (array([], dtype=int64),)], [0.79251700680272108, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.79591836734693877, 'RandomForest', (array([ 27,  35,  42,  71,  97, 102, 129, 130, 134, 137, 146, 165, 181,\n",
      "       214, 231], dtype=int64),)]]\n",
      "[0.87075861985462399, 0.86056097403005893, 0.85034165784911153, 0.85034165784911153, 0.85034165784911153, 0.8350267919979143]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.871608893585\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0549496939422\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[229   4]\n",
      " [ 47  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90       233\n",
      "          1       0.78      0.23      0.35        61\n",
      "\n",
      "avg / total       0.82      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.81292517006802723, 'LogisticRegression', (array([  8,  23,  35, 109, 111, 119, 124, 125, 139, 155, 181, 204, 224,\n",
      "       231, 243, 262], dtype=int64),)], [0.80952380952380953, 'SelectKBest+LR', (array([  1,   8,  23,  33,  35,  94, 109, 111, 124, 130, 148, 181, 189,\n",
      "       225, 231, 243, 262], dtype=int64),)], [0.79251700680272108, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.79251700680272108, 'KNN', (array([], dtype=int64),)], [0.79251700680272108, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.79591836734693877, 'RandomForest', (array([ 27,  35,  42,  71,  97, 102, 129, 130, 134, 137, 146, 165, 181,\n",
      "       214, 231], dtype=int64),)], [0.82653061224489799, 'XGBoost', (array([  8,  21,  23,  27,  97, 102, 111, 118, 130, 137, 139, 148, 172,\n",
      "       181, 204, 208, 231, 243], dtype=int64),)]]\n",
      "[0.87075861985462399, 0.86056097403005893, 0.85034165784911153, 0.85034165784911153, 0.85034165784911153, 0.8350267919979143, 0.87160889358509186]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.864804030916\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.027972027972\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   5]\n",
      " [ 39  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       242\n",
      "          1       0.72      0.25      0.37        52\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  4,   7,  40,  44,  69,  71,  79,  86,  89,  92,  97, 125, 140,\n",
      "       207, 228, 233, 243, 287], dtype=int64),)]]\n",
      "[0.86480403091649316]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.850365502988\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.144787031151\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   2]\n",
      " [ 47   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91       242\n",
      "          1       0.71      0.10      0.17        52\n",
      "\n",
      "avg / total       0.81      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  4,   7,  40,  44,  69,  71,  79,  86,  89,  92,  97, 125, 140,\n",
      "       207, 228, 233, 243, 287], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 71,  86,  97, 228, 233, 255, 287], dtype=int64),)]]\n",
      "[0.86480403091649316, 0.85036550298845059]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  4,   7,  40,  44,  69,  71,  79,  86,  89,  92,  97, 125, 140,\n",
      "       207, 228, 233, 243, 287], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 71,  86,  97, 228, 233, 255, 287], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86480403091649316, 0.85036550298845059, 0.84268856342182852]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  4,   7,  40,  44,  69,  71,  79,  86,  89,  92,  97, 125, 140,\n",
      "       207, 228, 233, 243, 287], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 71,  86,  97, 228, 233, 255, 287], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86480403091649316, 0.85036550298845059, 0.84268856342182852, 0.84268856342182852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.842688563422\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.214876033058\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   0]\n",
      " [ 52   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       242\n",
      "\n",
      "avg / total       0.82      1.00      0.90       242\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  4,   7,  40,  44,  69,  71,  79,  86,  89,  92,  97, 125, 140,\n",
      "       207, 228, 233, 243, 287], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 71,  86,  97, 228, 233, 255, 287], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86480403091649316, 0.85036550298845059, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.8350137433\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.284965034965\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   8]\n",
      " [ 47   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.89       242\n",
      "          1       0.38      0.10      0.15        52\n",
      "\n",
      "avg / total       0.75      0.81      0.76       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  4,   7,  40,  44,  69,  71,  79,  86,  89,  92,  97, 125, 140,\n",
      "       207, 228, 233, 243, 287], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 71,  86,  97, 228, 233, 255, 287], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81292517006802723, 'RandomForest', (array([ 29,  43,  44,  69,  71,  92,  97, 100, 153, 183, 189, 200, 212], dtype=int64),)]]\n",
      "[0.86480403091649316, 0.85036550298845059, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.8350137433001743]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861404811952\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0654799745709\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   4]\n",
      " [ 36  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       242\n",
      "          1       0.80      0.31      0.44        52\n",
      "\n",
      "avg / total       0.86      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([  4,   7,  40,  44,  69,  71,  79,  86,  89,  92,  97, 125, 140,\n",
      "       207, 228, 233, 243, 287], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 71,  86,  97, 228, 233, 255, 287], dtype=int64),)], [0.8231292517006803, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8231292517006803, 'KNN', (array([], dtype=int64),)], [0.8231292517006803, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81292517006802723, 'RandomForest', (array([ 29,  43,  44,  69,  71,  92,  97, 100, 153, 183, 189, 200, 212], dtype=int64),)], [0.86394557823129248, 'XGBoost', (array([  4,  29,  43,  44,  53,  69,  71,  79,  86,  89,  92,  97, 125,\n",
      "       127, 173, 177, 197, 280, 287, 293], dtype=int64),)]]\n",
      "[0.86480403091649316, 0.85036550298845059, 0.84268856342182852, 0.84268856342182852, 0.84268856342182852, 0.8350137433001743, 0.8614048119524389]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854591836735\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0833333333333\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   1]\n",
      " [ 32  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       252\n",
      "          1       0.91      0.24      0.38        42\n",
      "\n",
      "avg / total       0.89      0.89      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 15,  60,  62,  66,  98, 126, 188, 234, 242, 278, 290], dtype=int64),)]]\n",
      "[0.85459183673469397]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848639455782\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 2.22044604925e-16\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   2]\n",
      " [ 34   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       252\n",
      "          1       0.80      0.19      0.31        42\n",
      "\n",
      "avg / total       0.87      0.88      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 15,  60,  62,  66,  98, 126, 188, 234, 242, 278, 290], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  0,  15,  24,  60,  62,  85,  98, 126, 188, 234], dtype=int64),)]]\n",
      "[0.85459183673469397, 0.84863945578231303]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 15,  60,  62,  66,  98, 126, 188, 234, 242, 278, 290], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  0,  15,  24,  60,  62,  85,  98, 126, 188, 234], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85459183673469397, 0.84863945578231303, 0.83418367346938771]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 15,  60,  62,  66,  98, 126, 188, 234, 242, 278, 290], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  0,  15,  24,  60,  62,  85,  98, 126, 188, 234], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85459183673469397, 0.84863945578231303, 0.83418367346938771, 0.83418367346938771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.166666666667\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   0]\n",
      " [ 42   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       252\n",
      "\n",
      "avg / total       0.86      1.00      0.92       252\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 15,  60,  62,  66,  98, 126, 188, 234, 242, 278, 290], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  0,  15,  24,  60,  62,  85,  98, 126, 188, 234], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85459183673469397, 0.84863945578231303, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.834183673469\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.111111111111\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   6]\n",
      " [ 34   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.92       252\n",
      "          1       0.57      0.19      0.29        42\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 15,  60,  62,  66,  98, 126, 188, 234, 242, 278, 290], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  0,  15,  24,  60,  62,  85,  98, 126, 188, 234], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 60,  98, 104, 126, 150, 172, 183, 191, 234, 242, 251, 262, 267, 285], dtype=int64),)]]\n",
      "[0.85459183673469397, 0.84863945578231303, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846088435374\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0833333333333\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   4]\n",
      " [ 29  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       252\n",
      "          1       0.76      0.31      0.44        42\n",
      "\n",
      "avg / total       0.88      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88775510204081631, 'LogisticRegression', (array([ 15,  60,  62,  66,  98, 126, 188, 234, 242, 278, 290], dtype=int64),)], [0.87755102040816324, 'SelectKBest+LR', (array([  0,  15,  24,  60,  62,  85,  98, 126, 188, 234], dtype=int64),)], [0.8571428571428571, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.8571428571428571, 'KNN', (array([], dtype=int64),)], [0.8571428571428571, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 60,  98, 104, 126, 150, 172, 183, 191, 234, 242, 251, 262, 267, 285], dtype=int64),)], [0.88775510204081631, 'XGBoost', (array([ 15,  60,  62,  84,  85,  91,  98, 107, 126, 150, 170, 183, 188,\n",
      "       191, 209, 234, 262], dtype=int64),)]]\n",
      "[0.85459183673469397, 0.84863945578231303, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.83418367346938771, 0.84608843537414968]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865632656426\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0882935653372\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   9]\n",
      " [ 27  20]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       247\n",
      "          1       0.69      0.43      0.53        47\n",
      "\n",
      "avg / total       0.86      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  3,   8,  12,  17,  30,  41,  67,  91,  95, 111, 120, 123, 141,\n",
      "       142, 148, 159, 161, 171, 177, 180, 193, 222, 235, 245, 263, 270,\n",
      "       273, 279, 281], dtype=int64),)]]\n",
      "[0.86563265642577425]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.84694027517\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0130071496253\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   2]\n",
      " [ 38   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       247\n",
      "          1       0.82      0.19      0.31        47\n",
      "\n",
      "avg / total       0.86      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  3,   8,  12,  17,  30,  41,  67,  91,  95, 111, 120, 123, 141,\n",
      "       142, 148, 159, 161, 171, 177, 180, 193, 222, 235, 245, 263, 270,\n",
      "       273, 279, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  3,  30,  41,  91, 111, 123, 161, 193, 222, 245, 281], dtype=int64),)]]\n",
      "[0.86563265642577425, 0.84694027516969828]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  3,   8,  12,  17,  30,  41,  67,  91,  95, 111, 120, 123, 141,\n",
      "       142, 148, 159, 161, 171, 177, 180, 193, 222, 235, 245, 263, 270,\n",
      "       273, 279, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  3,  30,  41,  91, 111, 123, 161, 193, 222, 245, 281], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86563265642577425, 0.84694027516969828, 0.83843684060636081]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  3,   8,  12,  17,  30,  41,  67,  91,  95, 111, 120, 123, 141,\n",
      "       142, 148, 159, 161, 171, 177, 180, 193, 222, 235, 245, 263, 270,\n",
      "       273, 279, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  3,  30,  41,  91, 111, 123, 161, 193, 222, 245, 281], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86563265642577425, 0.84694027516969828, 0.83843684060636081, 0.83843684060636081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.838436840606\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19028340081\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   0]\n",
      " [ 47   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       247\n",
      "\n",
      "avg / total       0.84      1.00      0.91       247\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  3,   8,  12,  17,  30,  41,  67,  91,  95, 111, 120, 123, 141,\n",
      "       142, 148, 159, 161, 171, 177, 180, 193, 222, 235, 245, 263, 270,\n",
      "       273, 279, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  3,  30,  41,  91, 111, 123, 161, 193, 222, 245, 281], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86563265642577425, 0.84694027516969828, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845220066121\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0629683865966\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   4]\n",
      " [ 33  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       247\n",
      "          1       0.78      0.30      0.43        47\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  3,   8,  12,  17,  30,  41,  67,  91,  95, 111, 120, 123, 141,\n",
      "       142, 148, 159, 161, 171, 177, 180, 193, 222, 235, 245, 263, 270,\n",
      "       273, 279, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  3,  30,  41,  91, 111, 123, 161, 193, 222, 245, 281], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([  3,  17,  30,  41,  67, 111, 121, 126, 151, 162, 171, 177, 193,\n",
      "       196, 248, 260, 272, 281], dtype=int64),)]]\n",
      "[0.86563265642577425, 0.84694027516969828, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081, 0.84522006612137057]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.864793168069\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0882935653372\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   4]\n",
      " [ 32  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       247\n",
      "          1       0.79      0.32      0.45        47\n",
      "\n",
      "avg / total       0.87      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([  3,   8,  12,  17,  30,  41,  67,  91,  95, 111, 120, 123, 141,\n",
      "       142, 148, 159, 161, 171, 177, 180, 193, 222, 235, 245, 263, 270,\n",
      "       273, 279, 281], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  3,  30,  41,  91, 111, 123, 161, 193, 222, 245, 281], dtype=int64),)], [0.84013605442176875, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84013605442176875, 'KNN', (array([], dtype=int64),)], [0.84013605442176875, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.87414965986394555, 'RandomForest', (array([  3,  17,  30,  41,  67, 111, 121, 126, 151, 162, 171, 177, 193,\n",
      "       196, 248, 260, 272, 281], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([ 12,  30,  37,  41,  91, 111, 123, 137, 139, 144, 162, 171, 193,\n",
      "       198, 222, 260, 270, 273, 281], dtype=int64),)]]\n",
      "[0.86563265642577425, 0.84694027516969828, 0.83843684060636081, 0.83843684060636081, 0.83843684060636081, 0.84522006612137057, 0.86479316806930762]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866496598639\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.134259259259\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   6]\n",
      " [ 44  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       240\n",
      "          1       0.62      0.19      0.29        54\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  7,  30,  32,  56,  63,  79, 101, 115, 126, 142, 197, 199, 225,\n",
      "       234, 245, 250], dtype=int64),)]]\n",
      "[0.86649659863945583]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.156944444444\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[231   9]\n",
      " [ 42  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.96      0.90       240\n",
      "          1       0.57      0.22      0.32        54\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  7,  30,  32,  56,  63,  79, 101, 115, 126, 142, 197, 199, 225,\n",
      "       234, 245, 250], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  3,   7,  30,  56,  63,  79,  90, 115, 126, 141, 142, 161, 197,\n",
      "       199, 207, 225, 245, 250, 260, 274, 291], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.86734693877551017]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  7,  30,  32,  56,  63,  79, 101, 115, 126, 142, 197, 199, 225,\n",
      "       234, 245, 250], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  3,   7,  30,  56,  63,  79,  90, 115, 126, 141, 142, 161, 197,\n",
      "       199, 207, 225, 245, 250, 260, 274, 291], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.86734693877551017, 0.84438775510204078]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  7,  30,  32,  56,  63,  79, 101, 115, 126, 142, 197, 199, 225,\n",
      "       234, 245, 250], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  3,   7,  30,  56,  63,  79,  90, 115, 126, 141, 142, 161, 197,\n",
      "       199, 207, 225, 245, 250, 260, 274, 291], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.86734693877551017, 0.84438775510204078, 0.84438775510204078]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  7,  30,  32,  56,  63,  79, 101, 115, 126, 142, 197, 199, 225,\n",
      "       234, 245, 250], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  3,   7,  30,  56,  63,  79,  90, 115, 126, 141, 142, 161, 197,\n",
      "       199, 207, 225, 245, 250, 260, 274, 291], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.86734693877551017, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.85119047619\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.156944444444\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   7]\n",
      " [ 44  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       240\n",
      "          1       0.59      0.19      0.28        54\n",
      "\n",
      "avg / total       0.79      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  7,  30,  32,  56,  63,  79, 101, 115, 126, 142, 197, 199, 225,\n",
      "       234, 245, 250], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  3,   7,  30,  56,  63,  79,  90, 115, 126, 141, 142, 161, 197,\n",
      "       199, 207, 225, 245, 250, 260, 274, 291], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([  3,   7,  30,  61,  63,  64, 141, 142, 146, 149, 152, 207, 217,\n",
      "       231, 234, 260, 291], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.86734693877551017, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.85119047619047628]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866496598639\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0435185185185\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   8]\n",
      " [ 38  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       240\n",
      "          1       0.67      0.30      0.41        54\n",
      "\n",
      "avg / total       0.82      0.84      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.82993197278911568, 'LogisticRegression', (array([  7,  30,  32,  56,  63,  79, 101, 115, 126, 142, 197, 199, 225,\n",
      "       234, 245, 250], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  3,   7,  30,  56,  63,  79,  90, 115, 126, 141, 142, 161, 197,\n",
      "       199, 207, 225, 245, 250, 260, 274, 291], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([  3,   7,  30,  61,  63,  64, 141, 142, 146, 149, 152, 207, 217,\n",
      "       231, 234, 260, 291], dtype=int64),)], [0.84353741496598644, 'XGBoost', (array([  7,  30,  32,  61,  63,  79,  95, 115, 126, 141, 142, 152, 161,\n",
      "       199, 207, 210, 217, 225, 234, 246, 250, 260, 284, 291], dtype=int64),)]]\n",
      "[0.86649659863945583, 0.86734693877551017, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.85119047619047628, 0.86649659863945583]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.866509005417\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0793079151335\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   9]\n",
      " [ 31  22]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92       241\n",
      "          1       0.71      0.42      0.52        53\n",
      "\n",
      "avg / total       0.85      0.86      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  4,  15,  29,  36,  37,  42,  61,  70,  80,  84,  86,  92, 114,\n",
      "       132, 134, 146, 151, 154, 172, 178, 193, 196, 214, 227, 229, 261,\n",
      "       263, 270, 281, 286, 290], dtype=int64),)]]\n",
      "[0.86650900541652653]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.868222745454\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.127847803961\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   2]\n",
      " [ 47   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91       241\n",
      "          1       0.75      0.11      0.20        53\n",
      "\n",
      "avg / total       0.82      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  4,  15,  29,  36,  37,  42,  61,  70,  80,  84,  86,  92, 114,\n",
      "       132, 134, 146, 151, 154, 172, 178, 193, 196, 214, 227, 229, 261,\n",
      "       263, 270, 281, 286, 290], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 82,  84,  86, 114, 132, 154, 172, 261], dtype=int64),)]]\n",
      "[0.86650900541652653, 0.86822274545397315]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  4,  15,  29,  36,  37,  42,  61,  70,  80,  84,  86,  92, 114,\n",
      "       132, 134, 146, 151, 154, 172, 178, 193, 196, 214, 227, 229, 261,\n",
      "       263, 270, 281, 286, 290], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 82,  84,  86, 114, 132, 154, 172, 261], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86650900541652653, 0.86822274545397315, 0.84353890355788297]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  4,  15,  29,  36,  37,  42,  61,  70,  80,  84,  86,  92, 114,\n",
      "       132, 134, 146, 151, 154, 172, 178, 193, 196, 214, 227, 229, 261,\n",
      "       263, 270, 281, 286, 290], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 82,  84,  86, 114, 132, 154, 172, 261], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86650900541652653, 0.86822274545397315, 0.84353890355788297, 0.84353890355788297]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.819727891156\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843538903558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.180272108844\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.219917012448\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   0]\n",
      " [ 53   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       241\n",
      "\n",
      "avg / total       0.82      1.00      0.90       241\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  4,  15,  29,  36,  37,  42,  61,  70,  80,  84,  86,  92, 114,\n",
      "       132, 134, 146, 151, 154, 172, 178, 193, 196, 214, 227, 229, 261,\n",
      "       263, 270, 281, 286, 290], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 82,  84,  86, 114, 132, 154, 172, 261], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86650900541652653, 0.86822274545397315, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845237420115\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.196899710326\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   9]\n",
      " [ 43  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.96      0.90       241\n",
      "          1       0.53      0.19      0.28        53\n",
      "\n",
      "avg / total       0.79      0.82      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  4,  15,  29,  36,  37,  42,  61,  70,  80,  84,  86,  92, 114,\n",
      "       132, 134, 146, 151, 154, 172, 178, 193, 196, 214, 227, 229, 261,\n",
      "       263, 270, 281, 286, 290], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 82,  84,  86, 114, 132, 154, 172, 261], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8231292517006803, 'RandomForest', (array([  3,  37,  42,  70,  84, 110, 132, 149, 150, 154, 176, 179, 190,\n",
      "       196, 202, 216, 222, 238, 252], dtype=int64),)]]\n",
      "[0.86650900541652653, 0.86822274545397315, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297, 0.84523742011463288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862257304736\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0332733108902\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   6]\n",
      " [ 36  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       241\n",
      "          1       0.74      0.32      0.45        53\n",
      "\n",
      "avg / total       0.84      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86394557823129248, 'LogisticRegression', (array([  4,  15,  29,  36,  37,  42,  61,  70,  80,  84,  86,  92, 114,\n",
      "       132, 134, 146, 151, 154, 172, 178, 193, 196, 214, 227, 229, 261,\n",
      "       263, 270, 281, 286, 290], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 82,  84,  86, 114, 132, 154, 172, 261], dtype=int64),)], [0.81972789115646261, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81972789115646261, 'KNN', (array([], dtype=int64),)], [0.81972789115646261, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8231292517006803, 'RandomForest', (array([  3,  37,  42,  70,  84, 110, 132, 149, 150, 154, 176, 179, 190,\n",
      "       196, 202, 216, 222, 238, 252], dtype=int64),)], [0.8571428571428571, 'XGBoost', (array([  1,   4,  15,  36,  42,  70,  84,  92,  99, 132, 134, 135, 146,\n",
      "       151, 154, 177, 196, 202, 212, 252, 263, 264, 270], dtype=int64),)]]\n",
      "[0.86650900541652653, 0.86822274545397315, 0.84353890355788297, 0.84353890355788297, 0.84353890355788297, 0.84523742011463288, 0.8622573047362545]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859688919267\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0980014025245\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   6]\n",
      " [ 29  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       248\n",
      "          1       0.74      0.37      0.49        46\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  2,  19,  57,  64,  83, 112, 116, 117, 122, 130, 133, 135, 139,\n",
      "       157, 161, 170, 179, 212, 214, 215, 243, 252, 264], dtype=int64),)]]\n",
      "[0.85968891926723112]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.84779930337\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00508415147265\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   6]\n",
      " [ 33  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       248\n",
      "          1       0.68      0.28      0.40        46\n",
      "\n",
      "avg / total       0.85      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  2,  19,  57,  64,  83, 112, 116, 117, 122, 130, 133, 135, 139,\n",
      "       157, 161, 170, 179, 212, 214, 215, 243, 252, 264], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  2,  14,  57,  64,  80, 112, 116, 122, 130, 135, 139, 157, 170,\n",
      "       179, 200, 212, 214, 215, 243], dtype=int64),)]]\n",
      "[0.85968891926723112, 0.84779930336998177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  2,  19,  57,  64,  83, 112, 116, 117, 122, 130, 133, 135, 139,\n",
      "       157, 161, 170, 179, 212, 214, 215, 243, 252, 264], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  2,  14,  57,  64,  80, 112, 116, 122, 130, 135, 139, 157, 170,\n",
      "       179, 200, 212, 214, 215, 243], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85968891926723112, 0.84779930336998177, 0.83758650047030658]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  2,  19,  57,  64,  83, 112, 116, 117, 122, 130, 133, 135, 139,\n",
      "       157, 161, 170, 179, 212, 214, 215, 243, 252, 264], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  2,  14,  57,  64,  80, 112, 116, 122, 130, 135, 139, 157, 170,\n",
      "       179, 200, 212, 214, 215, 243], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85968891926723112, 0.84779930336998177, 0.83758650047030658, 0.83758650047030658]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  2,  19,  57,  64,  83, 112, 116, 117, 122, 130, 133, 135, 139,\n",
      "       157, 161, 170, 179, 212, 214, 215, 243, 252, 264], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  2,  14,  57,  64,  80, 112, 116, 122, 130, 135, 139, 157, 170,\n",
      "       179, 200, 212, 214, 215, 243], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85968891926723112, 0.84779930336998177, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833362950225\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00508415147265\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   6]\n",
      " [ 33  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       248\n",
      "          1       0.68      0.28      0.40        46\n",
      "\n",
      "avg / total       0.85      0.87      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  2,  19,  57,  64,  83, 112, 116, 117, 122, 130, 133, 135, 139,\n",
      "       157, 161, 170, 179, 212, 214, 215, 243, 252, 264], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  2,  14,  57,  64,  80, 112, 116, 122, 130, 135, 139, 157, 170,\n",
      "       179, 200, 212, 214, 215, 243], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86734693877551017, 'RandomForest', (array([  1,   2,  19,  46,  57,  80,  97, 112, 122, 135, 139, 140, 157,\n",
      "       162, 167, 179, 200, 212, 254], dtype=int64),)]]\n",
      "[0.85968891926723112, 0.84779930336998177, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.83336295022489582]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.867381049112\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0206872370266\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   5]\n",
      " [ 33  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       248\n",
      "          1       0.72      0.28      0.41        46\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88095238095238093, 'LogisticRegression', (array([  2,  19,  57,  64,  83, 112, 116, 117, 122, 130, 133, 135, 139,\n",
      "       157, 161, 170, 179, 212, 214, 215, 243, 252, 264], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([  2,  14,  57,  64,  80, 112, 116, 122, 130, 135, 139, 157, 170,\n",
      "       179, 200, 212, 214, 215, 243], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86734693877551017, 'RandomForest', (array([  1,   2,  19,  46,  57,  80,  97, 112, 122, 135, 139, 140, 157,\n",
      "       162, 167, 179, 200, 212, 254], dtype=int64),)], [0.87074829931972786, 'XGBoost', (array([  2,  13,  14,  19,  21,  64,  83, 122, 130, 133, 141, 157, 162,\n",
      "       168, 176, 179, 212, 215], dtype=int64),)]]\n",
      "[0.85968891926723112, 0.84779930336998177, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.83336295022489582, 0.86738104911175673]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858842939765\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0378181818182\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   7]\n",
      " [ 29  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       250\n",
      "          1       0.68      0.34      0.45        44\n",
      "\n",
      "avg / total       0.86      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 26,  28,  30,  36,  52,  74,  77,  83,  85, 134, 141, 160, 172,\n",
      "       183, 204, 206, 223, 226, 229, 233, 260, 276], dtype=int64),)]]\n",
      "[0.85884293976468784]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846940297305\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0958181818182\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   2]\n",
      " [ 39   5]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       250\n",
      "          1       0.71      0.11      0.20        44\n",
      "\n",
      "avg / total       0.84      0.86      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 26,  28,  30,  36,  52,  74,  77,  83,  85, 134, 141, 160, 172,\n",
      "       183, 204, 206, 223, 226, 229, 233, 260, 276], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 26,  52,  74, 183, 204, 229, 276], dtype=int64),)]]\n",
      "[0.85884293976468784, 0.84694029730489395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 26,  28,  30,  36,  52,  74,  77,  83,  85, 134, 141, 160, 172,\n",
      "       183, 204, 206, 223, 226, 229, 233, 260, 276], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 26,  52,  74, 183, 204, 229, 276], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85884293976468784, 0.84694029730489395, 0.83588580913059995]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 26,  28,  30,  36,  52,  74,  77,  83,  85, 134, 141, 160, 172,\n",
      "       183, 204, 206, 223, 226, 229, 233, 260, 276], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 26,  52,  74, 183, 204, 229, 276], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85884293976468784, 0.84694029730489395, 0.83588580913059995, 0.83588580913059995]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.835885809131\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.176\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[250   0]\n",
      " [ 44   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       250\n",
      "\n",
      "avg / total       0.85      1.00      0.92       250\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 26,  28,  30,  36,  52,  74,  77,  83,  85, 134, 141, 160, 172,\n",
      "       183, 204, 206, 223, 226, 229, 233, 260, 276], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 26,  52,  74, 183, 204, 229, 276], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85884293976468784, 0.84694029730489395, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.830779385546\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.282909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235  15]\n",
      " [ 33  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91       250\n",
      "          1       0.42      0.25      0.31        44\n",
      "\n",
      "avg / total       0.81      0.84      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 26,  28,  30,  36,  52,  74,  77,  83,  85, 134, 141, 160, 172,\n",
      "       183, 204, 206, 223, 226, 229, 233, 260, 276], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 26,  52,  74, 183, 204, 229, 276], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([  9,  11,  28,  38,  52,  55,  58,  63,  65,  74,  90, 107, 141,\n",
      "       151, 174, 188, 193, 198, 226, 229, 233, 245, 268, 280, 289, 290], dtype=int64),)]]\n",
      "[0.85884293976468784, 0.84694029730489395, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.83077938554556674]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.901360544218\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860532790392\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.0986394557823\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.224909090909\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   3]\n",
      " [ 26  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94       250\n",
      "          1       0.86      0.41      0.55        44\n",
      "\n",
      "avg / total       0.90      0.90      0.89       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 26,  28,  30,  36,  52,  74,  77,  83,  85, 134, 141, 160, 172,\n",
      "       183, 204, 206, 223, 226, 229, 233, 260, 276], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 26,  52,  74, 183, 204, 229, 276], dtype=int64),)], [0.85034013605442171, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.85034013605442171, 'KNN', (array([], dtype=int64),)], [0.85034013605442171, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([  9,  11,  28,  38,  52,  55,  58,  63,  65,  74,  90, 107, 141,\n",
      "       151, 174, 188, 193, 198, 226, 229, 233, 245, 268, 280, 289, 290], dtype=int64),)], [0.90136054421768708, 'XGBoost', (array([ 28,  30,  36,  42,  65,  74,  77, 107, 141, 142, 183, 198, 209,\n",
      "       218, 223, 226, 229, 233, 245, 260, 276], dtype=int64),)]]\n",
      "[0.85884293976468784, 0.84694029730489395, 0.83588580913059995, 0.83588580913059995, 0.83588580913059995, 0.83077938554556674, 0.86053279039240438]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.878420324873\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0628476084538\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[226   6]\n",
      " [ 46  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.97      0.90       232\n",
      "          1       0.73      0.26      0.38        62\n",
      "\n",
      "avg / total       0.81      0.82      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8231292517006803, 'LogisticRegression', (array([  2,  14,  38, 107, 115, 131, 134, 151, 161, 167, 176, 180, 186,\n",
      "       192, 200, 203, 205, 217, 230, 243, 254, 265], dtype=int64),)]]\n",
      "[0.87842032487295174]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865639158639\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0424082313682\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[229   3]\n",
      " [ 48  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       232\n",
      "          1       0.82      0.23      0.35        62\n",
      "\n",
      "avg / total       0.83      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8231292517006803, 'LogisticRegression', (array([  2,  14,  38, 107, 115, 131, 134, 151, 161, 167, 176, 180, 186,\n",
      "       192, 200, 203, 205, 217, 230, 243, 254, 265], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  2,   8,  14,  27,  38, 107, 115, 151, 158, 161, 167, 176, 186,\n",
      "       192, 203, 205, 217], dtype=int64),)]]\n",
      "[0.87842032487295174, 0.86563915863944885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.789115646259\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851191997985\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.210884353741\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.26724137931\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   0]\n",
      " [ 62   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       232\n",
      "\n",
      "avg / total       0.79      1.00      0.88       232\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8231292517006803, 'LogisticRegression', (array([  2,  14,  38, 107, 115, 131, 134, 151, 161, 167, 176, 180, 186,\n",
      "       192, 200, 203, 205, 217, 230, 243, 254, 265], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  2,   8,  14,  27,  38, 107, 115, 151, 158, 161, 167, 176, 186,\n",
      "       192, 203, 205, 217], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87842032487295174, 0.86563915863944885, 0.85119199798516598]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.789115646259\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851191997985\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.210884353741\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.26724137931\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   0]\n",
      " [ 62   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       232\n",
      "\n",
      "avg / total       0.79      1.00      0.88       232\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8231292517006803, 'LogisticRegression', (array([  2,  14,  38, 107, 115, 131, 134, 151, 161, 167, 176, 180, 186,\n",
      "       192, 200, 203, 205, 217, 230, 243, 254, 265], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  2,   8,  14,  27,  38, 107, 115, 151, 158, 161, 167, 176, 186,\n",
      "       192, 203, 205, 217], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78911564625850339, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87842032487295174, 0.86563915863944885, 0.85119199798516598, 0.85119199798516598]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.789115646259\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851191997985\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.210884353741\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.26724137931\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   0]\n",
      " [ 62   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88       232\n",
      "\n",
      "avg / total       0.79      1.00      0.88       232\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8231292517006803, 'LogisticRegression', (array([  2,  14,  38, 107, 115, 131, 134, 151, 161, 167, 176, 180, 186,\n",
      "       192, 200, 203, 205, 217, 230, 243, 254, 265], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  2,   8,  14,  27,  38, 107, 115, 151, 158, 161, 167, 176, 186,\n",
      "       192, 203, 205, 217], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78911564625850339, 'KNN', (array([], dtype=int64),)], [0.78911564625850339, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87842032487295174, 0.86563915863944885, 0.85119199798516598, 0.85119199798516598, 0.85119199798516598]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.80612244898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.846920790664\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.19387755102\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.165044493882\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[227   5]\n",
      " [ 52  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.98      0.89       232\n",
      "          1       0.67      0.16      0.26        62\n",
      "\n",
      "avg / total       0.78      0.81      0.76       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8231292517006803, 'LogisticRegression', (array([  2,  14,  38, 107, 115, 131, 134, 151, 161, 167, 176, 180, 186,\n",
      "       192, 200, 203, 205, 217, 230, 243, 254, 265], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  2,   8,  14,  27,  38, 107, 115, 151, 158, 161, 167, 176, 186,\n",
      "       192, 203, 205, 217], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78911564625850339, 'KNN', (array([], dtype=int64),)], [0.78911564625850339, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.80612244897959184, 'RandomForest', (array([ 15,  19,  26,  27,  38,  74, 119, 145, 151, 161, 176, 206, 222,\n",
      "       260, 274], dtype=int64),)]]\n",
      "[0.87842032487295174, 0.86563915863944885, 0.85119199798516598, 0.85119199798516598, 0.85119199798516598, 0.84692079066387038]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.875843284542\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00152947719689\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[230   2]\n",
      " [ 47  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90       232\n",
      "          1       0.88      0.24      0.38        62\n",
      "\n",
      "avg / total       0.84      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.8231292517006803, 'LogisticRegression', (array([  2,  14,  38, 107, 115, 131, 134, 151, 161, 167, 176, 180, 186,\n",
      "       192, 200, 203, 205, 217, 230, 243, 254, 265], dtype=int64),)], [0.82653061224489799, 'SelectKBest+LR', (array([  2,   8,  14,  27,  38, 107, 115, 151, 158, 161, 167, 176, 186,\n",
      "       192, 203, 205, 217], dtype=int64),)], [0.78911564625850339, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.78911564625850339, 'KNN', (array([], dtype=int64),)], [0.78911564625850339, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.80612244897959184, 'RandomForest', (array([ 15,  19,  26,  27,  38,  74, 119, 145, 151, 161, 176, 206, 222,\n",
      "       260, 274], dtype=int64),)], [0.83333333333333337, 'XGBoost', (array([ 19,  26,  27,  38,  74, 115, 134, 136, 151, 167, 176, 180, 186,\n",
      "       200, 205, 260, 274], dtype=int64),)]]\n",
      "[0.87842032487295174, 0.86563915863944885, 0.85119199798516598, 0.85119199798516598, 0.85119199798516598, 0.84692079066387038, 0.87584328454249272]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863936259314\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.275426588258\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241  12]\n",
      " [ 33   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       253\n",
      "          1       0.40      0.20      0.26        41\n",
      "\n",
      "avg / total       0.81      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  39,  51,  56,  66,  71,  83, 109, 135, 149, 164, 165, 166,\n",
      "       179, 181, 194, 203, 266, 276, 289], dtype=int64),)]]\n",
      "[0.86393625931399221]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.851200630711\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.247083775186\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   7]\n",
      " [ 37   4]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.97      0.92       253\n",
      "          1       0.36      0.10      0.15        41\n",
      "\n",
      "avg / total       0.80      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  39,  51,  56,  66,  71,  83, 109, 135, 149, 164, 165, 166,\n",
      "       179, 181, 194, 203, 266, 276, 289], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 39,  51,  56,  73, 109, 149, 179, 181, 194, 276, 289], dtype=int64),)]]\n",
      "[0.86393625931399221, 0.85120063071140617]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  39,  51,  56,  66,  71,  83, 109, 135, 149, 164, 165, 166,\n",
      "       179, 181, 194, 203, 266, 276, 289], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 39,  51,  56,  73, 109, 149, 179, 181, 194, 276, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86393625931399221, 0.85120063071140617, 0.83333477765483888]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  39,  51,  56,  66,  71,  83, 109, 135, 149, 164, 165, 166,\n",
      "       179, 181, 194, 203, 266, 276, 289], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 39,  51,  56,  73, 109, 149, 179, 181, 194, 276, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86393625931399221, 0.85120063071140617, 0.83333477765483888, 0.83333477765483888]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833334777655\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.162055335968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   0]\n",
      " [ 41   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       253\n",
      "\n",
      "avg / total       0.86      1.00      0.93       253\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  39,  51,  56,  66,  71,  83, 109, 135, 149, 164, 165, 166,\n",
      "       179, 181, 194, 203, 266, 276, 289], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 39,  51,  56,  73, 109, 149, 179, 181, 194, 276, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86393625931399221, 0.85120063071140617, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844402292392\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.332112214403\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   7]\n",
      " [ 40   1]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       253\n",
      "          1       0.12      0.02      0.04        41\n",
      "\n",
      "avg / total       0.76      0.84      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  39,  51,  56,  66,  71,  83, 109, 135, 149, 164, 165, 166,\n",
      "       179, 181, 194, 203, 266, 276, 289], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 39,  51,  56,  73, 109, 149, 179, 181, 194, 276, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84013605442176875, 'RandomForest', (array([ 14, 109, 135, 149, 162, 175, 194, 223], dtype=int64),)]]\n",
      "[0.86393625931399221, 0.85120063071140617, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888, 0.8444022923916773]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863111972303\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0770268967512\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   7]\n",
      " [ 31  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       253\n",
      "          1       0.59      0.24      0.34        41\n",
      "\n",
      "avg / total       0.85      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 32,  39,  51,  56,  66,  71,  83, 109, 135, 149, 164, 165, 166,\n",
      "       179, 181, 194, 203, 266, 276, 289], dtype=int64),)], [0.85034013605442171, 'SelectKBest+LR', (array([ 39,  51,  56,  73, 109, 149, 179, 181, 194, 276, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.86054421768707479, 'KNN', (array([], dtype=int64),)], [0.86054421768707479, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84013605442176875, 'RandomForest', (array([ 14, 109, 135, 149, 162, 175, 194, 223], dtype=int64),)], [0.87074829931972786, 'XGBoost', (array([ 14,  51,  56,  71,  86,  98, 109, 149, 164, 165, 166, 175, 181,\n",
      "       183, 203, 271, 289], dtype=int64),)]]\n",
      "[0.86393625931399221, 0.85120063071140617, 0.83333477765483888, 0.83333477765483888, 0.83333477765483888, 0.8444022923916773, 0.86311197230302683]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0208333333333\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   6]\n",
      " [ 39  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       240\n",
      "          1       0.71      0.28      0.40        54\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  27,  28,  40,  55,  59,  65,  74,  81,  97, 115, 133, 166,\n",
      "       172, 180, 199, 227, 232, 246, 284, 288], dtype=int64),)]]\n",
      "[0.87074829931972797]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.849489795918\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.111574074074\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235   5]\n",
      " [ 44  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91       240\n",
      "          1       0.67      0.19      0.29        54\n",
      "\n",
      "avg / total       0.81      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  27,  28,  40,  55,  59,  65,  74,  81,  97, 115, 133, 166,\n",
      "       172, 180, 199, 227, 232, 246, 284, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 20,  24,  27,  28,  40,  55,  59,  73,  97, 161, 166, 172, 180,\n",
      "       232, 246], dtype=int64),)]]\n",
      "[0.87074829931972797, 0.84948979591836737]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  27,  28,  40,  55,  59,  65,  74,  81,  97, 115, 133, 166,\n",
      "       172, 180, 199, 227, 232, 246, 284, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 20,  24,  27,  28,  40,  55,  59,  73,  97, 161, 166, 172, 180,\n",
      "       232, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.87074829931972797, 0.84948979591836737, 0.84438775510204078]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  27,  28,  40,  55,  59,  65,  74,  81,  97, 115, 133, 166,\n",
      "       172, 180, 199, 227, 232, 246, 284, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 20,  24,  27,  28,  40,  55,  59,  73,  97, 161, 166, 172, 180,\n",
      "       232, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.87074829931972797, 0.84948979591836737, 0.84438775510204078, 0.84438775510204078]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.816326530612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.183673469388\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.225\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   0]\n",
      " [ 54   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       240\n",
      "\n",
      "avg / total       0.82      1.00      0.90       240\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  27,  28,  40,  55,  59,  65,  74,  81,  97, 115, 133, 166,\n",
      "       172, 180, 199, 227, 232, 246, 284, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 20,  24,  27,  28,  40,  55,  59,  73,  97, 161, 166, 172, 180,\n",
      "       232, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.87074829931972797, 0.84948979591836737, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0888888888889\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   6]\n",
      " [ 42  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91       240\n",
      "          1       0.67      0.22      0.33        54\n",
      "\n",
      "avg / total       0.81      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  27,  28,  40,  55,  59,  65,  74,  81,  97, 115, 133, 166,\n",
      "       172, 180, 199, 227, 232, 246, 284, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 20,  24,  27,  28,  40,  55,  59,  73,  97, 161, 166, 172, 180,\n",
      "       232, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 19,  20,  50,  58,  81,  97, 101, 115, 122, 135, 153, 166, 172,\n",
      "       177, 180, 189, 246, 293], dtype=int64),)]]\n",
      "[0.87074829931972797, 0.84948979591836737, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.84353741496598644]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.87925170068\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.134259259259\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[229  11]\n",
      " [ 39  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90       240\n",
      "          1       0.58      0.28      0.38        54\n",
      "\n",
      "avg / total       0.80      0.83      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  27,  28,  40,  55,  59,  65,  74,  81,  97, 115, 133, 166,\n",
      "       172, 180, 199, 227, 232, 246, 284, 288], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([ 20,  24,  27,  28,  40,  55,  59,  73,  97, 161, 166, 172, 180,\n",
      "       232, 246], dtype=int64),)], [0.81632653061224492, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81632653061224492, 'KNN', (array([], dtype=int64),)], [0.81632653061224492, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.83673469387755106, 'RandomForest', (array([ 19,  20,  50,  58,  81,  97, 101, 115, 122, 135, 153, 166, 172,\n",
      "       177, 180, 189, 246, 293], dtype=int64),)], [0.82993197278911568, 'XGBoost', (array([ 14,  27,  32,  47,  59,  66,  68,  81,  97, 110, 115, 134, 161,\n",
      "       166, 172, 174, 178, 180, 213, 229, 232, 233, 237, 246, 284, 288], dtype=int64),)]]\n",
      "[0.87074829931972797, 0.84948979591836737, 0.84438775510204078, 0.84438775510204078, 0.84438775510204078, 0.84353741496598644, 0.87925170068027214]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863944991649\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.127729174591\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[231   8]\n",
      " [ 31  24]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       239\n",
      "          1       0.75      0.44      0.55        55\n",
      "\n",
      "avg / total       0.86      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  9,  11,  12,  33,  35,  40,  56,  71,  83,  89,  92,  99, 103,\n",
      "       118, 119, 125, 135, 143, 155, 176, 183, 188, 221, 242, 245, 248,\n",
      "       251, 253, 268, 272, 275, 279], dtype=int64),)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86394499164861216]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857144390005\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0959300114112\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   1]\n",
      " [ 48   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       239\n",
      "          1       0.88      0.13      0.22        55\n",
      "\n",
      "avg / total       0.84      0.83      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  9,  11,  12,  33,  35,  40,  56,  71,  83,  89,  92,  99, 103,\n",
      "       118, 119, 125, 135, 143, 155, 176, 183, 188, 221, 242, 245, 248,\n",
      "       251, 253, 268, 272, 275, 279], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  9, 103, 135, 143, 155, 176, 221, 248], dtype=int64),)]]\n",
      "[0.86394499164861216, 0.85714439000514464]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  9,  11,  12,  33,  35,  40,  56,  71,  83,  89,  92,  99, 103,\n",
      "       118, 119, 125, 135, 143, 155, 176, 183, 188, 221, 242, 245, 248,\n",
      "       251, 253, 268, 272, 275, 279], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  9, 103, 135, 143, 155, 176, 221, 248], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86394499164861216, 0.85714439000514464, 0.8452395948975896]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  9,  11,  12,  33,  35,  40,  56,  71,  83,  89,  92,  99, 103,\n",
      "       118, 119, 125, 135, 143, 155, 176, 183, 188, 221, 242, 245, 248,\n",
      "       251, 253, 268, 272, 275, 279], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  9, 103, 135, 143, 155, 176, 221, 248], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86394499164861216, 0.85714439000514464, 0.8452395948975896, 0.8452395948975896]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  9,  11,  12,  33,  35,  40,  56,  71,  83,  89,  92,  99, 103,\n",
      "       118, 119, 125, 135, 143, 155, 176, 183, 188, 221, 242, 245, 248,\n",
      "       251, 253, 268, 272, 275, 279], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  9, 103, 135, 143, 155, 176, 221, 248], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86394499164861216, 0.85714439000514464, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840126713369\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[227  12]\n",
      " [ 43  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89       239\n",
      "          1       0.50      0.22      0.30        55\n",
      "\n",
      "avg / total       0.78      0.81      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  9,  11,  12,  33,  35,  40,  56,  71,  83,  89,  92,  99, 103,\n",
      "       118, 119, 125, 135, 143, 155, 176, 183, 188, 221, 242, 245, 248,\n",
      "       251, 253, 268, 272, 275, 279], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  9, 103, 135, 143, 155, 176, 221, 248], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81292517006802723, 'RandomForest', (array([ 44,  49,  69,  73,  74,  83,  89, 130, 133, 143, 147, 156, 164,\n",
      "       188, 192, 216, 220, 221, 229, 244, 248, 251, 268, 278], dtype=int64),)]]\n",
      "[0.86394499164861216, 0.85714439000514464, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896, 0.84012671336927303]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.865643530341\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00646633701027\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[232   7]\n",
      " [ 38  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       239\n",
      "          1       0.71      0.31      0.43        55\n",
      "\n",
      "avg / total       0.83      0.85      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([  9,  11,  12,  33,  35,  40,  56,  71,  83,  89,  92,  99, 103,\n",
      "       118, 119, 125, 135, 143, 155, 176, 183, 188, 221, 242, 245, 248,\n",
      "       251, 253, 268, 272, 275, 279], dtype=int64),)], [0.83333333333333337, 'SelectKBest+LR', (array([  9, 103, 135, 143, 155, 176, 221, 248], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.81292517006802723, 'RandomForest', (array([ 44,  49,  69,  73,  74,  83,  89, 130, 133, 143, 147, 156, 164,\n",
      "       188, 192, 216, 220, 221, 229, 244, 248, 251, 268, 278], dtype=int64),)], [0.84693877551020413, 'XGBoost', (array([ 12,  35,  49,  89, 119, 130, 143, 147, 155, 156, 164, 176, 183,\n",
      "       188, 192, 216, 221, 244, 247, 248, 251, 252, 256, 268], dtype=int64),)]]\n",
      "[0.86394499164861216, 0.85714439000514464, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896, 0.84012671336927303, 0.86564353034055752]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857135724076\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.118367346939\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   1]\n",
      " [ 35  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       245\n",
      "          1       0.93      0.29      0.44        49\n",
      "\n",
      "avg / total       0.88      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 21,  73,  89,  94,  95, 103, 125, 131, 143, 145, 206, 215, 245,\n",
      "       262, 291], dtype=int64),)]]\n",
      "[0.85713572407611116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.167346938776\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   1]\n",
      " [ 33  16]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93       245\n",
      "          1       0.94      0.33      0.48        49\n",
      "\n",
      "avg / total       0.89      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 21,  73,  89,  94,  95, 103, 125, 131, 143, 145, 206, 215, 245,\n",
      "       262, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 21,  26,  73,  95, 100, 103, 125, 131, 143, 145, 179, 215, 245,\n",
      "       262, 284, 287, 291], dtype=int64),)]]\n",
      "[0.85713572407611116, 0.8452395948975896]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 21,  73,  89,  94,  95, 103, 125, 131, 143, 145, 206, 215, 245,\n",
      "       262, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 21,  26,  73,  95, 100, 103, 125, 131, 143, 145, 179, 215, 245,\n",
      "       262, 284, 287, 291], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85713572407611116, 0.8452395948975896, 0.84013753194606755]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 21,  73,  89,  94,  95, 103, 125, 131, 143, 145, 206, 215, 245,\n",
      "       262, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 21,  26,  73,  95, 100, 103, 125, 131, 143, 145, 179, 215, 245,\n",
      "       262, 284, 287, 291], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85713572407611116, 0.8452395948975896, 0.84013753194606755, 0.84013753194606755]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 21,  73,  89,  94,  95, 103, 125, 131, 143, 145, 206, 215, 245,\n",
      "       262, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 21,  26,  73,  95, 100, 103, 125, 131, 143, 145, 179, 215, 245,\n",
      "       262, 284, 287, 291], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85713572407611116, 0.8452395948975896, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839280700664\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0285714285714\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   2]\n",
      " [ 40   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       245\n",
      "          1       0.82      0.18      0.30        49\n",
      "\n",
      "avg / total       0.85      0.86      0.82       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 21,  73,  89,  94,  95, 103, 125, 131, 143, 145, 206, 215, 245,\n",
      "       262, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 21,  26,  73,  95, 100, 103, 125, 131, 143, 145, 179, 215, 245,\n",
      "       262, 284, 287, 291], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 24,  63,  73,  95, 125, 143, 179, 206, 238, 262, 287], dtype=int64),)]]\n",
      "[0.85713572407611116, 0.8452395948975896, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.83928070066393634]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859706295396\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.118367346939\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   5]\n",
      " [ 31  18]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       245\n",
      "          1       0.78      0.37      0.50        49\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.87755102040816324, 'LogisticRegression', (array([ 21,  73,  89,  94,  95, 103, 125, 131, 143, 145, 206, 215, 245,\n",
      "       262, 291], dtype=int64),)], [0.88435374149659862, 'SelectKBest+LR', (array([ 21,  26,  73,  95, 100, 103, 125, 131, 143, 145, 179, 215, 245,\n",
      "       262, 284, 287, 291], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 24,  63,  73,  95, 125, 143, 179, 206, 238, 262, 287], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([ 10,  21,  26,  73,  81,  87,  89,  94,  95, 120, 123, 125, 143,\n",
      "       156, 162, 179, 198, 212, 215, 245, 262, 287, 292], dtype=int64),)]]\n",
      "[0.85713572407611116, 0.8452395948975896, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.83928070066393634, 0.85970629539568888]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861394557823\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0757697456493\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   6]\n",
      " [ 35  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       249\n",
      "          1       0.62      0.22      0.33        45\n",
      "\n",
      "avg / total       0.84      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 24,  33,  46,  81,  87,  96, 116, 125, 151, 163, 165, 184, 219,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       221, 237, 289], dtype=int64),)]]\n",
      "[0.86139455782312924]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.862244897959\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0757697456493\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   8]\n",
      " [ 33  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       249\n",
      "          1       0.60      0.27      0.37        45\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 24,  33,  46,  81,  87,  96, 116, 125, 151, 163, 165, 184, 219,\n",
      "       221, 237, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  46,  48,  55,  72,  77,  81,  88,  97, 108, 125, 145, 163,\n",
      "       165, 189, 199, 219, 237, 262, 289], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.8622448979591838]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 24,  33,  46,  81,  87,  96, 116, 125, 151, 163, 165, 184, 219,\n",
      "       221, 237, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  46,  48,  55,  72,  77,  81,  88,  97, 108, 125, 145, 163,\n",
      "       165, 189, 199, 219, 237, 262, 289], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.8622448979591838, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 24,  33,  46,  81,  87,  96, 116, 125, 151, 163, 165, 184, 219,\n",
      "       221, 237, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  46,  48,  55,  72,  77,  81,  88,  97, 108, 125, 145, 163,\n",
      "       165, 189, 199, 219, 237, 262, 289], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.8622448979591838, 0.83673469387755117, 0.83673469387755117]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 24,  33,  46,  81,  87,  96, 116, 125, 151, 163, 165, 184, 219,\n",
      "       221, 237, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  46,  48,  55,  72,  77,  81,  88,  97, 108, 125, 145, 163,\n",
      "       165, 189, 199, 219, 237, 262, 289], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.8622448979591838, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841836734694\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.102008032129\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   8]\n",
      " [ 34  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       249\n",
      "          1       0.58      0.24      0.34        45\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 24,  33,  46,  81,  87,  96, 116, 125, 151, 163, 165, 184, 219,\n",
      "       221, 237, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  46,  48,  55,  72,  77,  81,  88,  97, 108, 125, 145, 163,\n",
      "       165, 189, 199, 219, 237, 262, 289], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 24,  46,  54,  64,  71,  80,  81,  97, 125, 161, 163, 193, 195,\n",
      "       219, 250, 258, 262, 282, 289], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.8622448979591838, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.84183673469387754]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.856292517007\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.055421686747\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 33  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       249\n",
      "          1       0.80      0.27      0.40        45\n",
      "\n",
      "avg / total       0.87      0.88      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([ 24,  33,  46,  81,  87,  96, 116, 125, 151, 163, 165, 184, 219,\n",
      "       221, 237, 289], dtype=int64),)], [0.86054421768707479, 'SelectKBest+LR', (array([ 24,  46,  48,  55,  72,  77,  81,  88,  97, 108, 125, 145, 163,\n",
      "       165, 189, 199, 219, 237, 262, 289], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 24,  46,  54,  64,  71,  80,  81,  97, 125, 161, 163, 193, 195,\n",
      "       219, 250, 258, 262, 282, 289], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([  1,  24,  33,  64,  81, 116, 125, 145, 161, 163, 195, 207, 237,\n",
      "       262, 289], dtype=int64),)]]\n",
      "[0.86139455782312924, 0.8622448979591838, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.84183673469387754, 0.85629251700680264]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857960011087\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.167346938776\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[240   5]\n",
      " [ 29  20]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       245\n",
      "          1       0.80      0.41      0.54        49\n",
      "\n",
      "avg / total       0.88      0.88      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  2,  23,  50,  64,  75,  79,  84,  96,  98, 100, 114, 130, 140,\n",
      "       158, 161, 186, 207, 211, 215, 220, 224, 236, 247, 256, 273], dtype=int64),)]]\n",
      "[0.85796001108707676]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853714834756\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0204081632653\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   2]\n",
      " [ 38  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92       245\n",
      "          1       0.85      0.22      0.35        49\n",
      "\n",
      "avg / total       0.86      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  2,  23,  50,  64,  75,  79,  84,  96,  98, 100, 114, 130, 140,\n",
      "       158, 161, 186, 207, 211, 215, 220, 224, 236, 247, 256, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  2,  23,  50, 100, 108, 130, 158, 207, 224, 236, 247, 256, 273], dtype=int64),)]]\n",
      "[0.85796001108707676, 0.85371483475567456]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  2,  23,  50,  64,  75,  79,  84,  96,  98, 100, 114, 130, 140,\n",
      "       158, 161, 186, 207, 211, 215, 220, 224, 236, 247, 256, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  2,  23,  50, 100, 108, 130, 158, 207, 224, 236, 247, 256, 273], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85796001108707676, 0.85371483475567456, 0.84013753194606755]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  2,  23,  50,  64,  75,  79,  84,  96,  98, 100, 114, 130, 140,\n",
      "       158, 161, 186, 207, 211, 215, 220, 224, 236, 247, 256, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  2,  23,  50, 100, 108, 130, 158, 207, 224, 236, 247, 256, 273], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85796001108707676, 0.85371483475567456, 0.84013753194606755, 0.84013753194606755]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.833333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840137531946\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.166666666667\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.2\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   0]\n",
      " [ 49   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      1.00      0.91       245\n",
      "\n",
      "avg / total       0.83      1.00      0.91       245\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  2,  23,  50,  64,  75,  79,  84,  96,  98, 100, 114, 130, 140,\n",
      "       158, 161, 186, 207, 211, 215, 220, 224, 236, 247, 256, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  2,  23,  50, 100, 108, 130, 158, 207, 224, 236, 247, 256, 273], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85796001108707676, 0.85371483475567456, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.833354306431\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.224489795918\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[231  14]\n",
      " [ 36  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.94      0.90       245\n",
      "          1       0.48      0.27      0.34        49\n",
      "\n",
      "avg / total       0.80      0.83      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  2,  23,  50,  64,  75,  79,  84,  96,  98, 100, 114, 130, 140,\n",
      "       158, 161, 186, 207, 211, 215, 220, 224, 236, 247, 256, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  2,  23,  50, 100, 108, 130, 158, 207, 224, 236, 247, 256, 273], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([ 24,  53,  64,  84,  86,  89, 100, 104, 126, 130, 138, 149, 158,\n",
      "       179, 191, 193, 205, 215, 224, 234, 236, 240, 247, 256, 272, 281, 288], dtype=int64),)]]\n",
      "[0.85796001108707676, 0.85371483475567456, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.8333543064310579]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.874149659864\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857975201365\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.125850340136\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0938775510204\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   7]\n",
      " [ 30  19]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93       245\n",
      "          1       0.73      0.39      0.51        49\n",
      "\n",
      "avg / total       0.86      0.87      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  2,  23,  50,  64,  75,  79,  84,  96,  98, 100, 114, 130, 140,\n",
      "       158, 161, 186, 207, 211, 215, 220, 224, 236, 247, 256, 273], dtype=int64),)], [0.86394557823129248, 'SelectKBest+LR', (array([  2,  23,  50, 100, 108, 130, 158, 207, 224, 236, 247, 256, 273], dtype=int64),)], [0.83333333333333337, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.83333333333333337, 'KNN', (array([], dtype=int64),)], [0.83333333333333337, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82993197278911568, 'RandomForest', (array([ 24,  53,  64,  84,  86,  89, 100, 104, 126, 130, 138, 149, 158,\n",
      "       179, 191, 193, 205, 215, 224, 234, 236, 240, 247, 256, 272, 281, 288], dtype=int64),)], [0.87414965986394555, 'XGBoost', (array([  2,  18,  23,  50,  75,  84,  93, 100, 106, 113, 114, 130, 133,\n",
      "       158, 161, 171, 173, 207, 211, 224, 229, 236, 237, 247, 256, 272], dtype=int64),)]]\n",
      "[0.85796001108707676, 0.85371483475567456, 0.84013753194606755, 0.84013753194606755, 0.84013753194606755, 0.8333543064310579, 0.85797520136498007]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.854608526672\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.00508415147265\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238  10]\n",
      " [ 29  17]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.92       248\n",
      "          1       0.63      0.37      0.47        46\n",
      "\n",
      "avg / total       0.85      0.87      0.85       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 19,  21,  30,  46,  47,  49,  81,  91, 106, 111, 131, 140, 150,\n",
      "       168, 173, 176, 179, 235, 244, 257, 258, 259, 263, 269, 271, 272, 281], dtype=int64),)]]\n",
      "[0.85460852667209153]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.859708425908\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.159712482468\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   2]\n",
      " [ 43   3]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       248\n",
      "          1       0.60      0.07      0.12        46\n",
      "\n",
      "avg / total       0.81      0.85      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 19,  21,  30,  46,  47,  49,  81,  91, 106, 111, 131, 140, 150,\n",
      "       168, 173, 176, 179, 235, 244, 257, 258, 259, 263, 269, 271, 272, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 21, 146, 235, 259, 263], dtype=int64),)]]\n",
      "[0.85460852667209153, 0.85970842590825469]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 19,  21,  30,  46,  47,  49,  81,  91, 106, 111, 131, 140, 150,\n",
      "       168, 173, 176, 179, 235, 244, 257, 258, 259, 263, 269, 271, 272, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 21, 146, 235, 259, 263], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85460852667209153, 0.85970842590825469, 0.83758650047030658]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 19,  21,  30,  46,  47,  49,  81,  91, 106, 111, 131, 140, 150,\n",
      "       168, 173, 176, 179, 235, 244, 257, 258, 259, 263, 269, 271, 272, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 21, 146, 235, 259, 263], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85460852667209153, 0.85970842590825469, 0.83758650047030658, 0.83758650047030658]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.843537414966\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83758650047\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.156462585034\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.185483870968\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   0]\n",
      " [ 46   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.92       248\n",
      "\n",
      "avg / total       0.84      1.00      0.92       248\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 19,  21,  30,  46,  47,  49,  81,  91, 106, 111, 131, 140, 150,\n",
      "       168, 173, 176, 179, 235, 244, 257, 258, 259, 263, 269, 271, 272, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 21, 146, 235, 259, 263], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85460852667209153, 0.85970842590825469, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.857142857143\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.841840375934\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.142857142857\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0823983169705\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[242   6]\n",
      " [ 36  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       248\n",
      "          1       0.62      0.22      0.32        46\n",
      "\n",
      "avg / total       0.83      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 19,  21,  30,  46,  47,  49,  81,  91, 106, 111, 131, 140, 150,\n",
      "       168, 173, 176, 179, 235, 244, 257, 258, 259, 263, 269, 271, 272, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 21, 146, 235, 259, 263], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 21,  30,  94, 110, 168, 176, 191, 210, 233, 235, 244, 258, 259,\n",
      "       269, 272, 278], dtype=int64),)]]\n",
      "[0.85460852667209153, 0.85970842590825469, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.84184037593353533]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.880952380952\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857153055934\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.119047619048\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.0980014025245\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[244   4]\n",
      " [ 31  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       248\n",
      "          1       0.79      0.33      0.46        46\n",
      "\n",
      "avg / total       0.87      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86734693877551017, 'LogisticRegression', (array([ 19,  21,  30,  46,  47,  49,  81,  91, 106, 111, 131, 140, 150,\n",
      "       168, 173, 176, 179, 235, 244, 257, 258, 259, 263, 269, 271, 272, 281], dtype=int64),)], [0.84693877551020413, 'SelectKBest+LR', (array([ 21, 146, 235, 259, 263], dtype=int64),)], [0.84353741496598644, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84353741496598644, 'KNN', (array([], dtype=int64),)], [0.84353741496598644, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.8571428571428571, 'RandomForest', (array([ 21,  30,  94, 110, 168, 176, 191, 210, 233, 235, 244, 258, 259,\n",
      "       269, 272, 278], dtype=int64),)], [0.88095238095238093, 'XGBoost', (array([  7,  26,  30,  46,  54,  91, 110, 131, 140, 146, 150, 168, 196,\n",
      "       210, 233, 235, 248, 259, 281], dtype=int64),)]]\n",
      "[0.85460852667209153, 0.85970842590825469, 0.83758650047030658, 0.83758650047030658, 0.83758650047030658, 0.84184037593353533, 0.85715305593417812]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.139455782313\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0757697456493\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238  11]\n",
      " [ 30  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.96      0.92       249\n",
      "          1       0.58      0.33      0.42        45\n",
      "\n",
      "avg / total       0.84      0.86      0.84       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  5,   7,  12,  16,  34,  35,  42,  46,  47,  59,  67,  78,  80,\n",
      "       103, 107, 112, 116, 157, 159, 168, 177, 180, 187, 199, 241, 279], dtype=int64),)]]\n",
      "[0.86394557823129248]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.867346938776\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.840986394558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.132653061224\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0232931726908\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[247   2]\n",
      " [ 37   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93       249\n",
      "          1       0.80      0.18      0.29        45\n",
      "\n",
      "avg / total       0.86      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  5,   7,  12,  16,  34,  35,  42,  46,  47,  59,  67,  78,  80,\n",
      "       103, 107, 112, 116, 157, 159, 168, 177, 180, 187, 199, 241, 279], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 12,  34,  35,  46,  59, 112, 116, 177, 187, 249], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.8409863945578232]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  5,   7,  12,  16,  34,  35,  42,  46,  47,  59,  67,  78,  80,\n",
      "       103, 107, 112, 116, 157, 159, 168, 177, 180, 187, 199, 241, 279], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 12,  34,  35,  46,  59, 112, 116, 177, 187, 249], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.8409863945578232, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  5,   7,  12,  16,  34,  35,  42,  46,  47,  59,  67,  78,  80,\n",
      "       103, 107, 112, 116, 157, 159, 168, 177, 180, 187, 199, 241, 279], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 12,  34,  35,  46,  59, 112, 116, 177, 187, 249], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.8409863945578232, 0.83673469387755117, 0.83673469387755117]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  5,   7,  12,  16,  34,  35,  42,  46,  47,  59,  67,  78,  80,\n",
      "       103, 107, 112, 116, 157, 159, 168, 177, 180, 187, 199, 241, 279], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 12,  34,  35,  46,  59, 112, 116, 177, 187, 249], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.8409863945578232, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237  12]\n",
      " [ 33  12]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       249\n",
      "          1       0.50      0.27      0.35        45\n",
      "\n",
      "avg / total       0.82      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  5,   7,  12,  16,  34,  35,  42,  46,  47,  59,  67,  78,  80,\n",
      "       103, 107, 112, 116, 157, 159, 168, 177, 180, 187, 199, 241, 279], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 12,  34,  35,  46,  59, 112, 116, 177, 187, 249], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  5,   7,  16,  37,  46,  47,  63, 107, 110, 116, 149, 155, 157,\n",
      "       165, 172, 177, 187, 202, 206, 242, 247, 249, 272, 289], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.8409863945578232, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83673469387755095]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.861394557823\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.055421686747\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[243   6]\n",
      " [ 30  15]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       249\n",
      "          1       0.71      0.33      0.45        45\n",
      "\n",
      "avg / total       0.86      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.86054421768707479, 'LogisticRegression', (array([  5,   7,  12,  16,  34,  35,  42,  46,  47,  59,  67,  78,  80,\n",
      "       103, 107, 112, 116, 157, 159, 168, 177, 180, 187, 199, 241, 279], dtype=int64),)], [0.86734693877551017, 'SelectKBest+LR', (array([ 12,  34,  35,  46,  59, 112, 116, 177, 187, 249], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.84693877551020413, 'RandomForest', (array([  5,   7,  16,  37,  46,  47,  63, 107, 110, 116, 149, 155, 157,\n",
      "       165, 172, 177, 187, 202, 206, 242, 247, 249, 272, 289], dtype=int64),)], [0.87755102040816324, 'XGBoost', (array([ 12,  16,  34,  35,  37,  42,  46,  73,  97, 112, 116, 149, 157,\n",
      "       168, 177, 187, 199, 230, 249, 272, 289], dtype=int64),)]]\n",
      "[0.86394557823129248, 0.8409863945578232, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.83673469387755095, 0.86139455782312924]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858843537415\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.107898259705\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 31  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.94       249\n",
      "          1       0.82      0.31      0.45        45\n",
      "\n",
      "avg / total       0.88      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  5,  12,  37,  44,  54,  70, 109, 119, 121, 122, 173, 208, 239,\n",
      "       251, 282, 284, 293], dtype=int64),)]]\n",
      "[0.85884353741496611]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.87074829932\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.848639455782\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.12925170068\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.00294511378849\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   1]\n",
      " [ 37   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       249\n",
      "          1       0.89      0.18      0.30        45\n",
      "\n",
      "avg / total       0.87      0.87      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  5,  12,  37,  44,  54,  70, 109, 119, 121, 122, 173, 208, 239,\n",
      "       251, 282, 284, 293], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 12,  37,  70, 121, 173, 208, 239, 244, 251], dtype=int64),)]]\n",
      "[0.85884353741496611, 0.84863945578231303]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  5,  12,  37,  44,  54,  70, 109, 119, 121, 122, 173, 208, 239,\n",
      "       251, 282, 284, 293], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 12,  37,  70, 121, 173, 208, 239, 244, 251], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.85884353741496611, 0.84863945578231303, 0.83673469387755117]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  5,  12,  37,  44,  54,  70, 109, 119, 121, 122, 173, 208, 239,\n",
      "       251, 282, 284, 293], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 12,  37,  70, 121, 173, 208, 239, 244, 251], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.85884353741496611, 0.84863945578231303, 0.83673469387755117, 0.83673469387755117]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.180722891566\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[249   0]\n",
      " [ 45   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92       249\n",
      "\n",
      "avg / total       0.85      1.00      0.92       249\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  5,  12,  37,  44,  54,  70, 109, 119, 121, 122, 173, 208, 239,\n",
      "       251, 282, 284, 293], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 12,  37,  70, 121, 173, 208, 239, 244, 251], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.85884353741496611, 0.84863945578231303, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.863945578231\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.829081632653\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.136054421769\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.04953145917\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   3]\n",
      " [ 37   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       249\n",
      "          1       0.73      0.18      0.29        45\n",
      "\n",
      "avg / total       0.85      0.86      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  5,  12,  37,  44,  54,  70, 109, 119, 121, 122, 173, 208, 239,\n",
      "       251, 282, 284, 293], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 12,  37,  70, 121, 173, 208, 239, 244, 251], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 12,  14, 105, 119, 122, 161, 173, 227, 228, 238, 251], dtype=int64),)]]\n",
      "[0.85884353741496611, 0.84863945578231303, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.82908163265306134]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.891156462585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.860544217687\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.108843537415\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.160374832664\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[248   1]\n",
      " [ 31  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       249\n",
      "          1       0.93      0.31      0.47        45\n",
      "\n",
      "avg / total       0.90      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([  5,  12,  37,  44,  54,  70, 109, 119, 121, 122, 173, 208, 239,\n",
      "       251, 282, 284, 293], dtype=int64),)], [0.87074829931972786, 'SelectKBest+LR', (array([ 12,  37,  70, 121, 173, 208, 239, 244, 251], dtype=int64),)], [0.84693877551020413, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.84693877551020413, 'KNN', (array([], dtype=int64),)], [0.84693877551020413, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.86394557823129248, 'RandomForest', (array([ 12,  14, 105, 119, 122, 161, 173, 227, 228, 238, 251], dtype=int64),)], [0.891156462585034, 'XGBoost', (array([ 12,  19,  20,  37, 122, 139, 173, 206, 208, 220, 227, 239, 258,\n",
      "       282, 284], dtype=int64),)]]\n",
      "[0.85884353741496611, 0.84863945578231303, 0.83673469387755117, 0.83673469387755117, 0.83673469387755117, 0.82908163265306134, 0.8605442176870749]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863081613882\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m 0.01589958159\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[237   2]\n",
      " [ 42  13]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.99      0.92       239\n",
      "          1       0.87      0.24      0.37        55\n",
      "\n",
      "avg / total       0.85      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 11,  15,  21,  36,  38,  49,  89,  93, 108, 123, 134, 201, 202,\n",
      "       237, 244], dtype=int64),)]]\n",
      "[0.86308161388241544]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.823129251701\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.863101131591\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.176870748299\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.163027767212\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[238   1]\n",
      " [ 51   4]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       239\n",
      "          1       0.80      0.07      0.13        55\n",
      "\n",
      "avg / total       0.82      0.82      0.76       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 11,  15,  21,  36,  38,  49,  89,  93, 108, 123, 134, 201, 202,\n",
      "       237, 244], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 38,  49,  70, 134, 201], dtype=int64),)]]\n",
      "[0.86308161388241544, 0.86310113159103663]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x0000012443365048>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 11,  15,  21,  36,  38,  49,  89,  93, 108, 123, 134, 201, 202,\n",
      "       237, 244], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 38,  49,  70, 134, 201], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)]]\n",
      "[0.86308161388241544, 0.86310113159103663, 0.8452395948975896]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 11,  15,  21,  36,  38,  49,  89,  93, 108, 123, 134, 201, 202,\n",
      "       237, 244], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 38,  49,  70, 134, 201], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)]]\n",
      "[0.86308161388241544, 0.86310113159103663, 0.8452395948975896, 0.8452395948975896]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.812925170068\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845239594898\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.187074829932\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.230125523013\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   0]\n",
      " [ 55   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      1.00      0.90       239\n",
      "\n",
      "avg / total       0.81      1.00      0.90       239\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 11,  15,  21,  36,  38,  49,  89,  93, 108, 123, 134, 201, 202,\n",
      "       237, 244], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 38,  49,  70, 134, 201], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)]]\n",
      "[0.86308161388241544, 0.86310113159103663, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.845228720983\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.173469387755\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.140661848612\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[233   6]\n",
      " [ 45  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       239\n",
      "          1       0.62      0.18      0.28        55\n",
      "\n",
      "avg / total       0.80      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 11,  15,  21,  36,  38,  49,  89,  93, 108, 123, 134, 201, 202,\n",
      "       237, 244], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 38,  49,  70, 134, 201], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([  7,  29,  36,  38,  55,  56,  86, 108, 160, 167, 170, 193, 214,\n",
      "       261, 274, 278], dtype=int64),)]]\n",
      "[0.86308161388241544, 0.86310113159103663, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896, 0.8452287209828061]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mY_TEST : \n",
      "\u001b[0;0m [0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\u001b[1mY_PRED : \n",
      "\u001b[0;0m [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.829931972789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.870762903015\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.170068027211\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.118295930011\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[234   5]\n",
      " [ 45  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90       239\n",
      "          1       0.67      0.18      0.29        55\n",
      "\n",
      "avg / total       0.81      0.83      0.79       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.85034013605442171, 'LogisticRegression', (array([ 11,  15,  21,  36,  38,  49,  89,  93, 108, 123, 134, 201, 202,\n",
      "       237, 244], dtype=int64),)], [0.8231292517006803, 'SelectKBest+LR', (array([ 38,  49,  70, 134, 201], dtype=int64),)], [0.81292517006802723, 'SelectKBest+kNN', (array([], dtype=int64),)], [0.81292517006802723, 'KNN', (array([], dtype=int64),)], [0.81292517006802723, 'RecursiveFeatureElimination', (array([], dtype=int64),)], [0.82653061224489799, 'RandomForest', (array([  7,  29,  36,  38,  55,  56,  86, 108, 160, 167, 170, 193, 214,\n",
      "       261, 274, 278], dtype=int64),)], [0.82993197278911568, 'XGBoost', (array([  5,   9,  21,  29,  36,  38,  56, 104, 107, 134, 145, 160, 167,\n",
      "       193, 201], dtype=int64),)]]\n",
      "[0.86308161388241544, 0.86310113159103663, 0.8452395948975896, 0.8452395948975896, 0.8452395948975896, 0.8452287209828061, 0.87076290301495085]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.91836734693877553, 'XGBoost', (array([  6,  49, 102, 104, 111, 122, 146, 178, 200, 207, 242, 260, 284], dtype=int64),)]\n",
      "LR =  0\n",
      "kNN =  0\n",
      "RF =  0\n",
      "RFE =  0\n",
      "SKB+LR =  34\n",
      "SKB+kNN =  0\n",
      "XGB =  66\n"
     ]
    }
   ],
   "source": [
    "max_accuracy=[]\n",
    "lr=xgb=knn=skblr=skbknn=rfe=rf=knn=0\n",
    "for i in range(0,100,1) :\n",
    "    value=[]\n",
    "    %run Main.ipynb\n",
    "    %store -r accuracy_arr\n",
    "    value=max(accuracy_arr)\n",
    "    if not max_accuracy :\n",
    "        max_accuracy = value\n",
    "    elif(max_accuracy[0] < value[0]) :\n",
    "        max_accuracy = value\n",
    "    if max_accuracy[1]=='LogisticRegression' :\n",
    "        lr=lr+1\n",
    "    elif max_accuracy[1]=='XGBoost' :\n",
    "        xgb=xgb+1\n",
    "    elif max_accuracy[1]=='SelectKBest+LR' :\n",
    "        skblr=skblr+1\n",
    "    elif max_accuracy[1]=='SelectKBest+kNN' :\n",
    "        skbknn=skbknn+1\n",
    "    elif max_accuracy[1]=='RandomForest' :\n",
    "        rf=rf+1\n",
    "    elif max_accuracy[1]=='RecursiveFeatureElimination' :\n",
    "        rfe=rfe+1\n",
    "    else :\n",
    "        knn=knn+1\n",
    "    print(\"Final:\",max_accuracy)\n",
    "print (\"LR = \",lr)\n",
    "print(\"kNN = \",knn)\n",
    "print(\"RF = \",rf)\n",
    "print(\"RFE = \",rfe)\n",
    "print(\"SKB+LR = \",skblr)\n",
    "print(\"SKB+kNN = \",skbknn)\n",
    "print(\"XGB = \",xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPLOYEE NUMBERS OF EMPLOYEES WHO ARE LIKELY TO LEAVE :\n",
      "1627\n",
      " 175\n",
      " 982\n",
      "  45\n",
      "1845\n",
      "1822\n",
      "1071\n",
      " 550\n",
      "1083\n",
      "1693\n",
      "1069\n",
      "1391\n",
      "1362\n"
     ]
    }
   ],
   "source": [
    "print(\"EMPLOYEE NUMBERS OF EMPLOYEES WHO ARE LIKELY TO LEAVE :\")\n",
    "for i in max_accuracy[2] :\n",
    "    print(X_test.iloc[i,5].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
